Loading model, this may take a second...
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, None, None, 3 0                                            
__________________________________________________________________________________________________
padding_conv1 (ZeroPadding2D)   (None, None, None, 3 0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, None, None, 6 9408        padding_conv1[0][0]              
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, None, None, 6 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1 (MaxPooling2D)            (None, None, None, 6 0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, None, None, 6 4096        pool1[0][0]                      
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
res2a_branch2a_relu (Activation (None, None, None, 6 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
padding2a_branch2b (ZeroPadding (None, None, None, 6 0           res2a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, None, None, 6 36864       padding2a_branch2b[0][0]         
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
res2a_branch2b_relu (Activation (None, None, None, 6 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
res2a_branch2c (Conv2D)         (None, None, None, 2 16384       res2a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, None, None, 2 16384       pool1[0][0]                      
__________________________________________________________________________________________________
bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              
__________________________________________________________________________________________________
res2a (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
res2a_relu (Activation)         (None, None, None, 2 0           res2a[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, None, None, 6 16384       res2a_relu[0][0]                 
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
res2b_branch2a_relu (Activation (None, None, None, 6 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
padding2b_branch2b (ZeroPadding (None, None, None, 6 0           res2b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, None, None, 6 36864       padding2b_branch2b[0][0]         
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
res2b_branch2b_relu (Activation (None, None, None, 6 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
res2b_branch2c (Conv2D)         (None, None, None, 2 16384       res2b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             
__________________________________________________________________________________________________
res2b (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              
                                                                 res2a_relu[0][0]                 
__________________________________________________________________________________________________
res2b_relu (Activation)         (None, None, None, 2 0           res2b[0][0]                      
__________________________________________________________________________________________________
res2c_branch2a (Conv2D)         (None, None, None, 6 16384       res2b_relu[0][0]                 
__________________________________________________________________________________________________
bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             
__________________________________________________________________________________________________
res2c_branch2a_relu (Activation (None, None, None, 6 0           bn2c_branch2a[0][0]              
__________________________________________________________________________________________________
padding2c_branch2b (ZeroPadding (None, None, None, 6 0           res2c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res2c_branch2b (Conv2D)         (None, None, None, 6 36864       padding2c_branch2b[0][0]         
__________________________________________________________________________________________________
bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             
__________________________________________________________________________________________________
res2c_branch2b_relu (Activation (None, None, None, 6 0           bn2c_branch2b[0][0]              
__________________________________________________________________________________________________
res2c_branch2c (Conv2D)         (None, None, None, 2 16384       res2c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             
__________________________________________________________________________________________________
res2c (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              
                                                                 res2b_relu[0][0]                 
__________________________________________________________________________________________________
res2c_relu (Activation)         (None, None, None, 2 0           res2c[0][0]                      
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, None, None, 1 32768       res2c_relu[0][0]                 
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
res3a_branch2a_relu (Activation (None, None, None, 1 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
padding3a_branch2b (ZeroPadding (None, None, None, 1 0           res3a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, None, None, 1 147456      padding3a_branch2b[0][0]         
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
res3a_branch2b_relu (Activation (None, None, None, 1 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
res3a_branch2c (Conv2D)         (None, None, None, 5 65536       res3a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, None, None, 5 131072      res2c_relu[0][0]                 
__________________________________________________________________________________________________
bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              
__________________________________________________________________________________________________
res3a (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
res3a_relu (Activation)         (None, None, None, 5 0           res3a[0][0]                      
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, None, None, 1 65536       res3a_relu[0][0]                 
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
res3b_branch2a_relu (Activation (None, None, None, 1 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
padding3b_branch2b (ZeroPadding (None, None, None, 1 0           res3b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, None, None, 1 147456      padding3b_branch2b[0][0]         
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
res3b_branch2b_relu (Activation (None, None, None, 1 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
res3b_branch2c (Conv2D)         (None, None, None, 5 65536       res3b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             
__________________________________________________________________________________________________
res3b (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              
                                                                 res3a_relu[0][0]                 
__________________________________________________________________________________________________
res3b_relu (Activation)         (None, None, None, 5 0           res3b[0][0]                      
__________________________________________________________________________________________________
res3c_branch2a (Conv2D)         (None, None, None, 1 65536       res3b_relu[0][0]                 
__________________________________________________________________________________________________
bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             
__________________________________________________________________________________________________
res3c_branch2a_relu (Activation (None, None, None, 1 0           bn3c_branch2a[0][0]              
__________________________________________________________________________________________________
padding3c_branch2b (ZeroPadding (None, None, None, 1 0           res3c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3c_branch2b (Conv2D)         (None, None, None, 1 147456      padding3c_branch2b[0][0]         
__________________________________________________________________________________________________
bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             
__________________________________________________________________________________________________
res3c_branch2b_relu (Activation (None, None, None, 1 0           bn3c_branch2b[0][0]              
__________________________________________________________________________________________________
res3c_branch2c (Conv2D)         (None, None, None, 5 65536       res3c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             
__________________________________________________________________________________________________
res3c (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              
                                                                 res3b_relu[0][0]                 
__________________________________________________________________________________________________
res3c_relu (Activation)         (None, None, None, 5 0           res3c[0][0]                      
__________________________________________________________________________________________________
res3d_branch2a (Conv2D)         (None, None, None, 1 65536       res3c_relu[0][0]                 
__________________________________________________________________________________________________
bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             
__________________________________________________________________________________________________
res3d_branch2a_relu (Activation (None, None, None, 1 0           bn3d_branch2a[0][0]              
__________________________________________________________________________________________________
padding3d_branch2b (ZeroPadding (None, None, None, 1 0           res3d_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3d_branch2b (Conv2D)         (None, None, None, 1 147456      padding3d_branch2b[0][0]         
__________________________________________________________________________________________________
bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             
__________________________________________________________________________________________________
res3d_branch2b_relu (Activation (None, None, None, 1 0           bn3d_branch2b[0][0]              
__________________________________________________________________________________________________
res3d_branch2c (Conv2D)         (None, None, None, 5 65536       res3d_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             
__________________________________________________________________________________________________
res3d (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              
                                                                 res3c_relu[0][0]                 
__________________________________________________________________________________________________
res3d_relu (Activation)         (None, None, None, 5 0           res3d[0][0]                      
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, None, None, 2 131072      res3d_relu[0][0]                 
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
res4a_branch2a_relu (Activation (None, None, None, 2 0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
padding4a_branch2b (ZeroPadding (None, None, None, 2 0           res4a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, None, None, 2 589824      padding4a_branch2b[0][0]         
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
res4a_branch2b_relu (Activation (None, None, None, 2 0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
res4a_branch2c (Conv2D)         (None, None, None, 1 262144      res4a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, None, None, 1 524288      res3d_relu[0][0]                 
__________________________________________________________________________________________________
bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              
__________________________________________________________________________________________________
res4a (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
res4a_relu (Activation)         (None, None, None, 1 0           res4a[0][0]                      
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, None, None, 2 262144      res4a_relu[0][0]                 
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
res4b_branch2a_relu (Activation (None, None, None, 2 0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
padding4b_branch2b (ZeroPadding (None, None, None, 2 0           res4b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, None, None, 2 589824      padding4b_branch2b[0][0]         
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
res4b_branch2b_relu (Activation (None, None, None, 2 0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
res4b_branch2c (Conv2D)         (None, None, None, 1 262144      res4b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             
__________________________________________________________________________________________________
res4b (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              
                                                                 res4a_relu[0][0]                 
__________________________________________________________________________________________________
res4b_relu (Activation)         (None, None, None, 1 0           res4b[0][0]                      
__________________________________________________________________________________________________
res4c_branch2a (Conv2D)         (None, None, None, 2 262144      res4b_relu[0][0]                 
__________________________________________________________________________________________________
bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             
__________________________________________________________________________________________________
res4c_branch2a_relu (Activation (None, None, None, 2 0           bn4c_branch2a[0][0]              
__________________________________________________________________________________________________
padding4c_branch2b (ZeroPadding (None, None, None, 2 0           res4c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4c_branch2b (Conv2D)         (None, None, None, 2 589824      padding4c_branch2b[0][0]         
__________________________________________________________________________________________________
bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             
__________________________________________________________________________________________________
res4c_branch2b_relu (Activation (None, None, None, 2 0           bn4c_branch2b[0][0]              
__________________________________________________________________________________________________
res4c_branch2c (Conv2D)         (None, None, None, 1 262144      res4c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             
__________________________________________________________________________________________________
res4c (Add)                     (None, None, None, 1 0           bn4c_branch2c[0][0]              
                                                                 res4b_relu[0][0]                 
__________________________________________________________________________________________________
res4c_relu (Activation)         (None, None, None, 1 0           res4c[0][0]                      
__________________________________________________________________________________________________
res4d_branch2a (Conv2D)         (None, None, None, 2 262144      res4c_relu[0][0]                 
__________________________________________________________________________________________________
bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             
__________________________________________________________________________________________________
res4d_branch2a_relu (Activation (None, None, None, 2 0           bn4d_branch2a[0][0]              
__________________________________________________________________________________________________
padding4d_branch2b (ZeroPadding (None, None, None, 2 0           res4d_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4d_branch2b (Conv2D)         (None, None, None, 2 589824      padding4d_branch2b[0][0]         
__________________________________________________________________________________________________
bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             
__________________________________________________________________________________________________
res4d_branch2b_relu (Activation (None, None, None, 2 0           bn4d_branch2b[0][0]              
__________________________________________________________________________________________________
res4d_branch2c (Conv2D)         (None, None, None, 1 262144      res4d_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             
__________________________________________________________________________________________________
res4d (Add)                     (None, None, None, 1 0           bn4d_branch2c[0][0]              
                                                                 res4c_relu[0][0]                 
__________________________________________________________________________________________________
res4d_relu (Activation)         (None, None, None, 1 0           res4d[0][0]                      
__________________________________________________________________________________________________
res4e_branch2a (Conv2D)         (None, None, None, 2 262144      res4d_relu[0][0]                 
__________________________________________________________________________________________________
bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             
__________________________________________________________________________________________________
res4e_branch2a_relu (Activation (None, None, None, 2 0           bn4e_branch2a[0][0]              
__________________________________________________________________________________________________
padding4e_branch2b (ZeroPadding (None, None, None, 2 0           res4e_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4e_branch2b (Conv2D)         (None, None, None, 2 589824      padding4e_branch2b[0][0]         
__________________________________________________________________________________________________
bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             
__________________________________________________________________________________________________
res4e_branch2b_relu (Activation (None, None, None, 2 0           bn4e_branch2b[0][0]              
__________________________________________________________________________________________________
res4e_branch2c (Conv2D)         (None, None, None, 1 262144      res4e_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             
__________________________________________________________________________________________________
res4e (Add)                     (None, None, None, 1 0           bn4e_branch2c[0][0]              
                                                                 res4d_relu[0][0]                 
__________________________________________________________________________________________________
res4e_relu (Activation)         (None, None, None, 1 0           res4e[0][0]                      
__________________________________________________________________________________________________
res4f_branch2a (Conv2D)         (None, None, None, 2 262144      res4e_relu[0][0]                 
__________________________________________________________________________________________________
bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             
__________________________________________________________________________________________________
res4f_branch2a_relu (Activation (None, None, None, 2 0           bn4f_branch2a[0][0]              
__________________________________________________________________________________________________
padding4f_branch2b (ZeroPadding (None, None, None, 2 0           res4f_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4f_branch2b (Conv2D)         (None, None, None, 2 589824      padding4f_branch2b[0][0]         
__________________________________________________________________________________________________
bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             
__________________________________________________________________________________________________
res4f_branch2b_relu (Activation (None, None, None, 2 0           bn4f_branch2b[0][0]              
__________________________________________________________________________________________________
res4f_branch2c (Conv2D)         (None, None, None, 1 262144      res4f_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             
__________________________________________________________________________________________________
res4f (Add)                     (None, None, None, 1 0           bn4f_branch2c[0][0]              
                                                                 res4e_relu[0][0]                 
__________________________________________________________________________________________________
res4f_relu (Activation)         (None, None, None, 1 0           res4f[0][0]                      
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, None, None, 5 524288      res4f_relu[0][0]                 
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
res5a_branch2a_relu (Activation (None, None, None, 5 0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
padding5a_branch2b (ZeroPadding (None, None, None, 5 0           res5a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5a_branch2b[0][0]         
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
res5a_branch2b_relu (Activation (None, None, None, 5 0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
res5a_branch2c (Conv2D)         (None, None, None, 2 1048576     res5a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, None, None, 2 2097152     res4f_relu[0][0]                 
__________________________________________________________________________________________________
bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              
__________________________________________________________________________________________________
res5a (Add)                     (None, None, None, 2 0           bn5a_branch2c[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
res5a_relu (Activation)         (None, None, None, 2 0           res5a[0][0]                      
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, None, None, 5 1048576     res5a_relu[0][0]                 
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
res5b_branch2a_relu (Activation (None, None, None, 5 0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
padding5b_branch2b (ZeroPadding (None, None, None, 5 0           res5b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5b_branch2b[0][0]         
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
res5b_branch2b_relu (Activation (None, None, None, 5 0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
res5b_branch2c (Conv2D)         (None, None, None, 2 1048576     res5b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             
__________________________________________________________________________________________________
res5b (Add)                     (None, None, None, 2 0           bn5b_branch2c[0][0]              
                                                                 res5a_relu[0][0]                 
__________________________________________________________________________________________________
res5b_relu (Activation)         (None, None, None, 2 0           res5b[0][0]                      
__________________________________________________________________________________________________
res5c_branch2a (Conv2D)         (None, None, None, 5 1048576     res5b_relu[0][0]                 
__________________________________________________________________________________________________
bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             
__________________________________________________________________________________________________
res5c_branch2a_relu (Activation (None, None, None, 5 0           bn5c_branch2a[0][0]              
__________________________________________________________________________________________________
padding5c_branch2b (ZeroPadding (None, None, None, 5 0           res5c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res5c_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5c_branch2b[0][0]         
__________________________________________________________________________________________________
bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             
__________________________________________________________________________________________________
res5c_branch2b_relu (Activation (None, None, None, 5 0           bn5c_branch2b[0][0]              
__________________________________________________________________________________________________
res5c_branch2c (Conv2D)         (None, None, None, 2 1048576     res5c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             
__________________________________________________________________________________________________
res5c (Add)                     (None, None, None, 2 0           bn5c_branch2c[0][0]              
                                                                 res5b_relu[0][0]                 
__________________________________________________________________________________________________
res5c_relu (Activation)         (None, None, None, 2 0           res5c[0][0]                      
__________________________________________________________________________________________________
C5_reduced (Conv2D)             (None, None, None, 2 524544      res5c_relu[0][0]                 
__________________________________________________________________________________________________
P5_upsampled (UpsampleLike)     (None, None, None, 2 0           C5_reduced[0][0]                 
                                                                 res4f_relu[0][0]                 
__________________________________________________________________________________________________
C4_reduced (Conv2D)             (None, None, None, 2 262400      res4f_relu[0][0]                 
__________________________________________________________________________________________________
P4_merged (Add)                 (None, None, None, 2 0           P5_upsampled[0][0]               
                                                                 C4_reduced[0][0]                 
__________________________________________________________________________________________________
P4_upsampled (UpsampleLike)     (None, None, None, 2 0           P4_merged[0][0]                  
                                                                 res3d_relu[0][0]                 
__________________________________________________________________________________________________
C3_reduced (Conv2D)             (None, None, None, 2 131328      res3d_relu[0][0]                 
__________________________________________________________________________________________________
P6 (Conv2D)                     (None, None, None, 2 4718848     res5c_relu[0][0]                 
__________________________________________________________________________________________________
P3_merged (Add)                 (None, None, None, 2 0           P4_upsampled[0][0]               
                                                                 C3_reduced[0][0]                 
__________________________________________________________________________________________________
C6_relu (Activation)            (None, None, None, 2 0           P6[0][0]                         
__________________________________________________________________________________________________
P3 (Conv2D)                     (None, None, None, 2 590080      P3_merged[0][0]                  
__________________________________________________________________________________________________
P4 (Conv2D)                     (None, None, None, 2 590080      P4_merged[0][0]                  
__________________________________________________________________________________________________
P5 (Conv2D)                     (None, None, None, 2 590080      C5_reduced[0][0]                 
__________________________________________________________________________________________________
P7 (Conv2D)                     (None, None, None, 2 590080      C6_relu[0][0]                    
__________________________________________________________________________________________________
regression_submodel (Model)     (None, None, 4)      2443300     P3[0][0]                         
                                                                 P4[0][0]                         
                                                                 P5[0][0]                         
                                                                 P6[0][0]                         
                                                                 P7[0][0]                         
__________________________________________________________________________________________________
classification_submodel (Model) (None, None, 1)      2381065     P3[0][0]                         
                                                                 P4[0][0]                         
                                                                 P5[0][0]                         
                                                                 P6[0][0]                         
                                                                 P7[0][0]                         
__________________________________________________________________________________________________
regression (Concatenate)        (None, None, 4)      0           regression_submodel[1][0]        
                                                                 regression_submodel[2][0]        
                                                                 regression_submodel[3][0]        
                                                                 regression_submodel[4][0]        
                                                                 regression_submodel[5][0]        
__________________________________________________________________________________________________
classification (Concatenate)    (None, None, 1)      0           classification_submodel[1][0]    
                                                                 classification_submodel[2][0]    
                                                                 classification_submodel[3][0]    
                                                                 classification_submodel[4][0]    
                                                                 classification_submodel[5][0]    
==================================================================================================
Total params: 36,382,957
Trainable params: 36,276,717
Non-trainable params: 106,240
__________________________________________________________________________________________________
None
Epoch 1/8

  1/500 [..............................] - ETA: 54:56 - loss: 3.7666 - regression_loss: 3.1227 - classification_loss: 0.6438
  2/500 [..............................] - ETA: 29:19 - loss: 3.2174 - regression_loss: 2.7454 - classification_loss: 0.4719
  3/500 [..............................] - ETA: 20:47 - loss: 2.9248 - regression_loss: 2.4961 - classification_loss: 0.4287
  4/500 [..............................] - ETA: 16:31 - loss: 2.7411 - regression_loss: 2.3542 - classification_loss: 0.3869
  5/500 [..............................] - ETA: 13:56 - loss: 2.5147 - regression_loss: 2.1732 - classification_loss: 0.3415
  6/500 [..............................] - ETA: 12:14 - loss: 2.5104 - regression_loss: 2.1772 - classification_loss: 0.3331
  7/500 [..............................] - ETA: 11:00 - loss: 2.4429 - regression_loss: 2.1095 - classification_loss: 0.3334
  8/500 [..............................] - ETA: 10:05 - loss: 2.3828 - regression_loss: 2.0598 - classification_loss: 0.3229
  9/500 [..............................] - ETA: 9:22 - loss: 2.4722 - regression_loss: 2.1191 - classification_loss: 0.3530 
 10/500 [..............................] - ETA: 8:48 - loss: 2.3531 - regression_loss: 2.0230 - classification_loss: 0.3301
 11/500 [..............................] - ETA: 8:19 - loss: 2.2415 - regression_loss: 1.9319 - classification_loss: 0.3096
 12/500 [..............................] - ETA: 7:55 - loss: 2.3014 - regression_loss: 1.9705 - classification_loss: 0.3308
 13/500 [..............................] - ETA: 7:35 - loss: 2.3027 - regression_loss: 1.9757 - classification_loss: 0.3270
 14/500 [..............................] - ETA: 7:18 - loss: 2.2717 - regression_loss: 1.9439 - classification_loss: 0.3279
 15/500 [..............................] - ETA: 7:03 - loss: 2.2461 - regression_loss: 1.9241 - classification_loss: 0.3220
 16/500 [..............................] - ETA: 6:49 - loss: 2.2190 - regression_loss: 1.8974 - classification_loss: 0.3216
 17/500 [>.............................] - ETA: 6:38 - loss: 2.2215 - regression_loss: 1.9034 - classification_loss: 0.3181
 18/500 [>.............................] - ETA: 6:27 - loss: 2.1488 - regression_loss: 1.8429 - classification_loss: 0.3059
 19/500 [>.............................] - ETA: 6:18 - loss: 2.1770 - regression_loss: 1.8620 - classification_loss: 0.3150
 20/500 [>.............................] - ETA: 6:09 - loss: 2.1694 - regression_loss: 1.8575 - classification_loss: 0.3119
 21/500 [>.............................] - ETA: 6:02 - loss: 2.1446 - regression_loss: 1.8342 - classification_loss: 0.3103
 22/500 [>.............................] - ETA: 5:54 - loss: 2.0972 - regression_loss: 1.7966 - classification_loss: 0.3006
 23/500 [>.............................] - ETA: 5:48 - loss: 2.1114 - regression_loss: 1.8039 - classification_loss: 0.3074
 24/500 [>.............................] - ETA: 5:42 - loss: 2.0951 - regression_loss: 1.7915 - classification_loss: 0.3036
 25/500 [>.............................] - ETA: 5:36 - loss: 2.0985 - regression_loss: 1.7968 - classification_loss: 0.3017
 26/500 [>.............................] - ETA: 5:31 - loss: 2.1045 - regression_loss: 1.7982 - classification_loss: 0.3063
 27/500 [>.............................] - ETA: 5:26 - loss: 2.0814 - regression_loss: 1.7773 - classification_loss: 0.3041
 28/500 [>.............................] - ETA: 5:22 - loss: 2.0456 - regression_loss: 1.7489 - classification_loss: 0.2967
 29/500 [>.............................] - ETA: 5:18 - loss: 2.0307 - regression_loss: 1.7371 - classification_loss: 0.2935
 30/500 [>.............................] - ETA: 5:14 - loss: 2.0343 - regression_loss: 1.7419 - classification_loss: 0.2923
 31/500 [>.............................] - ETA: 5:10 - loss: 2.0372 - regression_loss: 1.7460 - classification_loss: 0.2912
 32/500 [>.............................] - ETA: 5:06 - loss: 2.0288 - regression_loss: 1.7397 - classification_loss: 0.2892
 33/500 [>.............................] - ETA: 5:03 - loss: 2.0324 - regression_loss: 1.7411 - classification_loss: 0.2913
 34/500 [=>............................] - ETA: 5:00 - loss: 2.0120 - regression_loss: 1.7227 - classification_loss: 0.2893
 35/500 [=>............................] - ETA: 4:57 - loss: 1.9805 - regression_loss: 1.6967 - classification_loss: 0.2838
 36/500 [=>............................] - ETA: 4:54 - loss: 1.9814 - regression_loss: 1.6961 - classification_loss: 0.2852
 37/500 [=>............................] - ETA: 4:51 - loss: 1.9683 - regression_loss: 1.6859 - classification_loss: 0.2824
 38/500 [=>............................] - ETA: 4:48 - loss: 1.9374 - regression_loss: 1.6600 - classification_loss: 0.2774
 39/500 [=>............................] - ETA: 4:46 - loss: 1.9249 - regression_loss: 1.6483 - classification_loss: 0.2765
 40/500 [=>............................] - ETA: 4:43 - loss: 1.9273 - regression_loss: 1.6516 - classification_loss: 0.2757
 41/500 [=>............................] - ETA: 4:41 - loss: 1.9152 - regression_loss: 1.6421 - classification_loss: 0.2731
 42/500 [=>............................] - ETA: 4:39 - loss: 1.8859 - regression_loss: 1.6173 - classification_loss: 0.2686
 43/500 [=>............................] - ETA: 4:36 - loss: 1.8697 - regression_loss: 1.6025 - classification_loss: 0.2672
 44/500 [=>............................] - ETA: 4:34 - loss: 1.8648 - regression_loss: 1.5972 - classification_loss: 0.2676
 45/500 [=>............................] - ETA: 4:32 - loss: 1.8672 - regression_loss: 1.6003 - classification_loss: 0.2669
 46/500 [=>............................] - ETA: 4:30 - loss: 1.8394 - regression_loss: 1.5766 - classification_loss: 0.2629
 47/500 [=>............................] - ETA: 4:28 - loss: 1.8282 - regression_loss: 1.5661 - classification_loss: 0.2621
 48/500 [=>............................] - ETA: 4:27 - loss: 1.8232 - regression_loss: 1.5626 - classification_loss: 0.2606
 49/500 [=>............................] - ETA: 4:25 - loss: 1.8251 - regression_loss: 1.5651 - classification_loss: 0.2600
 50/500 [==>...........................] - ETA: 4:23 - loss: 1.8170 - regression_loss: 1.5572 - classification_loss: 0.2599
 51/500 [==>...........................] - ETA: 4:22 - loss: 1.8241 - regression_loss: 1.5640 - classification_loss: 0.2601
 52/500 [==>...........................] - ETA: 4:20 - loss: 1.8198 - regression_loss: 1.5596 - classification_loss: 0.2602
 53/500 [==>...........................] - ETA: 4:18 - loss: 1.7953 - regression_loss: 1.5385 - classification_loss: 0.2568
 54/500 [==>...........................] - ETA: 4:17 - loss: 1.7908 - regression_loss: 1.5354 - classification_loss: 0.2555
 55/500 [==>...........................] - ETA: 4:15 - loss: 1.7777 - regression_loss: 1.5235 - classification_loss: 0.2542
 56/500 [==>...........................] - ETA: 4:14 - loss: 1.7669 - regression_loss: 1.5136 - classification_loss: 0.2533
 57/500 [==>...........................] - ETA: 4:13 - loss: 1.7679 - regression_loss: 1.5151 - classification_loss: 0.2528
 58/500 [==>...........................] - ETA: 4:11 - loss: 1.7444 - regression_loss: 1.4946 - classification_loss: 0.2497
 59/500 [==>...........................] - ETA: 4:10 - loss: 1.7380 - regression_loss: 1.4887 - classification_loss: 0.2493
 60/500 [==>...........................] - ETA: 4:08 - loss: 1.7330 - regression_loss: 1.4849 - classification_loss: 0.2481
 61/500 [==>...........................] - ETA: 4:07 - loss: 1.7338 - regression_loss: 1.4862 - classification_loss: 0.2476
 62/500 [==>...........................] - ETA: 4:06 - loss: 1.7281 - regression_loss: 1.4818 - classification_loss: 0.2462
 63/500 [==>...........................] - ETA: 4:05 - loss: 1.7174 - regression_loss: 1.4718 - classification_loss: 0.2456
 64/500 [==>...........................] - ETA: 4:03 - loss: 1.6968 - regression_loss: 1.4540 - classification_loss: 0.2428
 65/500 [==>...........................] - ETA: 4:02 - loss: 1.6862 - regression_loss: 1.4444 - classification_loss: 0.2419
 66/500 [==>...........................] - ETA: 4:01 - loss: 1.6776 - regression_loss: 1.4364 - classification_loss: 0.2412
 67/500 [===>..........................] - ETA: 4:00 - loss: 1.6846 - regression_loss: 1.4429 - classification_loss: 0.2416
 68/500 [===>..........................] - ETA: 3:59 - loss: 1.6730 - regression_loss: 1.4336 - classification_loss: 0.2393
 69/500 [===>..........................] - ETA: 3:58 - loss: 1.6673 - regression_loss: 1.4292 - classification_loss: 0.2381
 70/500 [===>..........................] - ETA: 3:57 - loss: 1.6581 - regression_loss: 1.4207 - classification_loss: 0.2374
 71/500 [===>..........................] - ETA: 3:56 - loss: 1.6456 - regression_loss: 1.4104 - classification_loss: 0.2352
 72/500 [===>..........................] - ETA: 3:54 - loss: 1.6345 - regression_loss: 1.4002 - classification_loss: 0.2343
 73/500 [===>..........................] - ETA: 3:53 - loss: 1.6353 - regression_loss: 1.4014 - classification_loss: 0.2339
 74/500 [===>..........................] - ETA: 3:52 - loss: 1.6296 - regression_loss: 1.3968 - classification_loss: 0.2328
 75/500 [===>..........................] - ETA: 3:51 - loss: 1.6212 - regression_loss: 1.3890 - classification_loss: 0.2321
 76/500 [===>..........................] - ETA: 3:50 - loss: 1.6152 - regression_loss: 1.3842 - classification_loss: 0.2310
 77/500 [===>..........................] - ETA: 3:49 - loss: 1.5998 - regression_loss: 1.3710 - classification_loss: 0.2288
 78/500 [===>..........................] - ETA: 3:49 - loss: 1.5897 - regression_loss: 1.3617 - classification_loss: 0.2280
 79/500 [===>..........................] - ETA: 3:48 - loss: 1.5819 - regression_loss: 1.3545 - classification_loss: 0.2274
 80/500 [===>..........................] - ETA: 3:47 - loss: 1.5827 - regression_loss: 1.3556 - classification_loss: 0.2271
 81/500 [===>..........................] - ETA: 3:46 - loss: 1.5671 - regression_loss: 1.3420 - classification_loss: 0.2251
 82/500 [===>..........................] - ETA: 3:45 - loss: 1.5632 - regression_loss: 1.3393 - classification_loss: 0.2240
 83/500 [===>..........................] - ETA: 3:44 - loss: 1.5554 - regression_loss: 1.3321 - classification_loss: 0.2233
 84/500 [====>.........................] - ETA: 3:43 - loss: 1.5441 - regression_loss: 1.3217 - classification_loss: 0.2223
 85/500 [====>.........................] - ETA: 3:42 - loss: 1.5448 - regression_loss: 1.3227 - classification_loss: 0.2221
 86/500 [====>.........................] - ETA: 3:41 - loss: 1.5408 - regression_loss: 1.3197 - classification_loss: 0.2211
 87/500 [====>.........................] - ETA: 3:40 - loss: 1.5413 - regression_loss: 1.3205 - classification_loss: 0.2208
 88/500 [====>.........................] - ETA: 3:39 - loss: 1.5305 - regression_loss: 1.3113 - classification_loss: 0.2192
 89/500 [====>.........................] - ETA: 3:39 - loss: 1.5227 - regression_loss: 1.3042 - classification_loss: 0.2185
 90/500 [====>.........................] - ETA: 3:38 - loss: 1.5130 - regression_loss: 1.2954 - classification_loss: 0.2176
 91/500 [====>.........................] - ETA: 3:37 - loss: 1.5053 - regression_loss: 1.2883 - classification_loss: 0.2170
 92/500 [====>.........................] - ETA: 3:36 - loss: 1.5001 - regression_loss: 1.2841 - classification_loss: 0.2160
 93/500 [====>.........................] - ETA: 3:35 - loss: 1.5059 - regression_loss: 1.2894 - classification_loss: 0.2165
 94/500 [====>.........................] - ETA: 3:34 - loss: 1.4950 - regression_loss: 1.2794 - classification_loss: 0.2156
 95/500 [====>.........................] - ETA: 3:34 - loss: 1.4834 - regression_loss: 1.2695 - classification_loss: 0.2139
 96/500 [====>.........................] - ETA: 3:33 - loss: 1.4722 - regression_loss: 1.2592 - classification_loss: 0.2130
 97/500 [====>.........................] - ETA: 3:32 - loss: 1.4777 - regression_loss: 1.2643 - classification_loss: 0.2134
 98/500 [====>.........................] - ETA: 3:31 - loss: 1.4730 - regression_loss: 1.2605 - classification_loss: 0.2125
 99/500 [====>.........................] - ETA: 3:31 - loss: 1.4611 - regression_loss: 1.2501 - classification_loss: 0.2110
100/500 [=====>........................] - ETA: 3:30 - loss: 1.4543 - regression_loss: 1.2439 - classification_loss: 0.2104
101/500 [=====>........................] - ETA: 3:29 - loss: 1.4495 - regression_loss: 1.2400 - classification_loss: 0.2095
102/500 [=====>........................] - ETA: 3:28 - loss: 1.4382 - regression_loss: 1.2297 - classification_loss: 0.2086
103/500 [=====>........................] - ETA: 3:27 - loss: 1.4272 - regression_loss: 1.2201 - classification_loss: 0.2072
104/500 [=====>........................] - ETA: 3:27 - loss: 1.4279 - regression_loss: 1.2209 - classification_loss: 0.2070
105/500 [=====>........................] - ETA: 3:26 - loss: 1.4212 - regression_loss: 1.2148 - classification_loss: 0.2064
106/500 [=====>........................] - ETA: 3:25 - loss: 1.4217 - regression_loss: 1.2154 - classification_loss: 0.2063
107/500 [=====>........................] - ETA: 3:25 - loss: 1.4124 - regression_loss: 1.2070 - classification_loss: 0.2054
108/500 [=====>........................] - ETA: 3:24 - loss: 1.4058 - regression_loss: 1.2010 - classification_loss: 0.2048
109/500 [=====>........................] - ETA: 3:23 - loss: 1.3981 - regression_loss: 1.1945 - classification_loss: 0.2035
110/500 [=====>........................] - ETA: 3:22 - loss: 1.3952 - regression_loss: 1.1924 - classification_loss: 0.2028
111/500 [=====>........................] - ETA: 3:22 - loss: 1.3910 - regression_loss: 1.1890 - classification_loss: 0.2020
112/500 [=====>........................] - ETA: 3:21 - loss: 1.3814 - regression_loss: 1.1803 - classification_loss: 0.2011
113/500 [=====>........................] - ETA: 3:20 - loss: 1.3750 - regression_loss: 1.1745 - classification_loss: 0.2006
114/500 [=====>........................] - ETA: 3:19 - loss: 1.3671 - regression_loss: 1.1677 - classification_loss: 0.1994
115/500 [=====>........................] - ETA: 3:19 - loss: 1.3717 - regression_loss: 1.1720 - classification_loss: 0.1997
116/500 [=====>........................] - ETA: 3:18 - loss: 1.3724 - regression_loss: 1.1728 - classification_loss: 0.1996
117/500 [======>.......................] - ETA: 3:17 - loss: 1.3642 - regression_loss: 1.1658 - classification_loss: 0.1984
118/500 [======>.......................] - ETA: 3:17 - loss: 1.3557 - regression_loss: 1.1580 - classification_loss: 0.1977
119/500 [======>.......................] - ETA: 3:16 - loss: 1.3501 - regression_loss: 1.1530 - classification_loss: 0.1971
120/500 [======>.......................] - ETA: 3:15 - loss: 1.3462 - regression_loss: 1.1498 - classification_loss: 0.1964
121/500 [======>.......................] - ETA: 3:15 - loss: 1.3369 - regression_loss: 1.1413 - classification_loss: 0.1956
122/500 [======>.......................] - ETA: 3:14 - loss: 1.3287 - regression_loss: 1.1343 - classification_loss: 0.1945
123/500 [======>.......................] - ETA: 3:13 - loss: 1.3247 - regression_loss: 1.1309 - classification_loss: 0.1938
124/500 [======>.......................] - ETA: 3:13 - loss: 1.3188 - regression_loss: 1.1255 - classification_loss: 0.1933
125/500 [======>.......................] - ETA: 3:12 - loss: 1.3229 - regression_loss: 1.1293 - classification_loss: 0.1936
126/500 [======>.......................] - ETA: 3:11 - loss: 1.3189 - regression_loss: 1.1260 - classification_loss: 0.1929
127/500 [======>.......................] - ETA: 3:11 - loss: 1.3146 - regression_loss: 1.1220 - classification_loss: 0.1926
128/500 [======>.......................] - ETA: 3:10 - loss: 1.3081 - regression_loss: 1.1166 - classification_loss: 0.1915
129/500 [======>.......................] - ETA: 3:09 - loss: 1.2995 - regression_loss: 1.1088 - classification_loss: 0.1907
130/500 [======>.......................] - ETA: 3:09 - loss: 1.3002 - regression_loss: 1.1095 - classification_loss: 0.1907
131/500 [======>.......................] - ETA: 3:08 - loss: 1.2925 - regression_loss: 1.1028 - classification_loss: 0.1897
132/500 [======>.......................] - ETA: 3:07 - loss: 1.2883 - regression_loss: 1.0989 - classification_loss: 0.1893
133/500 [======>.......................] - ETA: 3:07 - loss: 1.2802 - regression_loss: 1.0917 - classification_loss: 0.1886
134/500 [=======>......................] - ETA: 3:06 - loss: 1.2810 - regression_loss: 1.0925 - classification_loss: 0.1885
135/500 [=======>......................] - ETA: 3:06 - loss: 1.2775 - regression_loss: 1.0896 - classification_loss: 0.1879
136/500 [=======>......................] - ETA: 3:05 - loss: 1.2780 - regression_loss: 1.0901 - classification_loss: 0.1878
137/500 [=======>......................] - ETA: 3:04 - loss: 1.2729 - regression_loss: 1.0855 - classification_loss: 0.1874
138/500 [=======>......................] - ETA: 3:04 - loss: 1.2657 - regression_loss: 1.0793 - classification_loss: 0.1864
139/500 [=======>......................] - ETA: 3:03 - loss: 1.2591 - regression_loss: 1.0734 - classification_loss: 0.1857
140/500 [=======>......................] - ETA: 3:02 - loss: 1.2571 - regression_loss: 1.0719 - classification_loss: 0.1852
141/500 [=======>......................] - ETA: 3:02 - loss: 1.2498 - regression_loss: 1.0653 - classification_loss: 0.1845
142/500 [=======>......................] - ETA: 3:01 - loss: 1.2460 - regression_loss: 1.0619 - classification_loss: 0.1842
143/500 [=======>......................] - ETA: 3:01 - loss: 1.2394 - regression_loss: 1.0561 - classification_loss: 0.1833
144/500 [=======>......................] - ETA: 3:00 - loss: 1.2430 - regression_loss: 1.0594 - classification_loss: 0.1836
145/500 [=======>......................] - ETA: 2:59 - loss: 1.2395 - regression_loss: 1.0565 - classification_loss: 0.1830
146/500 [=======>......................] - ETA: 2:59 - loss: 1.2332 - regression_loss: 1.0511 - classification_loss: 0.1821
147/500 [=======>......................] - ETA: 2:58 - loss: 1.2366 - regression_loss: 1.0542 - classification_loss: 0.1824
148/500 [=======>......................] - ETA: 2:58 - loss: 1.2319 - regression_loss: 1.0500 - classification_loss: 0.1819
149/500 [=======>......................] - ETA: 2:57 - loss: 1.2262 - regression_loss: 1.0449 - classification_loss: 0.1813
150/500 [========>.....................] - ETA: 2:56 - loss: 1.2231 - regression_loss: 1.0423 - classification_loss: 0.1808
151/500 [========>.....................] - ETA: 2:56 - loss: 1.2176 - regression_loss: 1.0377 - classification_loss: 0.1800
152/500 [========>.....................] - ETA: 2:55 - loss: 1.2121 - regression_loss: 1.0328 - classification_loss: 0.1794
153/500 [========>.....................] - ETA: 2:55 - loss: 1.2090 - regression_loss: 1.0299 - classification_loss: 0.1790
154/500 [========>.....................] - ETA: 2:54 - loss: 1.2072 - regression_loss: 1.0286 - classification_loss: 0.1786
155/500 [========>.....................] - ETA: 2:53 - loss: 1.2102 - regression_loss: 1.0313 - classification_loss: 0.1789
156/500 [========>.....................] - ETA: 2:53 - loss: 1.2068 - regression_loss: 1.0284 - classification_loss: 0.1783
157/500 [========>.....................] - ETA: 2:52 - loss: 1.2006 - regression_loss: 1.0230 - classification_loss: 0.1776
158/500 [========>.....................] - ETA: 2:52 - loss: 1.1968 - regression_loss: 1.0196 - classification_loss: 0.1773
159/500 [========>.....................] - ETA: 2:51 - loss: 1.1910 - regression_loss: 1.0143 - classification_loss: 0.1767
160/500 [========>.....................] - ETA: 2:50 - loss: 1.1916 - regression_loss: 1.0149 - classification_loss: 0.1767
161/500 [========>.....................] - ETA: 2:50 - loss: 1.1921 - regression_loss: 1.0155 - classification_loss: 0.1766
162/500 [========>.....................] - ETA: 2:49 - loss: 1.1881 - regression_loss: 1.0118 - classification_loss: 0.1763
163/500 [========>.....................] - ETA: 2:49 - loss: 1.1869 - regression_loss: 1.0110 - classification_loss: 0.1758
164/500 [========>.....................] - ETA: 2:48 - loss: 1.1817 - regression_loss: 1.0066 - classification_loss: 0.1751
165/500 [========>.....................] - ETA: 2:48 - loss: 1.1757 - regression_loss: 1.0012 - classification_loss: 0.1746
166/500 [========>.....................] - ETA: 2:47 - loss: 1.1767 - regression_loss: 1.0022 - classification_loss: 0.1745
167/500 [=========>....................] - ETA: 2:46 - loss: 1.1707 - regression_loss: 0.9967 - classification_loss: 0.1739
168/500 [=========>....................] - ETA: 2:46 - loss: 1.1688 - regression_loss: 0.9953 - classification_loss: 0.1735
169/500 [=========>....................] - ETA: 2:45 - loss: 1.1636 - regression_loss: 0.9908 - classification_loss: 0.1728
170/500 [=========>....................] - ETA: 2:45 - loss: 1.1610 - regression_loss: 0.9885 - classification_loss: 0.1725
171/500 [=========>....................] - ETA: 2:44 - loss: 1.1583 - regression_loss: 0.9861 - classification_loss: 0.1722
172/500 [=========>....................] - ETA: 2:44 - loss: 1.1608 - regression_loss: 0.9884 - classification_loss: 0.1724
173/500 [=========>....................] - ETA: 2:43 - loss: 1.1551 - regression_loss: 0.9833 - classification_loss: 0.1719
174/500 [=========>....................] - ETA: 2:42 - loss: 1.1532 - regression_loss: 0.9818 - classification_loss: 0.1715
175/500 [=========>....................] - ETA: 2:42 - loss: 1.1484 - regression_loss: 0.9776 - classification_loss: 0.1708
176/500 [=========>....................] - ETA: 2:41 - loss: 1.1459 - regression_loss: 0.9755 - classification_loss: 0.1703
177/500 [=========>....................] - ETA: 2:41 - loss: 1.1409 - regression_loss: 0.9712 - classification_loss: 0.1697
178/500 [=========>....................] - ETA: 2:40 - loss: 1.1374 - regression_loss: 0.9680 - classification_loss: 0.1693
179/500 [=========>....................] - ETA: 2:40 - loss: 1.1397 - regression_loss: 0.9702 - classification_loss: 0.1695
180/500 [=========>....................] - ETA: 2:39 - loss: 1.1343 - regression_loss: 0.9652 - classification_loss: 0.1690
181/500 [=========>....................] - ETA: 2:38 - loss: 1.1317 - regression_loss: 0.9631 - classification_loss: 0.1686
182/500 [=========>....................] - ETA: 2:38 - loss: 1.1262 - regression_loss: 0.9582 - classification_loss: 0.1681
183/500 [=========>....................] - ETA: 2:37 - loss: 1.1271 - regression_loss: 0.9590 - classification_loss: 0.1681
184/500 [==========>...................] - ETA: 2:37 - loss: 1.1241 - regression_loss: 0.9563 - classification_loss: 0.1678
185/500 [==========>...................] - ETA: 2:36 - loss: 1.1202 - regression_loss: 0.9530 - classification_loss: 0.1672
186/500 [==========>...................] - ETA: 2:36 - loss: 1.1171 - regression_loss: 0.9502 - classification_loss: 0.1669
187/500 [==========>...................] - ETA: 2:35 - loss: 1.1127 - regression_loss: 0.9463 - classification_loss: 0.1665
188/500 [==========>...................] - ETA: 2:35 - loss: 1.1080 - regression_loss: 0.9421 - classification_loss: 0.1658
189/500 [==========>...................] - ETA: 2:34 - loss: 1.1056 - regression_loss: 0.9402 - classification_loss: 0.1655
190/500 [==========>...................] - ETA: 2:33 - loss: 1.1078 - regression_loss: 0.9421 - classification_loss: 0.1656
191/500 [==========>...................] - ETA: 2:33 - loss: 1.1029 - regression_loss: 0.9378 - classification_loss: 0.1651
192/500 [==========>...................] - ETA: 2:32 - loss: 1.1003 - regression_loss: 0.9356 - classification_loss: 0.1647
193/500 [==========>...................] - ETA: 2:32 - loss: 1.0958 - regression_loss: 0.9317 - classification_loss: 0.1641
194/500 [==========>...................] - ETA: 2:31 - loss: 1.0930 - regression_loss: 0.9292 - classification_loss: 0.1638
195/500 [==========>...................] - ETA: 2:31 - loss: 1.0949 - regression_loss: 0.9309 - classification_loss: 0.1640
196/500 [==========>...................] - ETA: 2:30 - loss: 1.0919 - regression_loss: 0.9281 - classification_loss: 0.1637
197/500 [==========>...................] - ETA: 2:30 - loss: 1.0894 - regression_loss: 0.9261 - classification_loss: 0.1633
198/500 [==========>...................] - ETA: 2:29 - loss: 1.0852 - regression_loss: 0.9225 - classification_loss: 0.1628
199/500 [==========>...................] - ETA: 2:29 - loss: 1.0858 - regression_loss: 0.9231 - classification_loss: 0.1628
200/500 [===========>..................] - ETA: 2:28 - loss: 1.0812 - regression_loss: 0.9189 - classification_loss: 0.1623
201/500 [===========>..................] - ETA: 2:27 - loss: 1.0816 - regression_loss: 0.9194 - classification_loss: 0.1623
202/500 [===========>..................] - ETA: 2:27 - loss: 1.0788 - regression_loss: 0.9168 - classification_loss: 0.1620
203/500 [===========>..................] - ETA: 2:26 - loss: 1.0741 - regression_loss: 0.9125 - classification_loss: 0.1615
204/500 [===========>..................] - ETA: 2:26 - loss: 1.0720 - regression_loss: 0.9108 - classification_loss: 0.1612
205/500 [===========>..................] - ETA: 2:25 - loss: 1.0681 - regression_loss: 0.9074 - classification_loss: 0.1607
206/500 [===========>..................] - ETA: 2:25 - loss: 1.0654 - regression_loss: 0.9049 - classification_loss: 0.1605
207/500 [===========>..................] - ETA: 2:24 - loss: 1.0658 - regression_loss: 0.9054 - classification_loss: 0.1604
208/500 [===========>..................] - ETA: 2:24 - loss: 1.0634 - regression_loss: 0.9033 - classification_loss: 0.1601
209/500 [===========>..................] - ETA: 2:23 - loss: 1.0597 - regression_loss: 0.9000 - classification_loss: 0.1597
210/500 [===========>..................] - ETA: 2:23 - loss: 1.0559 - regression_loss: 0.8968 - classification_loss: 0.1591
211/500 [===========>..................] - ETA: 2:22 - loss: 1.0546 - regression_loss: 0.8957 - classification_loss: 0.1588
212/500 [===========>..................] - ETA: 2:22 - loss: 1.0523 - regression_loss: 0.8937 - classification_loss: 0.1586
213/500 [===========>..................] - ETA: 2:21 - loss: 1.0527 - regression_loss: 0.8941 - classification_loss: 0.1586
214/500 [===========>..................] - ETA: 2:21 - loss: 1.0493 - regression_loss: 0.8912 - classification_loss: 0.1581
215/500 [===========>..................] - ETA: 2:20 - loss: 1.0451 - regression_loss: 0.8874 - classification_loss: 0.1576
216/500 [===========>..................] - ETA: 2:19 - loss: 1.0411 - regression_loss: 0.8840 - classification_loss: 0.1571
217/500 [============>.................] - ETA: 2:19 - loss: 1.0386 - regression_loss: 0.8816 - classification_loss: 0.1569
218/500 [============>.................] - ETA: 2:18 - loss: 1.0363 - regression_loss: 0.8797 - classification_loss: 0.1566
219/500 [============>.................] - ETA: 2:18 - loss: 1.0321 - regression_loss: 0.8759 - classification_loss: 0.1562
220/500 [============>.................] - ETA: 2:17 - loss: 1.0337 - regression_loss: 0.8774 - classification_loss: 0.1563
221/500 [============>.................] - ETA: 2:17 - loss: 1.0300 - regression_loss: 0.8742 - classification_loss: 0.1558
222/500 [============>.................] - ETA: 2:16 - loss: 1.0278 - regression_loss: 0.8723 - classification_loss: 0.1555
223/500 [============>.................] - ETA: 2:16 - loss: 1.0251 - regression_loss: 0.8699 - classification_loss: 0.1552
224/500 [============>.................] - ETA: 2:15 - loss: 1.0211 - regression_loss: 0.8663 - classification_loss: 0.1548
225/500 [============>.................] - ETA: 2:15 - loss: 1.0213 - regression_loss: 0.8665 - classification_loss: 0.1548
226/500 [============>.................] - ETA: 2:14 - loss: 1.0215 - regression_loss: 0.8667 - classification_loss: 0.1548
227/500 [============>.................] - ETA: 2:14 - loss: 1.0176 - regression_loss: 0.8632 - classification_loss: 0.1544
228/500 [============>.................] - ETA: 2:13 - loss: 1.0139 - regression_loss: 0.8600 - classification_loss: 0.1539
229/500 [============>.................] - ETA: 2:13 - loss: 1.0119 - regression_loss: 0.8582 - classification_loss: 0.1537
230/500 [============>.................] - ETA: 2:12 - loss: 1.0097 - regression_loss: 0.8563 - classification_loss: 0.1534
231/500 [============>.................] - ETA: 2:12 - loss: 1.0111 - regression_loss: 0.8576 - classification_loss: 0.1535
232/500 [============>.................] - ETA: 2:11 - loss: 1.0077 - regression_loss: 0.8546 - classification_loss: 0.1531
233/500 [============>.................] - ETA: 2:10 - loss: 1.0047 - regression_loss: 0.8520 - classification_loss: 0.1527
234/500 [=============>................] - ETA: 2:10 - loss: 1.0026 - regression_loss: 0.8502 - classification_loss: 0.1524
235/500 [=============>................] - ETA: 2:09 - loss: 1.0002 - regression_loss: 0.8481 - classification_loss: 0.1522
236/500 [=============>................] - ETA: 2:09 - loss: 0.9992 - regression_loss: 0.8473 - classification_loss: 0.1519
237/500 [=============>................] - ETA: 2:08 - loss: 0.9955 - regression_loss: 0.8440 - classification_loss: 0.1515
238/500 [=============>................] - ETA: 2:08 - loss: 0.9927 - regression_loss: 0.8416 - classification_loss: 0.1511
239/500 [=============>................] - ETA: 2:07 - loss: 0.9908 - regression_loss: 0.8400 - classification_loss: 0.1508
240/500 [=============>................] - ETA: 2:07 - loss: 0.9912 - regression_loss: 0.8404 - classification_loss: 0.1508
241/500 [=============>................] - ETA: 2:06 - loss: 0.9892 - regression_loss: 0.8386 - classification_loss: 0.1506
242/500 [=============>................] - ETA: 2:06 - loss: 0.9877 - regression_loss: 0.8374 - classification_loss: 0.1503
243/500 [=============>................] - ETA: 2:05 - loss: 0.9845 - regression_loss: 0.8345 - classification_loss: 0.1500
244/500 [=============>................] - ETA: 2:05 - loss: 0.9847 - regression_loss: 0.8347 - classification_loss: 0.1499
245/500 [=============>................] - ETA: 2:04 - loss: 0.9820 - regression_loss: 0.8325 - classification_loss: 0.1495
246/500 [=============>................] - ETA: 2:04 - loss: 0.9834 - regression_loss: 0.8337 - classification_loss: 0.1496
247/500 [=============>................] - ETA: 2:03 - loss: 0.9823 - regression_loss: 0.8329 - classification_loss: 0.1494
248/500 [=============>................] - ETA: 2:03 - loss: 0.9794 - regression_loss: 0.8304 - classification_loss: 0.1490
249/500 [=============>................] - ETA: 2:02 - loss: 0.9774 - regression_loss: 0.8287 - classification_loss: 0.1488
250/500 [==============>...............] - ETA: 2:02 - loss: 0.9743 - regression_loss: 0.8258 - classification_loss: 0.1484
251/500 [==============>...............] - ETA: 2:01 - loss: 0.9755 - regression_loss: 0.8270 - classification_loss: 0.1485
252/500 [==============>...............] - ETA: 2:01 - loss: 0.9746 - regression_loss: 0.8263 - classification_loss: 0.1483
253/500 [==============>...............] - ETA: 2:00 - loss: 0.9725 - regression_loss: 0.8244 - classification_loss: 0.1481
254/500 [==============>...............] - ETA: 2:00 - loss: 0.9699 - regression_loss: 0.8222 - classification_loss: 0.1477
255/500 [==============>...............] - ETA: 1:59 - loss: 0.9666 - regression_loss: 0.8193 - classification_loss: 0.1473
256/500 [==============>...............] - ETA: 1:59 - loss: 0.9633 - regression_loss: 0.8163 - classification_loss: 0.1470
257/500 [==============>...............] - ETA: 1:58 - loss: 0.9613 - regression_loss: 0.8145 - classification_loss: 0.1468
258/500 [==============>...............] - ETA: 1:58 - loss: 0.9582 - regression_loss: 0.8117 - classification_loss: 0.1464
259/500 [==============>...............] - ETA: 1:57 - loss: 0.9563 - regression_loss: 0.8101 - classification_loss: 0.1461
260/500 [==============>...............] - ETA: 1:57 - loss: 0.9573 - regression_loss: 0.8111 - classification_loss: 0.1462
261/500 [==============>...............] - ETA: 1:56 - loss: 0.9542 - regression_loss: 0.8083 - classification_loss: 0.1458
262/500 [==============>...............] - ETA: 1:56 - loss: 0.9512 - regression_loss: 0.8057 - classification_loss: 0.1455
263/500 [==============>...............] - ETA: 1:55 - loss: 0.9493 - regression_loss: 0.8040 - classification_loss: 0.1453
264/500 [==============>...............] - ETA: 1:55 - loss: 0.9503 - regression_loss: 0.8049 - classification_loss: 0.1454
265/500 [==============>...............] - ETA: 1:54 - loss: 0.9492 - regression_loss: 0.8041 - classification_loss: 0.1451
266/500 [==============>...............] - ETA: 1:53 - loss: 0.9471 - regression_loss: 0.8022 - classification_loss: 0.1449
267/500 [===============>..............] - ETA: 1:53 - loss: 0.9450 - regression_loss: 0.8004 - classification_loss: 0.1446
268/500 [===============>..............] - ETA: 1:52 - loss: 0.9430 - regression_loss: 0.7987 - classification_loss: 0.1443
269/500 [===============>..............] - ETA: 1:52 - loss: 0.9438 - regression_loss: 0.7995 - classification_loss: 0.1444
270/500 [===============>..............] - ETA: 1:51 - loss: 0.9421 - regression_loss: 0.7980 - classification_loss: 0.1441
271/500 [===============>..............] - ETA: 1:51 - loss: 0.9391 - regression_loss: 0.7953 - classification_loss: 0.1438
272/500 [===============>..............] - ETA: 1:50 - loss: 0.9372 - regression_loss: 0.7936 - classification_loss: 0.1436
273/500 [===============>..............] - ETA: 1:50 - loss: 0.9373 - regression_loss: 0.7938 - classification_loss: 0.1436
274/500 [===============>..............] - ETA: 1:49 - loss: 0.9364 - regression_loss: 0.7931 - classification_loss: 0.1434
275/500 [===============>..............] - ETA: 1:49 - loss: 0.9336 - regression_loss: 0.7906 - classification_loss: 0.1430
276/500 [===============>..............] - ETA: 1:48 - loss: 0.9319 - regression_loss: 0.7891 - classification_loss: 0.1427
277/500 [===============>..............] - ETA: 1:48 - loss: 0.9298 - regression_loss: 0.7873 - classification_loss: 0.1425
278/500 [===============>..............] - ETA: 1:47 - loss: 0.9268 - regression_loss: 0.7846 - classification_loss: 0.1422
279/500 [===============>..............] - ETA: 1:47 - loss: 0.9241 - regression_loss: 0.7823 - classification_loss: 0.1419
280/500 [===============>..............] - ETA: 1:46 - loss: 0.9244 - regression_loss: 0.7825 - classification_loss: 0.1419
281/500 [===============>..............] - ETA: 1:46 - loss: 0.9215 - regression_loss: 0.7800 - classification_loss: 0.1415
282/500 [===============>..............] - ETA: 1:45 - loss: 0.9197 - regression_loss: 0.7784 - classification_loss: 0.1413
283/500 [===============>..............] - ETA: 1:45 - loss: 0.9198 - regression_loss: 0.7785 - classification_loss: 0.1413
284/500 [================>.............] - ETA: 1:44 - loss: 0.9187 - regression_loss: 0.7776 - classification_loss: 0.1411
285/500 [================>.............] - ETA: 1:44 - loss: 0.9162 - regression_loss: 0.7754 - classification_loss: 0.1408
286/500 [================>.............] - ETA: 1:43 - loss: 0.9145 - regression_loss: 0.7740 - classification_loss: 0.1405
287/500 [================>.............] - ETA: 1:43 - loss: 0.9122 - regression_loss: 0.7720 - classification_loss: 0.1402
288/500 [================>.............] - ETA: 1:42 - loss: 0.9131 - regression_loss: 0.7728 - classification_loss: 0.1403
289/500 [================>.............] - ETA: 1:42 - loss: 0.9105 - regression_loss: 0.7705 - classification_loss: 0.1400
290/500 [================>.............] - ETA: 1:41 - loss: 0.9087 - regression_loss: 0.7689 - classification_loss: 0.1398
291/500 [================>.............] - ETA: 1:41 - loss: 0.9070 - regression_loss: 0.7674 - classification_loss: 0.1396
292/500 [================>.............] - ETA: 1:40 - loss: 0.9071 - regression_loss: 0.7675 - classification_loss: 0.1396
293/500 [================>.............] - ETA: 1:40 - loss: 0.9059 - regression_loss: 0.7665 - classification_loss: 0.1394
294/500 [================>.............] - ETA: 1:39 - loss: 0.9035 - regression_loss: 0.7644 - classification_loss: 0.1391
295/500 [================>.............] - ETA: 1:39 - loss: 0.9016 - regression_loss: 0.7628 - classification_loss: 0.1388
296/500 [================>.............] - ETA: 1:38 - loss: 0.9007 - regression_loss: 0.7621 - classification_loss: 0.1386
297/500 [================>.............] - ETA: 1:38 - loss: 0.8979 - regression_loss: 0.7596 - classification_loss: 0.1383
298/500 [================>.............] - ETA: 1:37 - loss: 0.8966 - regression_loss: 0.7584 - classification_loss: 0.1381
299/500 [================>.............] - ETA: 1:37 - loss: 0.8942 - regression_loss: 0.7564 - classification_loss: 0.1378
300/500 [=================>............] - ETA: 1:36 - loss: 0.8944 - regression_loss: 0.7566 - classification_loss: 0.1378
301/500 [=================>............] - ETA: 1:36 - loss: 0.8927 - regression_loss: 0.7551 - classification_loss: 0.1376
302/500 [=================>............] - ETA: 1:35 - loss: 0.8920 - regression_loss: 0.7545 - classification_loss: 0.1374
303/500 [=================>............] - ETA: 1:35 - loss: 0.8926 - regression_loss: 0.7551 - classification_loss: 0.1375
304/500 [=================>............] - ETA: 1:34 - loss: 0.8905 - regression_loss: 0.7533 - classification_loss: 0.1372
305/500 [=================>............] - ETA: 1:34 - loss: 0.8885 - regression_loss: 0.7516 - classification_loss: 0.1369
306/500 [=================>............] - ETA: 1:33 - loss: 0.8861 - regression_loss: 0.7495 - classification_loss: 0.1366
307/500 [=================>............] - ETA: 1:33 - loss: 0.8846 - regression_loss: 0.7483 - classification_loss: 0.1364
308/500 [=================>............] - ETA: 1:32 - loss: 0.8847 - regression_loss: 0.7484 - classification_loss: 0.1364
309/500 [=================>............] - ETA: 1:32 - loss: 0.8825 - regression_loss: 0.7464 - classification_loss: 0.1361
310/500 [=================>............] - ETA: 1:31 - loss: 0.8810 - regression_loss: 0.7451 - classification_loss: 0.1359
311/500 [=================>............] - ETA: 1:31 - loss: 0.8810 - regression_loss: 0.7451 - classification_loss: 0.1359
312/500 [=================>............] - ETA: 1:30 - loss: 0.8799 - regression_loss: 0.7443 - classification_loss: 0.1356
313/500 [=================>............] - ETA: 1:30 - loss: 0.8779 - regression_loss: 0.7425 - classification_loss: 0.1353
314/500 [=================>............] - ETA: 1:29 - loss: 0.8762 - regression_loss: 0.7411 - classification_loss: 0.1352
315/500 [=================>............] - ETA: 1:29 - loss: 0.8753 - regression_loss: 0.7404 - classification_loss: 0.1350
316/500 [=================>............] - ETA: 1:29 - loss: 0.8730 - regression_loss: 0.7383 - classification_loss: 0.1347
317/500 [==================>...........] - ETA: 1:28 - loss: 0.8713 - regression_loss: 0.7368 - classification_loss: 0.1345
318/500 [==================>...........] - ETA: 1:28 - loss: 0.8699 - regression_loss: 0.7356 - classification_loss: 0.1343
319/500 [==================>...........] - ETA: 1:27 - loss: 0.8701 - regression_loss: 0.7358 - classification_loss: 0.1343
320/500 [==================>...........] - ETA: 1:27 - loss: 0.8680 - regression_loss: 0.7340 - classification_loss: 0.1340
321/500 [==================>...........] - ETA: 1:26 - loss: 0.8659 - regression_loss: 0.7322 - classification_loss: 0.1337
322/500 [==================>...........] - ETA: 1:26 - loss: 0.8649 - regression_loss: 0.7314 - classification_loss: 0.1335
323/500 [==================>...........] - ETA: 1:25 - loss: 0.8651 - regression_loss: 0.7316 - classification_loss: 0.1335
324/500 [==================>...........] - ETA: 1:25 - loss: 0.8633 - regression_loss: 0.7300 - classification_loss: 0.1333
325/500 [==================>...........] - ETA: 1:24 - loss: 0.8625 - regression_loss: 0.7294 - classification_loss: 0.1331
326/500 [==================>...........] - ETA: 1:24 - loss: 0.8613 - regression_loss: 0.7284 - classification_loss: 0.1329
327/500 [==================>...........] - ETA: 1:23 - loss: 0.8595 - regression_loss: 0.7268 - classification_loss: 0.1326
328/500 [==================>...........] - ETA: 1:23 - loss: 0.8574 - regression_loss: 0.7251 - classification_loss: 0.1324
329/500 [==================>...........] - ETA: 1:22 - loss: 0.8575 - regression_loss: 0.7251 - classification_loss: 0.1324
330/500 [==================>...........] - ETA: 1:22 - loss: 0.8562 - regression_loss: 0.7240 - classification_loss: 0.1321
331/500 [==================>...........] - ETA: 1:21 - loss: 0.8563 - regression_loss: 0.7241 - classification_loss: 0.1321
332/500 [==================>...........] - ETA: 1:21 - loss: 0.8541 - regression_loss: 0.7223 - classification_loss: 0.1319
333/500 [==================>...........] - ETA: 1:20 - loss: 0.8528 - regression_loss: 0.7211 - classification_loss: 0.1317
334/500 [===================>..........] - ETA: 1:20 - loss: 0.8508 - regression_loss: 0.7193 - classification_loss: 0.1314
335/500 [===================>..........] - ETA: 1:19 - loss: 0.8500 - regression_loss: 0.7187 - classification_loss: 0.1312
336/500 [===================>..........] - ETA: 1:19 - loss: 0.8480 - regression_loss: 0.7170 - classification_loss: 0.1310
337/500 [===================>..........] - ETA: 1:18 - loss: 0.8466 - regression_loss: 0.7158 - classification_loss: 0.1308
338/500 [===================>..........] - ETA: 1:18 - loss: 0.8446 - regression_loss: 0.7141 - classification_loss: 0.1305
339/500 [===================>..........] - ETA: 1:17 - loss: 0.8453 - regression_loss: 0.7147 - classification_loss: 0.1306
340/500 [===================>..........] - ETA: 1:17 - loss: 0.8441 - regression_loss: 0.7136 - classification_loss: 0.1305
341/500 [===================>..........] - ETA: 1:16 - loss: 0.8428 - regression_loss: 0.7125 - classification_loss: 0.1303
342/500 [===================>..........] - ETA: 1:16 - loss: 0.8408 - regression_loss: 0.7108 - classification_loss: 0.1300
343/500 [===================>..........] - ETA: 1:15 - loss: 0.8387 - regression_loss: 0.7090 - classification_loss: 0.1297
344/500 [===================>..........] - ETA: 1:15 - loss: 0.8387 - regression_loss: 0.7090 - classification_loss: 0.1297
345/500 [===================>..........] - ETA: 1:14 - loss: 0.8373 - regression_loss: 0.7077 - classification_loss: 0.1296
346/500 [===================>..........] - ETA: 1:14 - loss: 0.8353 - regression_loss: 0.7059 - classification_loss: 0.1293
347/500 [===================>..........] - ETA: 1:13 - loss: 0.8330 - regression_loss: 0.7040 - classification_loss: 0.1291
348/500 [===================>..........] - ETA: 1:13 - loss: 0.8336 - regression_loss: 0.7045 - classification_loss: 0.1291
349/500 [===================>..........] - ETA: 1:12 - loss: 0.8323 - regression_loss: 0.7034 - classification_loss: 0.1290
350/500 [====================>.........] - ETA: 1:12 - loss: 0.8311 - regression_loss: 0.7023 - classification_loss: 0.1288
351/500 [====================>.........] - ETA: 1:11 - loss: 0.8297 - regression_loss: 0.7011 - classification_loss: 0.1286
352/500 [====================>.........] - ETA: 1:11 - loss: 0.8288 - regression_loss: 0.7004 - classification_loss: 0.1285
353/500 [====================>.........] - ETA: 1:10 - loss: 0.8271 - regression_loss: 0.6989 - classification_loss: 0.1282
354/500 [====================>.........] - ETA: 1:10 - loss: 0.8277 - regression_loss: 0.6994 - classification_loss: 0.1283
355/500 [====================>.........] - ETA: 1:09 - loss: 0.8256 - regression_loss: 0.6976 - classification_loss: 0.1280
356/500 [====================>.........] - ETA: 1:09 - loss: 0.8236 - regression_loss: 0.6958 - classification_loss: 0.1278
357/500 [====================>.........] - ETA: 1:08 - loss: 0.8226 - regression_loss: 0.6950 - classification_loss: 0.1276
358/500 [====================>.........] - ETA: 1:08 - loss: 0.8208 - regression_loss: 0.6934 - classification_loss: 0.1273
359/500 [====================>.........] - ETA: 1:07 - loss: 0.8195 - regression_loss: 0.6923 - classification_loss: 0.1272
360/500 [====================>.........] - ETA: 1:07 - loss: 0.8195 - regression_loss: 0.6923 - classification_loss: 0.1272
361/500 [====================>.........] - ETA: 1:06 - loss: 0.8176 - regression_loss: 0.6906 - classification_loss: 0.1269
362/500 [====================>.........] - ETA: 1:06 - loss: 0.8167 - regression_loss: 0.6900 - classification_loss: 0.1268
363/500 [====================>.........] - ETA: 1:05 - loss: 0.8153 - regression_loss: 0.6887 - classification_loss: 0.1266
364/500 [====================>.........] - ETA: 1:05 - loss: 0.8144 - regression_loss: 0.6880 - classification_loss: 0.1264
365/500 [====================>.........] - ETA: 1:04 - loss: 0.8144 - regression_loss: 0.6880 - classification_loss: 0.1264
366/500 [====================>.........] - ETA: 1:04 - loss: 0.8129 - regression_loss: 0.6868 - classification_loss: 0.1261
367/500 [=====================>........] - ETA: 1:03 - loss: 0.8121 - regression_loss: 0.6861 - classification_loss: 0.1260
368/500 [=====================>........] - ETA: 1:03 - loss: 0.8104 - regression_loss: 0.6847 - classification_loss: 0.1257
369/500 [=====================>........] - ETA: 1:03 - loss: 0.8092 - regression_loss: 0.6837 - classification_loss: 0.1256
370/500 [=====================>........] - ETA: 1:02 - loss: 0.8092 - regression_loss: 0.6836 - classification_loss: 0.1256
371/500 [=====================>........] - ETA: 1:02 - loss: 0.8079 - regression_loss: 0.6824 - classification_loss: 0.1254
372/500 [=====================>........] - ETA: 1:01 - loss: 0.8066 - regression_loss: 0.6814 - classification_loss: 0.1252
373/500 [=====================>........] - ETA: 1:01 - loss: 0.8065 - regression_loss: 0.6813 - classification_loss: 0.1252
374/500 [=====================>........] - ETA: 1:00 - loss: 0.8055 - regression_loss: 0.6805 - classification_loss: 0.1250
375/500 [=====================>........] - ETA: 1:00 - loss: 0.8035 - regression_loss: 0.6787 - classification_loss: 0.1248
376/500 [=====================>........] - ETA: 59s - loss: 0.8024 - regression_loss: 0.6778 - classification_loss: 0.1246 
377/500 [=====================>........] - ETA: 59s - loss: 0.8007 - regression_loss: 0.6763 - classification_loss: 0.1244
378/500 [=====================>........] - ETA: 58s - loss: 0.8011 - regression_loss: 0.6767 - classification_loss: 0.1244
379/500 [=====================>........] - ETA: 58s - loss: 0.7992 - regression_loss: 0.6750 - classification_loss: 0.1242
380/500 [=====================>........] - ETA: 57s - loss: 0.7979 - regression_loss: 0.6738 - classification_loss: 0.1240
381/500 [=====================>........] - ETA: 57s - loss: 0.7967 - regression_loss: 0.6728 - classification_loss: 0.1239
382/500 [=====================>........] - ETA: 56s - loss: 0.7948 - regression_loss: 0.6711 - classification_loss: 0.1237
383/500 [=====================>........] - ETA: 56s - loss: 0.7940 - regression_loss: 0.6705 - classification_loss: 0.1235
384/500 [======================>.......] - ETA: 55s - loss: 0.7945 - regression_loss: 0.6709 - classification_loss: 0.1236
385/500 [======================>.......] - ETA: 55s - loss: 0.7932 - regression_loss: 0.6698 - classification_loss: 0.1233
386/500 [======================>.......] - ETA: 54s - loss: 0.7923 - regression_loss: 0.6691 - classification_loss: 0.1232
387/500 [======================>.......] - ETA: 54s - loss: 0.7905 - regression_loss: 0.6675 - classification_loss: 0.1230
388/500 [======================>.......] - ETA: 53s - loss: 0.7895 - regression_loss: 0.6667 - classification_loss: 0.1228
389/500 [======================>.......] - ETA: 53s - loss: 0.7894 - regression_loss: 0.6666 - classification_loss: 0.1228
390/500 [======================>.......] - ETA: 52s - loss: 0.7877 - regression_loss: 0.6652 - classification_loss: 0.1226
391/500 [======================>.......] - ETA: 52s - loss: 0.7865 - regression_loss: 0.6641 - classification_loss: 0.1224
392/500 [======================>.......] - ETA: 51s - loss: 0.7850 - regression_loss: 0.6628 - classification_loss: 0.1222
393/500 [======================>.......] - ETA: 51s - loss: 0.7842 - regression_loss: 0.6621 - classification_loss: 0.1221
394/500 [======================>.......] - ETA: 50s - loss: 0.7846 - regression_loss: 0.6625 - classification_loss: 0.1221
395/500 [======================>.......] - ETA: 50s - loss: 0.7829 - regression_loss: 0.6610 - classification_loss: 0.1219
396/500 [======================>.......] - ETA: 49s - loss: 0.7813 - regression_loss: 0.6596 - classification_loss: 0.1217
397/500 [======================>.......] - ETA: 49s - loss: 0.7804 - regression_loss: 0.6589 - classification_loss: 0.1215
398/500 [======================>.......] - ETA: 48s - loss: 0.7786 - regression_loss: 0.6573 - classification_loss: 0.1213
399/500 [======================>.......] - ETA: 48s - loss: 0.7785 - regression_loss: 0.6572 - classification_loss: 0.1213
400/500 [=======================>......] - ETA: 47s - loss: 0.7773 - regression_loss: 0.6561 - classification_loss: 0.1212
401/500 [=======================>......] - ETA: 47s - loss: 0.7759 - regression_loss: 0.6550 - classification_loss: 0.1210
402/500 [=======================>......] - ETA: 47s - loss: 0.7765 - regression_loss: 0.6555 - classification_loss: 0.1210
403/500 [=======================>......] - ETA: 46s - loss: 0.7753 - regression_loss: 0.6544 - classification_loss: 0.1209
404/500 [=======================>......] - ETA: 46s - loss: 0.7746 - regression_loss: 0.6539 - classification_loss: 0.1207
405/500 [=======================>......] - ETA: 45s - loss: 0.7732 - regression_loss: 0.6527 - classification_loss: 0.1205
406/500 [=======================>......] - ETA: 45s - loss: 0.7716 - regression_loss: 0.6513 - classification_loss: 0.1203
407/500 [=======================>......] - ETA: 44s - loss: 0.7700 - regression_loss: 0.6499 - classification_loss: 0.1201
408/500 [=======================>......] - ETA: 44s - loss: 0.7690 - regression_loss: 0.6491 - classification_loss: 0.1199
409/500 [=======================>......] - ETA: 43s - loss: 0.7683 - regression_loss: 0.6486 - classification_loss: 0.1198
410/500 [=======================>......] - ETA: 43s - loss: 0.7683 - regression_loss: 0.6486 - classification_loss: 0.1198
411/500 [=======================>......] - ETA: 42s - loss: 0.7686 - regression_loss: 0.6488 - classification_loss: 0.1198
412/500 [=======================>......] - ETA: 42s - loss: 0.7676 - regression_loss: 0.6480 - classification_loss: 0.1196
413/500 [=======================>......] - ETA: 41s - loss: 0.7666 - regression_loss: 0.6471 - classification_loss: 0.1195
414/500 [=======================>......] - ETA: 41s - loss: 0.7650 - regression_loss: 0.6456 - classification_loss: 0.1193
415/500 [=======================>......] - ETA: 40s - loss: 0.7637 - regression_loss: 0.6446 - classification_loss: 0.1191
416/500 [=======================>......] - ETA: 40s - loss: 0.7633 - regression_loss: 0.6443 - classification_loss: 0.1190
417/500 [========================>.....] - ETA: 39s - loss: 0.7637 - regression_loss: 0.6447 - classification_loss: 0.1190
418/500 [========================>.....] - ETA: 39s - loss: 0.7627 - regression_loss: 0.6438 - classification_loss: 0.1189
419/500 [========================>.....] - ETA: 38s - loss: 0.7613 - regression_loss: 0.6426 - classification_loss: 0.1187
420/500 [========================>.....] - ETA: 38s - loss: 0.7597 - regression_loss: 0.6413 - classification_loss: 0.1185
421/500 [========================>.....] - ETA: 37s - loss: 0.7589 - regression_loss: 0.6406 - classification_loss: 0.1183
422/500 [========================>.....] - ETA: 37s - loss: 0.7592 - regression_loss: 0.6408 - classification_loss: 0.1184
423/500 [========================>.....] - ETA: 36s - loss: 0.7576 - regression_loss: 0.6395 - classification_loss: 0.1182
424/500 [========================>.....] - ETA: 36s - loss: 0.7566 - regression_loss: 0.6385 - classification_loss: 0.1180
425/500 [========================>.....] - ETA: 35s - loss: 0.7555 - regression_loss: 0.6376 - classification_loss: 0.1178
426/500 [========================>.....] - ETA: 35s - loss: 0.7546 - regression_loss: 0.6369 - classification_loss: 0.1177
427/500 [========================>.....] - ETA: 34s - loss: 0.7533 - regression_loss: 0.6358 - classification_loss: 0.1175
428/500 [========================>.....] - ETA: 34s - loss: 0.7521 - regression_loss: 0.6348 - classification_loss: 0.1174
429/500 [========================>.....] - ETA: 33s - loss: 0.7508 - regression_loss: 0.6336 - classification_loss: 0.1172
430/500 [========================>.....] - ETA: 33s - loss: 0.7507 - regression_loss: 0.6336 - classification_loss: 0.1172
431/500 [========================>.....] - ETA: 33s - loss: 0.7497 - regression_loss: 0.6327 - classification_loss: 0.1170
432/500 [========================>.....] - ETA: 32s - loss: 0.7499 - regression_loss: 0.6329 - classification_loss: 0.1170
433/500 [========================>.....] - ETA: 32s - loss: 0.7491 - regression_loss: 0.6323 - classification_loss: 0.1169
434/500 [=========================>....] - ETA: 31s - loss: 0.7475 - regression_loss: 0.6308 - classification_loss: 0.1167
435/500 [=========================>....] - ETA: 31s - loss: 0.7465 - regression_loss: 0.6299 - classification_loss: 0.1166
436/500 [=========================>....] - ETA: 30s - loss: 0.7467 - regression_loss: 0.6301 - classification_loss: 0.1166
437/500 [=========================>....] - ETA: 30s - loss: 0.7452 - regression_loss: 0.6288 - classification_loss: 0.1164
438/500 [=========================>....] - ETA: 29s - loss: 0.7440 - regression_loss: 0.6278 - classification_loss: 0.1162
439/500 [=========================>....] - ETA: 29s - loss: 0.7429 - regression_loss: 0.6268 - classification_loss: 0.1161
440/500 [=========================>....] - ETA: 28s - loss: 0.7422 - regression_loss: 0.6263 - classification_loss: 0.1159
441/500 [=========================>....] - ETA: 28s - loss: 0.7410 - regression_loss: 0.6252 - classification_loss: 0.1157
442/500 [=========================>....] - ETA: 27s - loss: 0.7395 - regression_loss: 0.6240 - classification_loss: 0.1156
443/500 [=========================>....] - ETA: 27s - loss: 0.7385 - regression_loss: 0.6231 - classification_loss: 0.1154
444/500 [=========================>....] - ETA: 26s - loss: 0.7387 - regression_loss: 0.6232 - classification_loss: 0.1155
445/500 [=========================>....] - ETA: 26s - loss: 0.7379 - regression_loss: 0.6226 - classification_loss: 0.1153
446/500 [=========================>....] - ETA: 25s - loss: 0.7371 - regression_loss: 0.6219 - classification_loss: 0.1152
447/500 [=========================>....] - ETA: 25s - loss: 0.7372 - regression_loss: 0.6220 - classification_loss: 0.1152
448/500 [=========================>....] - ETA: 24s - loss: 0.7362 - regression_loss: 0.6211 - classification_loss: 0.1151
449/500 [=========================>....] - ETA: 24s - loss: 0.7349 - regression_loss: 0.6200 - classification_loss: 0.1149
450/500 [==========================>...] - ETA: 23s - loss: 0.7335 - regression_loss: 0.6188 - classification_loss: 0.1147
451/500 [==========================>...] - ETA: 23s - loss: 0.7324 - regression_loss: 0.6178 - classification_loss: 0.1146
452/500 [==========================>...] - ETA: 22s - loss: 0.7317 - regression_loss: 0.6172 - classification_loss: 0.1145
453/500 [==========================>...] - ETA: 22s - loss: 0.7317 - regression_loss: 0.6173 - classification_loss: 0.1145
454/500 [==========================>...] - ETA: 21s - loss: 0.7302 - regression_loss: 0.6159 - classification_loss: 0.1143
455/500 [==========================>...] - ETA: 21s - loss: 0.7289 - regression_loss: 0.6148 - classification_loss: 0.1141
456/500 [==========================>...] - ETA: 21s - loss: 0.7281 - regression_loss: 0.6141 - classification_loss: 0.1140
457/500 [==========================>...] - ETA: 20s - loss: 0.7268 - regression_loss: 0.6130 - classification_loss: 0.1138
458/500 [==========================>...] - ETA: 20s - loss: 0.7261 - regression_loss: 0.6124 - classification_loss: 0.1137
459/500 [==========================>...] - ETA: 19s - loss: 0.7249 - regression_loss: 0.6113 - classification_loss: 0.1135
460/500 [==========================>...] - ETA: 19s - loss: 0.7248 - regression_loss: 0.6113 - classification_loss: 0.1135
461/500 [==========================>...] - ETA: 18s - loss: 0.7233 - regression_loss: 0.6100 - classification_loss: 0.1133
462/500 [==========================>...] - ETA: 18s - loss: 0.7220 - regression_loss: 0.6088 - classification_loss: 0.1131
463/500 [==========================>...] - ETA: 17s - loss: 0.7209 - regression_loss: 0.6079 - classification_loss: 0.1130
464/500 [==========================>...] - ETA: 17s - loss: 0.7204 - regression_loss: 0.6075 - classification_loss: 0.1129
465/500 [==========================>...] - ETA: 16s - loss: 0.7204 - regression_loss: 0.6075 - classification_loss: 0.1129
466/500 [==========================>...] - ETA: 16s - loss: 0.7193 - regression_loss: 0.6066 - classification_loss: 0.1127
467/500 [===========================>..] - ETA: 15s - loss: 0.7180 - regression_loss: 0.6054 - classification_loss: 0.1125
468/500 [===========================>..] - ETA: 15s - loss: 0.7173 - regression_loss: 0.6049 - classification_loss: 0.1124
469/500 [===========================>..] - ETA: 14s - loss: 0.7173 - regression_loss: 0.6049 - classification_loss: 0.1124
470/500 [===========================>..] - ETA: 14s - loss: 0.7163 - regression_loss: 0.6041 - classification_loss: 0.1123
471/500 [===========================>..] - ETA: 13s - loss: 0.7164 - regression_loss: 0.6041 - classification_loss: 0.1123
472/500 [===========================>..] - ETA: 13s - loss: 0.7152 - regression_loss: 0.6030 - classification_loss: 0.1121
473/500 [===========================>..] - ETA: 12s - loss: 0.7143 - regression_loss: 0.6023 - classification_loss: 0.1120
474/500 [===========================>..] - ETA: 12s - loss: 0.7131 - regression_loss: 0.6013 - classification_loss: 0.1119
475/500 [===========================>..] - ETA: 11s - loss: 0.7127 - regression_loss: 0.6010 - classification_loss: 0.1117
476/500 [===========================>..] - ETA: 11s - loss: 0.7126 - regression_loss: 0.6009 - classification_loss: 0.1117
477/500 [===========================>..] - ETA: 10s - loss: 0.7120 - regression_loss: 0.6004 - classification_loss: 0.1116
478/500 [===========================>..] - ETA: 10s - loss: 0.7110 - regression_loss: 0.5995 - classification_loss: 0.1114
479/500 [===========================>..] - ETA: 10s - loss: 0.7102 - regression_loss: 0.5989 - classification_loss: 0.1113
480/500 [===========================>..] - ETA: 9s - loss: 0.7091 - regression_loss: 0.5979 - classification_loss: 0.1112 
481/500 [===========================>..] - ETA: 9s - loss: 0.7083 - regression_loss: 0.5972 - classification_loss: 0.1110
482/500 [===========================>..] - ETA: 8s - loss: 0.7074 - regression_loss: 0.5965 - classification_loss: 0.1109
483/500 [===========================>..] - ETA: 8s - loss: 0.7074 - regression_loss: 0.5966 - classification_loss: 0.1109
484/500 [============================>.] - ETA: 7s - loss: 0.7067 - regression_loss: 0.5959 - classification_loss: 0.1108
485/500 [============================>.] - ETA: 7s - loss: 0.7054 - regression_loss: 0.5948 - classification_loss: 0.1106
486/500 [============================>.] - ETA: 6s - loss: 0.7047 - regression_loss: 0.5942 - classification_loss: 0.1105
487/500 [============================>.] - ETA: 6s - loss: 0.7040 - regression_loss: 0.5936 - classification_loss: 0.1103
488/500 [============================>.] - ETA: 5s - loss: 0.7033 - regression_loss: 0.5930 - classification_loss: 0.1102
489/500 [============================>.] - ETA: 5s - loss: 0.7020 - regression_loss: 0.5919 - classification_loss: 0.1101
490/500 [============================>.] - ETA: 4s - loss: 0.7019 - regression_loss: 0.5919 - classification_loss: 0.1101
491/500 [============================>.] - ETA: 4s - loss: 0.7018 - regression_loss: 0.5918 - classification_loss: 0.1101
492/500 [============================>.] - ETA: 3s - loss: 0.7006 - regression_loss: 0.5907 - classification_loss: 0.1099
493/500 [============================>.] - ETA: 3s - loss: 0.7002 - regression_loss: 0.5904 - classification_loss: 0.1098
494/500 [============================>.] - ETA: 2s - loss: 0.6993 - regression_loss: 0.5897 - classification_loss: 0.1096
495/500 [============================>.] - ETA: 2s - loss: 0.6983 - regression_loss: 0.5888 - classification_loss: 0.1095
496/500 [============================>.] - ETA: 1s - loss: 0.6973 - regression_loss: 0.5879 - classification_loss: 0.1093
497/500 [============================>.] - ETA: 1s - loss: 0.6973 - regression_loss: 0.5880 - classification_loss: 0.1093
498/500 [============================>.] - ETA: 0s - loss: 0.6964 - regression_loss: 0.5872 - classification_loss: 0.1092
499/500 [============================>.] - ETA: 0s - loss: 0.6955 - regression_loss: 0.5864 - classification_loss: 0.1091
500/500 [==============================] - 238s 476ms/step - loss: 0.6949 - regression_loss: 0.5859 - classification_loss: 0.1089
44 instances of class building with average precision: 0.7183
mAP: 0.7183

Epoch 00001: saving model to ./snapshots/resnet50_csv_01.h5
Epoch 2/8

  1/500 [..............................] - ETA: 3:59 - loss: 0.3911 - regression_loss: 0.3438 - classification_loss: 0.0473
  2/500 [..............................] - ETA: 3:54 - loss: 0.4279 - regression_loss: 0.3744 - classification_loss: 0.0535
  3/500 [..............................] - ETA: 3:52 - loss: 0.3210 - regression_loss: 0.2753 - classification_loss: 0.0457
  4/500 [..............................] - ETA: 3:51 - loss: 0.4027 - regression_loss: 0.3421 - classification_loss: 0.0606
  5/500 [..............................] - ETA: 3:50 - loss: 0.3453 - regression_loss: 0.2910 - classification_loss: 0.0542
  6/500 [..............................] - ETA: 3:49 - loss: 0.3621 - regression_loss: 0.3093 - classification_loss: 0.0528
  7/500 [..............................] - ETA: 3:48 - loss: 0.3970 - regression_loss: 0.3369 - classification_loss: 0.0601
  8/500 [..............................] - ETA: 3:48 - loss: 0.3784 - regression_loss: 0.3186 - classification_loss: 0.0597
  9/500 [..............................] - ETA: 3:47 - loss: 0.3501 - regression_loss: 0.2938 - classification_loss: 0.0563
 10/500 [..............................] - ETA: 3:47 - loss: 0.3231 - regression_loss: 0.2693 - classification_loss: 0.0539
 11/500 [..............................] - ETA: 3:47 - loss: 0.2983 - regression_loss: 0.2466 - classification_loss: 0.0517
 12/500 [..............................] - ETA: 3:46 - loss: 0.3450 - regression_loss: 0.2876 - classification_loss: 0.0574
 13/500 [..............................] - ETA: 3:46 - loss: 0.3546 - regression_loss: 0.2978 - classification_loss: 0.0568
 14/500 [..............................] - ETA: 3:45 - loss: 0.3496 - regression_loss: 0.2931 - classification_loss: 0.0565
 15/500 [..............................] - ETA: 3:45 - loss: 0.3347 - regression_loss: 0.2799 - classification_loss: 0.0548
 16/500 [..............................] - ETA: 3:45 - loss: 0.3262 - regression_loss: 0.2717 - classification_loss: 0.0545
 17/500 [>.............................] - ETA: 3:44 - loss: 0.3302 - regression_loss: 0.2763 - classification_loss: 0.0539
 18/500 [>.............................] - ETA: 3:43 - loss: 0.3275 - regression_loss: 0.2749 - classification_loss: 0.0526
 19/500 [>.............................] - ETA: 3:43 - loss: 0.3481 - regression_loss: 0.2920 - classification_loss: 0.0561
 20/500 [>.............................] - ETA: 3:42 - loss: 0.3399 - regression_loss: 0.2851 - classification_loss: 0.0548
 21/500 [>.............................] - ETA: 3:42 - loss: 0.3413 - regression_loss: 0.2870 - classification_loss: 0.0543
 22/500 [>.............................] - ETA: 3:41 - loss: 0.3396 - regression_loss: 0.2852 - classification_loss: 0.0544
 23/500 [>.............................] - ETA: 3:41 - loss: 0.3289 - regression_loss: 0.2758 - classification_loss: 0.0531
 24/500 [>.............................] - ETA: 3:40 - loss: 0.3184 - regression_loss: 0.2663 - classification_loss: 0.0521
 25/500 [>.............................] - ETA: 3:40 - loss: 0.3345 - regression_loss: 0.2799 - classification_loss: 0.0547
 26/500 [>.............................] - ETA: 3:39 - loss: 0.3257 - regression_loss: 0.2720 - classification_loss: 0.0537
 27/500 [>.............................] - ETA: 3:39 - loss: 0.3196 - regression_loss: 0.2669 - classification_loss: 0.0528
 28/500 [>.............................] - ETA: 3:39 - loss: 0.3318 - regression_loss: 0.2773 - classification_loss: 0.0545
 29/500 [>.............................] - ETA: 3:38 - loss: 0.3306 - regression_loss: 0.2761 - classification_loss: 0.0544
 30/500 [>.............................] - ETA: 3:38 - loss: 0.3339 - regression_loss: 0.2797 - classification_loss: 0.0541
 31/500 [>.............................] - ETA: 3:37 - loss: 0.3320 - regression_loss: 0.2779 - classification_loss: 0.0540
 32/500 [>.............................] - ETA: 3:37 - loss: 0.3418 - regression_loss: 0.2862 - classification_loss: 0.0557
 33/500 [>.............................] - ETA: 3:36 - loss: 0.3429 - regression_loss: 0.2876 - classification_loss: 0.0553
 34/500 [=>............................] - ETA: 3:36 - loss: 0.3362 - regression_loss: 0.2817 - classification_loss: 0.0545
 35/500 [=>............................] - ETA: 3:35 - loss: 0.3354 - regression_loss: 0.2814 - classification_loss: 0.0539
 36/500 [=>............................] - ETA: 3:35 - loss: 0.3354 - regression_loss: 0.2818 - classification_loss: 0.0537
 37/500 [=>............................] - ETA: 3:34 - loss: 0.3456 - regression_loss: 0.2903 - classification_loss: 0.0553
 38/500 [=>............................] - ETA: 3:34 - loss: 0.3441 - regression_loss: 0.2894 - classification_loss: 0.0547
 39/500 [=>............................] - ETA: 3:33 - loss: 0.3438 - regression_loss: 0.2892 - classification_loss: 0.0546
 40/500 [=>............................] - ETA: 3:33 - loss: 0.3438 - regression_loss: 0.2897 - classification_loss: 0.0541
 41/500 [=>............................] - ETA: 3:32 - loss: 0.3394 - regression_loss: 0.2860 - classification_loss: 0.0535
 42/500 [=>............................] - ETA: 3:32 - loss: 0.3375 - regression_loss: 0.2840 - classification_loss: 0.0535
 43/500 [=>............................] - ETA: 3:31 - loss: 0.3341 - regression_loss: 0.2813 - classification_loss: 0.0528
 44/500 [=>............................] - ETA: 3:31 - loss: 0.3429 - regression_loss: 0.2888 - classification_loss: 0.0541
 45/500 [=>............................] - ETA: 3:30 - loss: 0.3453 - regression_loss: 0.2914 - classification_loss: 0.0540
 46/500 [=>............................] - ETA: 3:30 - loss: 0.3526 - regression_loss: 0.2974 - classification_loss: 0.0552
 47/500 [=>............................] - ETA: 3:30 - loss: 0.3534 - regression_loss: 0.2984 - classification_loss: 0.0550
 48/500 [=>............................] - ETA: 3:29 - loss: 0.3512 - regression_loss: 0.2963 - classification_loss: 0.0549
 49/500 [=>............................] - ETA: 3:29 - loss: 0.3469 - regression_loss: 0.2925 - classification_loss: 0.0544
 50/500 [==>...........................] - ETA: 3:28 - loss: 0.3420 - regression_loss: 0.2881 - classification_loss: 0.0539
 51/500 [==>...........................] - ETA: 3:28 - loss: 0.3366 - regression_loss: 0.2832 - classification_loss: 0.0534
 52/500 [==>...........................] - ETA: 3:27 - loss: 0.3355 - regression_loss: 0.2822 - classification_loss: 0.0534
 53/500 [==>...........................] - ETA: 3:27 - loss: 0.3350 - regression_loss: 0.2821 - classification_loss: 0.0528
 54/500 [==>...........................] - ETA: 3:26 - loss: 0.3366 - regression_loss: 0.2839 - classification_loss: 0.0527
 55/500 [==>...........................] - ETA: 3:26 - loss: 0.3431 - regression_loss: 0.2895 - classification_loss: 0.0536
 56/500 [==>...........................] - ETA: 3:25 - loss: 0.3413 - regression_loss: 0.2878 - classification_loss: 0.0535
 57/500 [==>...........................] - ETA: 3:25 - loss: 0.3473 - regression_loss: 0.2928 - classification_loss: 0.0545
 58/500 [==>...........................] - ETA: 3:24 - loss: 0.3480 - regression_loss: 0.2936 - classification_loss: 0.0544
 59/500 [==>...........................] - ETA: 3:24 - loss: 0.3486 - regression_loss: 0.2944 - classification_loss: 0.0542
 60/500 [==>...........................] - ETA: 3:23 - loss: 0.3476 - regression_loss: 0.2938 - classification_loss: 0.0537
 61/500 [==>...........................] - ETA: 3:23 - loss: 0.3479 - regression_loss: 0.2944 - classification_loss: 0.0535
 62/500 [==>...........................] - ETA: 3:23 - loss: 0.3485 - regression_loss: 0.2951 - classification_loss: 0.0534
 63/500 [==>...........................] - ETA: 3:22 - loss: 0.3540 - regression_loss: 0.2998 - classification_loss: 0.0543
 64/500 [==>...........................] - ETA: 3:22 - loss: 0.3538 - regression_loss: 0.2996 - classification_loss: 0.0542
 65/500 [==>...........................] - ETA: 3:21 - loss: 0.3510 - regression_loss: 0.2971 - classification_loss: 0.0538
 66/500 [==>...........................] - ETA: 3:21 - loss: 0.3509 - regression_loss: 0.2972 - classification_loss: 0.0537
 67/500 [===>..........................] - ETA: 3:20 - loss: 0.3478 - regression_loss: 0.2946 - classification_loss: 0.0532
 68/500 [===>..........................] - ETA: 3:20 - loss: 0.3447 - regression_loss: 0.2919 - classification_loss: 0.0529
 69/500 [===>..........................] - ETA: 3:19 - loss: 0.3494 - regression_loss: 0.2959 - classification_loss: 0.0535
 70/500 [===>..........................] - ETA: 3:19 - loss: 0.3479 - regression_loss: 0.2945 - classification_loss: 0.0534
 71/500 [===>..........................] - ETA: 3:19 - loss: 0.3517 - regression_loss: 0.2976 - classification_loss: 0.0541
 72/500 [===>..........................] - ETA: 3:18 - loss: 0.3479 - regression_loss: 0.2942 - classification_loss: 0.0537
 73/500 [===>..........................] - ETA: 3:18 - loss: 0.3469 - regression_loss: 0.2935 - classification_loss: 0.0534
 74/500 [===>..........................] - ETA: 3:17 - loss: 0.3473 - regression_loss: 0.2940 - classification_loss: 0.0533
 75/500 [===>..........................] - ETA: 3:17 - loss: 0.3471 - regression_loss: 0.2939 - classification_loss: 0.0532
 76/500 [===>..........................] - ETA: 3:17 - loss: 0.3510 - regression_loss: 0.2971 - classification_loss: 0.0539
 77/500 [===>..........................] - ETA: 3:16 - loss: 0.3522 - regression_loss: 0.2985 - classification_loss: 0.0537
 78/500 [===>..........................] - ETA: 3:16 - loss: 0.3498 - regression_loss: 0.2964 - classification_loss: 0.0534
 79/500 [===>..........................] - ETA: 3:15 - loss: 0.3484 - regression_loss: 0.2950 - classification_loss: 0.0534
 80/500 [===>..........................] - ETA: 3:15 - loss: 0.3452 - regression_loss: 0.2921 - classification_loss: 0.0530
 81/500 [===>..........................] - ETA: 3:14 - loss: 0.3420 - regression_loss: 0.2893 - classification_loss: 0.0527
 82/500 [===>..........................] - ETA: 3:14 - loss: 0.3391 - regression_loss: 0.2867 - classification_loss: 0.0524
 83/500 [===>..........................] - ETA: 3:13 - loss: 0.3435 - regression_loss: 0.2904 - classification_loss: 0.0530
 84/500 [====>.........................] - ETA: 3:13 - loss: 0.3422 - regression_loss: 0.2892 - classification_loss: 0.0530
 85/500 [====>.........................] - ETA: 3:12 - loss: 0.3420 - regression_loss: 0.2891 - classification_loss: 0.0529
 86/500 [====>.........................] - ETA: 3:12 - loss: 0.3452 - regression_loss: 0.2917 - classification_loss: 0.0535
 87/500 [====>.........................] - ETA: 3:12 - loss: 0.3422 - regression_loss: 0.2890 - classification_loss: 0.0532
 88/500 [====>.........................] - ETA: 3:11 - loss: 0.3419 - regression_loss: 0.2889 - classification_loss: 0.0530
 89/500 [====>.........................] - ETA: 3:11 - loss: 0.3419 - regression_loss: 0.2892 - classification_loss: 0.0527
 90/500 [====>.........................] - ETA: 3:10 - loss: 0.3425 - regression_loss: 0.2898 - classification_loss: 0.0527
 91/500 [====>.........................] - ETA: 3:10 - loss: 0.3397 - regression_loss: 0.2873 - classification_loss: 0.0524
 92/500 [====>.........................] - ETA: 3:09 - loss: 0.3387 - regression_loss: 0.2865 - classification_loss: 0.0521
 93/500 [====>.........................] - ETA: 3:09 - loss: 0.3428 - regression_loss: 0.2901 - classification_loss: 0.0527
 94/500 [====>.........................] - ETA: 3:08 - loss: 0.3428 - regression_loss: 0.2902 - classification_loss: 0.0526
 95/500 [====>.........................] - ETA: 3:08 - loss: 0.3419 - regression_loss: 0.2893 - classification_loss: 0.0525
 96/500 [====>.........................] - ETA: 3:07 - loss: 0.3390 - regression_loss: 0.2868 - classification_loss: 0.0523
 97/500 [====>.........................] - ETA: 3:07 - loss: 0.3369 - regression_loss: 0.2849 - classification_loss: 0.0520
 98/500 [====>.........................] - ETA: 3:06 - loss: 0.3352 - regression_loss: 0.2833 - classification_loss: 0.0519
 99/500 [====>.........................] - ETA: 3:06 - loss: 0.3354 - regression_loss: 0.2836 - classification_loss: 0.0518
100/500 [=====>........................] - ETA: 3:05 - loss: 0.3383 - regression_loss: 0.2861 - classification_loss: 0.0522
101/500 [=====>........................] - ETA: 3:05 - loss: 0.3362 - regression_loss: 0.2842 - classification_loss: 0.0520
102/500 [=====>........................] - ETA: 3:04 - loss: 0.3351 - regression_loss: 0.2832 - classification_loss: 0.0519
103/500 [=====>........................] - ETA: 3:04 - loss: 0.3349 - regression_loss: 0.2831 - classification_loss: 0.0518
104/500 [=====>........................] - ETA: 3:03 - loss: 0.3373 - regression_loss: 0.2850 - classification_loss: 0.0523
105/500 [=====>........................] - ETA: 3:03 - loss: 0.3353 - regression_loss: 0.2833 - classification_loss: 0.0520
106/500 [=====>........................] - ETA: 3:03 - loss: 0.3328 - regression_loss: 0.2811 - classification_loss: 0.0518
107/500 [=====>........................] - ETA: 3:02 - loss: 0.3317 - regression_loss: 0.2800 - classification_loss: 0.0517
108/500 [=====>........................] - ETA: 3:02 - loss: 0.3310 - regression_loss: 0.2795 - classification_loss: 0.0515
109/500 [=====>........................] - ETA: 3:01 - loss: 0.3346 - regression_loss: 0.2826 - classification_loss: 0.0520
110/500 [=====>........................] - ETA: 3:01 - loss: 0.3359 - regression_loss: 0.2840 - classification_loss: 0.0519
111/500 [=====>........................] - ETA: 3:00 - loss: 0.3345 - regression_loss: 0.2827 - classification_loss: 0.0518
112/500 [=====>........................] - ETA: 3:00 - loss: 0.3348 - regression_loss: 0.2831 - classification_loss: 0.0517
113/500 [=====>........................] - ETA: 2:59 - loss: 0.3325 - regression_loss: 0.2811 - classification_loss: 0.0514
114/500 [=====>........................] - ETA: 2:59 - loss: 0.3348 - regression_loss: 0.2830 - classification_loss: 0.0518
115/500 [=====>........................] - ETA: 2:58 - loss: 0.3337 - regression_loss: 0.2820 - classification_loss: 0.0517
116/500 [=====>........................] - ETA: 2:58 - loss: 0.3336 - regression_loss: 0.2821 - classification_loss: 0.0516
117/500 [======>.......................] - ETA: 2:57 - loss: 0.3315 - regression_loss: 0.2802 - classification_loss: 0.0513
118/500 [======>.......................] - ETA: 2:57 - loss: 0.3300 - regression_loss: 0.2789 - classification_loss: 0.0511
119/500 [======>.......................] - ETA: 2:56 - loss: 0.3311 - regression_loss: 0.2800 - classification_loss: 0.0511
120/500 [======>.......................] - ETA: 2:56 - loss: 0.3338 - regression_loss: 0.2822 - classification_loss: 0.0516
121/500 [======>.......................] - ETA: 2:55 - loss: 0.3316 - regression_loss: 0.2803 - classification_loss: 0.0513
122/500 [======>.......................] - ETA: 2:55 - loss: 0.3314 - regression_loss: 0.2802 - classification_loss: 0.0513
123/500 [======>.......................] - ETA: 2:54 - loss: 0.3334 - regression_loss: 0.2818 - classification_loss: 0.0517
124/500 [======>.......................] - ETA: 2:54 - loss: 0.3321 - regression_loss: 0.2807 - classification_loss: 0.0514
125/500 [======>.......................] - ETA: 2:54 - loss: 0.3321 - regression_loss: 0.2808 - classification_loss: 0.0513
126/500 [======>.......................] - ETA: 2:53 - loss: 0.3310 - regression_loss: 0.2798 - classification_loss: 0.0511
127/500 [======>.......................] - ETA: 2:53 - loss: 0.3321 - regression_loss: 0.2810 - classification_loss: 0.0511
128/500 [======>.......................] - ETA: 2:52 - loss: 0.3321 - regression_loss: 0.2810 - classification_loss: 0.0510
129/500 [======>.......................] - ETA: 2:52 - loss: 0.3318 - regression_loss: 0.2808 - classification_loss: 0.0510
130/500 [======>.......................] - ETA: 2:51 - loss: 0.3343 - regression_loss: 0.2829 - classification_loss: 0.0514
131/500 [======>.......................] - ETA: 2:51 - loss: 0.3365 - regression_loss: 0.2847 - classification_loss: 0.0518
132/500 [======>.......................] - ETA: 2:50 - loss: 0.3364 - regression_loss: 0.2848 - classification_loss: 0.0517
133/500 [======>.......................] - ETA: 2:50 - loss: 0.3349 - regression_loss: 0.2835 - classification_loss: 0.0515
134/500 [=======>......................] - ETA: 2:49 - loss: 0.3335 - regression_loss: 0.2823 - classification_loss: 0.0512
135/500 [=======>......................] - ETA: 2:49 - loss: 0.3324 - regression_loss: 0.2813 - classification_loss: 0.0511
136/500 [=======>......................] - ETA: 2:48 - loss: 0.3312 - regression_loss: 0.2801 - classification_loss: 0.0511
137/500 [=======>......................] - ETA: 2:48 - loss: 0.3302 - regression_loss: 0.2793 - classification_loss: 0.0509
138/500 [=======>......................] - ETA: 2:47 - loss: 0.3282 - regression_loss: 0.2775 - classification_loss: 0.0507
139/500 [=======>......................] - ETA: 2:47 - loss: 0.3300 - regression_loss: 0.2789 - classification_loss: 0.0511
140/500 [=======>......................] - ETA: 2:46 - loss: 0.3299 - regression_loss: 0.2790 - classification_loss: 0.0510
141/500 [=======>......................] - ETA: 2:46 - loss: 0.3316 - regression_loss: 0.2803 - classification_loss: 0.0513
142/500 [=======>......................] - ETA: 2:46 - loss: 0.3296 - regression_loss: 0.2785 - classification_loss: 0.0511
143/500 [=======>......................] - ETA: 2:45 - loss: 0.3287 - regression_loss: 0.2777 - classification_loss: 0.0511
144/500 [=======>......................] - ETA: 2:45 - loss: 0.3286 - regression_loss: 0.2776 - classification_loss: 0.0510
145/500 [=======>......................] - ETA: 2:44 - loss: 0.3267 - regression_loss: 0.2759 - classification_loss: 0.0508
146/500 [=======>......................] - ETA: 2:44 - loss: 0.3250 - regression_loss: 0.2744 - classification_loss: 0.0506
147/500 [=======>......................] - ETA: 2:43 - loss: 0.3234 - regression_loss: 0.2731 - classification_loss: 0.0504
148/500 [=======>......................] - ETA: 2:43 - loss: 0.3226 - regression_loss: 0.2723 - classification_loss: 0.0503
149/500 [=======>......................] - ETA: 2:42 - loss: 0.3245 - regression_loss: 0.2739 - classification_loss: 0.0506
150/500 [========>.....................] - ETA: 2:42 - loss: 0.3245 - regression_loss: 0.2739 - classification_loss: 0.0505
151/500 [========>.....................] - ETA: 2:41 - loss: 0.3226 - regression_loss: 0.2722 - classification_loss: 0.0504
152/500 [========>.....................] - ETA: 2:41 - loss: 0.3208 - regression_loss: 0.2707 - classification_loss: 0.0502
153/500 [========>.....................] - ETA: 2:40 - loss: 0.3225 - regression_loss: 0.2720 - classification_loss: 0.0504
154/500 [========>.....................] - ETA: 2:40 - loss: 0.3215 - regression_loss: 0.2711 - classification_loss: 0.0504
155/500 [========>.....................] - ETA: 2:39 - loss: 0.3213 - regression_loss: 0.2710 - classification_loss: 0.0503
156/500 [========>.....................] - ETA: 2:39 - loss: 0.3202 - regression_loss: 0.2700 - classification_loss: 0.0502
157/500 [========>.....................] - ETA: 2:39 - loss: 0.3187 - regression_loss: 0.2687 - classification_loss: 0.0500
158/500 [========>.....................] - ETA: 2:38 - loss: 0.3180 - regression_loss: 0.2682 - classification_loss: 0.0498
159/500 [========>.....................] - ETA: 2:38 - loss: 0.3178 - regression_loss: 0.2681 - classification_loss: 0.0497
160/500 [========>.....................] - ETA: 2:37 - loss: 0.3193 - regression_loss: 0.2693 - classification_loss: 0.0500
161/500 [========>.....................] - ETA: 2:37 - loss: 0.3187 - regression_loss: 0.2687 - classification_loss: 0.0500
162/500 [========>.....................] - ETA: 2:36 - loss: 0.3176 - regression_loss: 0.2678 - classification_loss: 0.0498
163/500 [========>.....................] - ETA: 2:36 - loss: 0.3175 - regression_loss: 0.2678 - classification_loss: 0.0497
164/500 [========>.....................] - ETA: 2:35 - loss: 0.3167 - regression_loss: 0.2671 - classification_loss: 0.0496
165/500 [========>.....................] - ETA: 2:35 - loss: 0.3183 - regression_loss: 0.2684 - classification_loss: 0.0498
166/500 [========>.....................] - ETA: 2:34 - loss: 0.3168 - regression_loss: 0.2671 - classification_loss: 0.0497
167/500 [=========>....................] - ETA: 2:34 - loss: 0.3167 - regression_loss: 0.2671 - classification_loss: 0.0496
168/500 [=========>....................] - ETA: 2:33 - loss: 0.3163 - regression_loss: 0.2668 - classification_loss: 0.0495
169/500 [=========>....................] - ETA: 2:33 - loss: 0.3176 - regression_loss: 0.2679 - classification_loss: 0.0497
170/500 [=========>....................] - ETA: 2:32 - loss: 0.3162 - regression_loss: 0.2666 - classification_loss: 0.0496
171/500 [=========>....................] - ETA: 2:32 - loss: 0.3146 - regression_loss: 0.2652 - classification_loss: 0.0494
172/500 [=========>....................] - ETA: 2:32 - loss: 0.3136 - regression_loss: 0.2642 - classification_loss: 0.0493
173/500 [=========>....................] - ETA: 2:31 - loss: 0.3151 - regression_loss: 0.2655 - classification_loss: 0.0496
174/500 [=========>....................] - ETA: 2:31 - loss: 0.3142 - regression_loss: 0.2648 - classification_loss: 0.0494
175/500 [=========>....................] - ETA: 2:30 - loss: 0.3143 - regression_loss: 0.2649 - classification_loss: 0.0493
176/500 [=========>....................] - ETA: 2:30 - loss: 0.3132 - regression_loss: 0.2640 - classification_loss: 0.0492
177/500 [=========>....................] - ETA: 2:29 - loss: 0.3119 - regression_loss: 0.2629 - classification_loss: 0.0490
178/500 [=========>....................] - ETA: 2:29 - loss: 0.3117 - regression_loss: 0.2628 - classification_loss: 0.0490
179/500 [=========>....................] - ETA: 2:28 - loss: 0.3131 - regression_loss: 0.2639 - classification_loss: 0.0492
180/500 [=========>....................] - ETA: 2:28 - loss: 0.3128 - regression_loss: 0.2636 - classification_loss: 0.0492
181/500 [=========>....................] - ETA: 2:27 - loss: 0.3115 - regression_loss: 0.2625 - classification_loss: 0.0490
182/500 [=========>....................] - ETA: 2:27 - loss: 0.3113 - regression_loss: 0.2624 - classification_loss: 0.0489
183/500 [=========>....................] - ETA: 2:26 - loss: 0.3125 - regression_loss: 0.2633 - classification_loss: 0.0492
184/500 [==========>...................] - ETA: 2:26 - loss: 0.3115 - regression_loss: 0.2625 - classification_loss: 0.0491
185/500 [==========>...................] - ETA: 2:25 - loss: 0.3102 - regression_loss: 0.2612 - classification_loss: 0.0489
186/500 [==========>...................] - ETA: 2:25 - loss: 0.3087 - regression_loss: 0.2600 - classification_loss: 0.0488
187/500 [==========>...................] - ETA: 2:25 - loss: 0.3090 - regression_loss: 0.2603 - classification_loss: 0.0487
188/500 [==========>...................] - ETA: 2:24 - loss: 0.3081 - regression_loss: 0.2596 - classification_loss: 0.0486
189/500 [==========>...................] - ETA: 2:24 - loss: 0.3080 - regression_loss: 0.2594 - classification_loss: 0.0486
190/500 [==========>...................] - ETA: 2:23 - loss: 0.3094 - regression_loss: 0.2606 - classification_loss: 0.0488
191/500 [==========>...................] - ETA: 2:23 - loss: 0.3105 - regression_loss: 0.2615 - classification_loss: 0.0491
192/500 [==========>...................] - ETA: 2:22 - loss: 0.3097 - regression_loss: 0.2608 - classification_loss: 0.0489
193/500 [==========>...................] - ETA: 2:22 - loss: 0.3103 - regression_loss: 0.2614 - classification_loss: 0.0488
194/500 [==========>...................] - ETA: 2:21 - loss: 0.3100 - regression_loss: 0.2612 - classification_loss: 0.0488
195/500 [==========>...................] - ETA: 2:21 - loss: 0.3103 - regression_loss: 0.2616 - classification_loss: 0.0487
196/500 [==========>...................] - ETA: 2:20 - loss: 0.3100 - regression_loss: 0.2614 - classification_loss: 0.0486
197/500 [==========>...................] - ETA: 2:20 - loss: 0.3097 - regression_loss: 0.2612 - classification_loss: 0.0485
198/500 [==========>...................] - ETA: 2:19 - loss: 0.3096 - regression_loss: 0.2611 - classification_loss: 0.0485
199/500 [==========>...................] - ETA: 2:19 - loss: 0.3111 - regression_loss: 0.2624 - classification_loss: 0.0487
200/500 [===========>..................] - ETA: 2:19 - loss: 0.3101 - regression_loss: 0.2616 - classification_loss: 0.0485
201/500 [===========>..................] - ETA: 2:18 - loss: 0.3094 - regression_loss: 0.2610 - classification_loss: 0.0484
202/500 [===========>..................] - ETA: 2:18 - loss: 0.3098 - regression_loss: 0.2614 - classification_loss: 0.0483
203/500 [===========>..................] - ETA: 2:17 - loss: 0.3109 - regression_loss: 0.2624 - classification_loss: 0.0485
204/500 [===========>..................] - ETA: 2:17 - loss: 0.3101 - regression_loss: 0.2618 - classification_loss: 0.0484
205/500 [===========>..................] - ETA: 2:16 - loss: 0.3101 - regression_loss: 0.2618 - classification_loss: 0.0483
206/500 [===========>..................] - ETA: 2:16 - loss: 0.3099 - regression_loss: 0.2616 - classification_loss: 0.0483
207/500 [===========>..................] - ETA: 2:15 - loss: 0.3086 - regression_loss: 0.2604 - classification_loss: 0.0481
208/500 [===========>..................] - ETA: 2:15 - loss: 0.3100 - regression_loss: 0.2617 - classification_loss: 0.0484
209/500 [===========>..................] - ETA: 2:14 - loss: 0.3104 - regression_loss: 0.2621 - classification_loss: 0.0483
210/500 [===========>..................] - ETA: 2:14 - loss: 0.3103 - regression_loss: 0.2621 - classification_loss: 0.0482
211/500 [===========>..................] - ETA: 2:13 - loss: 0.3097 - regression_loss: 0.2616 - classification_loss: 0.0481
212/500 [===========>..................] - ETA: 2:13 - loss: 0.3109 - regression_loss: 0.2626 - classification_loss: 0.0483
213/500 [===========>..................] - ETA: 2:12 - loss: 0.3109 - regression_loss: 0.2627 - classification_loss: 0.0482
214/500 [===========>..................] - ETA: 2:12 - loss: 0.3101 - regression_loss: 0.2620 - classification_loss: 0.0481
215/500 [===========>..................] - ETA: 2:12 - loss: 0.3091 - regression_loss: 0.2612 - classification_loss: 0.0480
216/500 [===========>..................] - ETA: 2:11 - loss: 0.3095 - regression_loss: 0.2616 - classification_loss: 0.0479
217/500 [============>.................] - ETA: 2:11 - loss: 0.3094 - regression_loss: 0.2615 - classification_loss: 0.0479
218/500 [============>.................] - ETA: 2:10 - loss: 0.3106 - regression_loss: 0.2625 - classification_loss: 0.0481
219/500 [============>.................] - ETA: 2:10 - loss: 0.3094 - regression_loss: 0.2614 - classification_loss: 0.0480
220/500 [============>.................] - ETA: 2:09 - loss: 0.3087 - regression_loss: 0.2608 - classification_loss: 0.0479
221/500 [============>.................] - ETA: 2:09 - loss: 0.3075 - regression_loss: 0.2597 - classification_loss: 0.0477
222/500 [============>.................] - ETA: 2:08 - loss: 0.3068 - regression_loss: 0.2591 - classification_loss: 0.0477
223/500 [============>.................] - ETA: 2:08 - loss: 0.3059 - regression_loss: 0.2584 - classification_loss: 0.0475
224/500 [============>.................] - ETA: 2:07 - loss: 0.3069 - regression_loss: 0.2592 - classification_loss: 0.0477
225/500 [============>.................] - ETA: 2:07 - loss: 0.3067 - regression_loss: 0.2591 - classification_loss: 0.0477
226/500 [============>.................] - ETA: 2:06 - loss: 0.3060 - regression_loss: 0.2585 - classification_loss: 0.0475
227/500 [============>.................] - ETA: 2:06 - loss: 0.3053 - regression_loss: 0.2578 - classification_loss: 0.0475
228/500 [============>.................] - ETA: 2:05 - loss: 0.3050 - regression_loss: 0.2576 - classification_loss: 0.0474
229/500 [============>.................] - ETA: 2:05 - loss: 0.3060 - regression_loss: 0.2584 - classification_loss: 0.0476
230/500 [============>.................] - ETA: 2:05 - loss: 0.3053 - regression_loss: 0.2578 - classification_loss: 0.0475
231/500 [============>.................] - ETA: 2:04 - loss: 0.3044 - regression_loss: 0.2570 - classification_loss: 0.0474
232/500 [============>.................] - ETA: 2:04 - loss: 0.3036 - regression_loss: 0.2563 - classification_loss: 0.0473
233/500 [============>.................] - ETA: 2:03 - loss: 0.3026 - regression_loss: 0.2555 - classification_loss: 0.0472
234/500 [=============>................] - ETA: 2:03 - loss: 0.3034 - regression_loss: 0.2561 - classification_loss: 0.0473
235/500 [=============>................] - ETA: 2:02 - loss: 0.3036 - regression_loss: 0.2563 - classification_loss: 0.0473
236/500 [=============>................] - ETA: 2:02 - loss: 0.3043 - regression_loss: 0.2569 - classification_loss: 0.0474
237/500 [=============>................] - ETA: 2:01 - loss: 0.3033 - regression_loss: 0.2560 - classification_loss: 0.0473
238/500 [=============>................] - ETA: 2:01 - loss: 0.3030 - regression_loss: 0.2558 - classification_loss: 0.0472
239/500 [=============>................] - ETA: 2:00 - loss: 0.3024 - regression_loss: 0.2552 - classification_loss: 0.0472
240/500 [=============>................] - ETA: 2:00 - loss: 0.3023 - regression_loss: 0.2552 - classification_loss: 0.0471
241/500 [=============>................] - ETA: 1:59 - loss: 0.3017 - regression_loss: 0.2546 - classification_loss: 0.0471
242/500 [=============>................] - ETA: 1:59 - loss: 0.3026 - regression_loss: 0.2553 - classification_loss: 0.0472
243/500 [=============>................] - ETA: 1:59 - loss: 0.3018 - regression_loss: 0.2547 - classification_loss: 0.0471
244/500 [=============>................] - ETA: 1:58 - loss: 0.3017 - regression_loss: 0.2546 - classification_loss: 0.0471
245/500 [=============>................] - ETA: 1:58 - loss: 0.3009 - regression_loss: 0.2540 - classification_loss: 0.0470
246/500 [=============>................] - ETA: 1:57 - loss: 0.3004 - regression_loss: 0.2535 - classification_loss: 0.0469
247/500 [=============>................] - ETA: 1:57 - loss: 0.2998 - regression_loss: 0.2531 - classification_loss: 0.0468
248/500 [=============>................] - ETA: 1:56 - loss: 0.2990 - regression_loss: 0.2523 - classification_loss: 0.0467
249/500 [=============>................] - ETA: 1:56 - loss: 0.2996 - regression_loss: 0.2528 - classification_loss: 0.0468
250/500 [==============>...............] - ETA: 1:55 - loss: 0.2996 - regression_loss: 0.2528 - classification_loss: 0.0467
251/500 [==============>...............] - ETA: 1:55 - loss: 0.3002 - regression_loss: 0.2533 - classification_loss: 0.0469
252/500 [==============>...............] - ETA: 1:54 - loss: 0.2992 - regression_loss: 0.2524 - classification_loss: 0.0468
253/500 [==============>...............] - ETA: 1:54 - loss: 0.2986 - regression_loss: 0.2519 - classification_loss: 0.0467
254/500 [==============>...............] - ETA: 1:53 - loss: 0.2985 - regression_loss: 0.2519 - classification_loss: 0.0466
255/500 [==============>...............] - ETA: 1:53 - loss: 0.2978 - regression_loss: 0.2512 - classification_loss: 0.0466
256/500 [==============>...............] - ETA: 1:53 - loss: 0.2976 - regression_loss: 0.2511 - classification_loss: 0.0465
257/500 [==============>...............] - ETA: 1:52 - loss: 0.2985 - regression_loss: 0.2518 - classification_loss: 0.0467
258/500 [==============>...............] - ETA: 1:52 - loss: 0.2981 - regression_loss: 0.2515 - classification_loss: 0.0466
259/500 [==============>...............] - ETA: 1:51 - loss: 0.2974 - regression_loss: 0.2508 - classification_loss: 0.0465
260/500 [==============>...............] - ETA: 1:51 - loss: 0.2966 - regression_loss: 0.2502 - classification_loss: 0.0464
261/500 [==============>...............] - ETA: 1:50 - loss: 0.2973 - regression_loss: 0.2507 - classification_loss: 0.0466
262/500 [==============>...............] - ETA: 1:50 - loss: 0.2964 - regression_loss: 0.2499 - classification_loss: 0.0465
263/500 [==============>...............] - ETA: 1:49 - loss: 0.2966 - regression_loss: 0.2502 - classification_loss: 0.0464
264/500 [==============>...............] - ETA: 1:49 - loss: 0.2957 - regression_loss: 0.2495 - classification_loss: 0.0463
265/500 [==============>...............] - ETA: 1:48 - loss: 0.2953 - regression_loss: 0.2491 - classification_loss: 0.0463
266/500 [==============>...............] - ETA: 1:48 - loss: 0.2961 - regression_loss: 0.2497 - classification_loss: 0.0464
267/500 [===============>..............] - ETA: 1:47 - loss: 0.2963 - regression_loss: 0.2499 - classification_loss: 0.0464
268/500 [===============>..............] - ETA: 1:47 - loss: 0.2957 - regression_loss: 0.2494 - classification_loss: 0.0463
269/500 [===============>..............] - ETA: 1:46 - loss: 0.2949 - regression_loss: 0.2487 - classification_loss: 0.0462
270/500 [===============>..............] - ETA: 1:46 - loss: 0.2942 - regression_loss: 0.2481 - classification_loss: 0.0461
271/500 [===============>..............] - ETA: 1:46 - loss: 0.2949 - regression_loss: 0.2486 - classification_loss: 0.0462
272/500 [===============>..............] - ETA: 1:45 - loss: 0.2948 - regression_loss: 0.2486 - classification_loss: 0.0462
273/500 [===============>..............] - ETA: 1:45 - loss: 0.2942 - regression_loss: 0.2481 - classification_loss: 0.0461
274/500 [===============>..............] - ETA: 1:44 - loss: 0.2933 - regression_loss: 0.2473 - classification_loss: 0.0460
275/500 [===============>..............] - ETA: 1:44 - loss: 0.2926 - regression_loss: 0.2466 - classification_loss: 0.0459
276/500 [===============>..............] - ETA: 1:43 - loss: 0.2927 - regression_loss: 0.2468 - classification_loss: 0.0459
277/500 [===============>..............] - ETA: 1:43 - loss: 0.2917 - regression_loss: 0.2460 - classification_loss: 0.0458
278/500 [===============>..............] - ETA: 1:42 - loss: 0.2909 - regression_loss: 0.2452 - classification_loss: 0.0457
279/500 [===============>..............] - ETA: 1:42 - loss: 0.2917 - regression_loss: 0.2459 - classification_loss: 0.0458
280/500 [===============>..............] - ETA: 1:41 - loss: 0.2913 - regression_loss: 0.2455 - classification_loss: 0.0458
281/500 [===============>..............] - ETA: 1:41 - loss: 0.2912 - regression_loss: 0.2455 - classification_loss: 0.0457
282/500 [===============>..............] - ETA: 1:40 - loss: 0.2905 - regression_loss: 0.2449 - classification_loss: 0.0456
283/500 [===============>..............] - ETA: 1:40 - loss: 0.2901 - regression_loss: 0.2445 - classification_loss: 0.0456
284/500 [================>.............] - ETA: 1:40 - loss: 0.2898 - regression_loss: 0.2443 - classification_loss: 0.0455
285/500 [================>.............] - ETA: 1:39 - loss: 0.2903 - regression_loss: 0.2448 - classification_loss: 0.0456
286/500 [================>.............] - ETA: 1:39 - loss: 0.2902 - regression_loss: 0.2447 - classification_loss: 0.0455
287/500 [================>.............] - ETA: 1:38 - loss: 0.2908 - regression_loss: 0.2451 - classification_loss: 0.0457
288/500 [================>.............] - ETA: 1:38 - loss: 0.2899 - regression_loss: 0.2444 - classification_loss: 0.0456
289/500 [================>.............] - ETA: 1:37 - loss: 0.2894 - regression_loss: 0.2439 - classification_loss: 0.0455
290/500 [================>.............] - ETA: 1:37 - loss: 0.2888 - regression_loss: 0.2434 - classification_loss: 0.0454
291/500 [================>.............] - ETA: 1:36 - loss: 0.2882 - regression_loss: 0.2429 - classification_loss: 0.0454
292/500 [================>.............] - ETA: 1:36 - loss: 0.2881 - regression_loss: 0.2427 - classification_loss: 0.0453
293/500 [================>.............] - ETA: 1:35 - loss: 0.2887 - regression_loss: 0.2432 - classification_loss: 0.0454
294/500 [================>.............] - ETA: 1:35 - loss: 0.2879 - regression_loss: 0.2426 - classification_loss: 0.0453
295/500 [================>.............] - ETA: 1:34 - loss: 0.2873 - regression_loss: 0.2421 - classification_loss: 0.0452
296/500 [================>.............] - ETA: 1:34 - loss: 0.2879 - regression_loss: 0.2425 - classification_loss: 0.0453
297/500 [================>.............] - ETA: 1:34 - loss: 0.2871 - regression_loss: 0.2419 - classification_loss: 0.0452
298/500 [================>.............] - ETA: 1:33 - loss: 0.2863 - regression_loss: 0.2411 - classification_loss: 0.0451
299/500 [================>.............] - ETA: 1:33 - loss: 0.2862 - regression_loss: 0.2411 - classification_loss: 0.0451
300/500 [=================>............] - ETA: 1:32 - loss: 0.2863 - regression_loss: 0.2413 - classification_loss: 0.0450
301/500 [=================>............] - ETA: 1:32 - loss: 0.2863 - regression_loss: 0.2413 - classification_loss: 0.0450
302/500 [=================>............] - ETA: 1:31 - loss: 0.2859 - regression_loss: 0.2409 - classification_loss: 0.0449
303/500 [=================>............] - ETA: 1:31 - loss: 0.2858 - regression_loss: 0.2409 - classification_loss: 0.0449
304/500 [=================>............] - ETA: 1:30 - loss: 0.2851 - regression_loss: 0.2403 - classification_loss: 0.0448
305/500 [=================>............] - ETA: 1:30 - loss: 0.2867 - regression_loss: 0.2417 - classification_loss: 0.0449
306/500 [=================>............] - ETA: 1:29 - loss: 0.2858 - regression_loss: 0.2410 - classification_loss: 0.0448
307/500 [=================>............] - ETA: 1:29 - loss: 0.2872 - regression_loss: 0.2422 - classification_loss: 0.0450
308/500 [=================>............] - ETA: 1:28 - loss: 0.2869 - regression_loss: 0.2420 - classification_loss: 0.0449
309/500 [=================>............] - ETA: 1:28 - loss: 0.2869 - regression_loss: 0.2421 - classification_loss: 0.0448
310/500 [=================>............] - ETA: 1:28 - loss: 0.2864 - regression_loss: 0.2416 - classification_loss: 0.0448
311/500 [=================>............] - ETA: 1:27 - loss: 0.2859 - regression_loss: 0.2412 - classification_loss: 0.0447
312/500 [=================>............] - ETA: 1:27 - loss: 0.2867 - regression_loss: 0.2419 - classification_loss: 0.0448
313/500 [=================>............] - ETA: 1:26 - loss: 0.2868 - regression_loss: 0.2421 - classification_loss: 0.0447
314/500 [=================>............] - ETA: 1:26 - loss: 0.2866 - regression_loss: 0.2419 - classification_loss: 0.0447
315/500 [=================>............] - ETA: 1:25 - loss: 0.2866 - regression_loss: 0.2419 - classification_loss: 0.0447
316/500 [=================>............] - ETA: 1:25 - loss: 0.2873 - regression_loss: 0.2425 - classification_loss: 0.0448
317/500 [==================>...........] - ETA: 1:24 - loss: 0.2872 - regression_loss: 0.2425 - classification_loss: 0.0448
318/500 [==================>...........] - ETA: 1:24 - loss: 0.2868 - regression_loss: 0.2421 - classification_loss: 0.0447
319/500 [==================>...........] - ETA: 1:23 - loss: 0.2867 - regression_loss: 0.2421 - classification_loss: 0.0446
320/500 [==================>...........] - ETA: 1:23 - loss: 0.2863 - regression_loss: 0.2417 - classification_loss: 0.0446
321/500 [==================>...........] - ETA: 1:22 - loss: 0.2860 - regression_loss: 0.2414 - classification_loss: 0.0445
322/500 [==================>...........] - ETA: 1:22 - loss: 0.2853 - regression_loss: 0.2408 - classification_loss: 0.0445
323/500 [==================>...........] - ETA: 1:21 - loss: 0.2853 - regression_loss: 0.2408 - classification_loss: 0.0444
324/500 [==================>...........] - ETA: 1:21 - loss: 0.2858 - regression_loss: 0.2413 - classification_loss: 0.0445
325/500 [==================>...........] - ETA: 1:21 - loss: 0.2851 - regression_loss: 0.2406 - classification_loss: 0.0444
326/500 [==================>...........] - ETA: 1:20 - loss: 0.2847 - regression_loss: 0.2403 - classification_loss: 0.0444
327/500 [==================>...........] - ETA: 1:20 - loss: 0.2847 - regression_loss: 0.2403 - classification_loss: 0.0443
328/500 [==================>...........] - ETA: 1:19 - loss: 0.2853 - regression_loss: 0.2409 - classification_loss: 0.0445
329/500 [==================>...........] - ETA: 1:19 - loss: 0.2848 - regression_loss: 0.2404 - classification_loss: 0.0444
330/500 [==================>...........] - ETA: 1:18 - loss: 0.2845 - regression_loss: 0.2402 - classification_loss: 0.0443
331/500 [==================>...........] - ETA: 1:18 - loss: 0.2841 - regression_loss: 0.2399 - classification_loss: 0.0442
332/500 [==================>...........] - ETA: 1:17 - loss: 0.2842 - regression_loss: 0.2400 - classification_loss: 0.0442
333/500 [==================>...........] - ETA: 1:17 - loss: 0.2839 - regression_loss: 0.2397 - classification_loss: 0.0441
334/500 [===================>..........] - ETA: 1:16 - loss: 0.2845 - regression_loss: 0.2402 - classification_loss: 0.0443
335/500 [===================>..........] - ETA: 1:16 - loss: 0.2839 - regression_loss: 0.2398 - classification_loss: 0.0442
336/500 [===================>..........] - ETA: 1:15 - loss: 0.2834 - regression_loss: 0.2393 - classification_loss: 0.0441
337/500 [===================>..........] - ETA: 1:15 - loss: 0.2838 - regression_loss: 0.2396 - classification_loss: 0.0442
338/500 [===================>..........] - ETA: 1:15 - loss: 0.2831 - regression_loss: 0.2390 - classification_loss: 0.0442
339/500 [===================>..........] - ETA: 1:14 - loss: 0.2829 - regression_loss: 0.2389 - classification_loss: 0.0441
340/500 [===================>..........] - ETA: 1:14 - loss: 0.2830 - regression_loss: 0.2390 - classification_loss: 0.0440
341/500 [===================>..........] - ETA: 1:13 - loss: 0.2838 - regression_loss: 0.2397 - classification_loss: 0.0441
342/500 [===================>..........] - ETA: 1:13 - loss: 0.2832 - regression_loss: 0.2391 - classification_loss: 0.0440
343/500 [===================>..........] - ETA: 1:12 - loss: 0.2826 - regression_loss: 0.2386 - classification_loss: 0.0440
344/500 [===================>..........] - ETA: 1:12 - loss: 0.2824 - regression_loss: 0.2385 - classification_loss: 0.0439
345/500 [===================>..........] - ETA: 1:11 - loss: 0.2822 - regression_loss: 0.2383 - classification_loss: 0.0439
346/500 [===================>..........] - ETA: 1:11 - loss: 0.2818 - regression_loss: 0.2379 - classification_loss: 0.0438
347/500 [===================>..........] - ETA: 1:10 - loss: 0.2824 - regression_loss: 0.2384 - classification_loss: 0.0439
348/500 [===================>..........] - ETA: 1:10 - loss: 0.2825 - regression_loss: 0.2386 - classification_loss: 0.0439
349/500 [===================>..........] - ETA: 1:09 - loss: 0.2821 - regression_loss: 0.2382 - classification_loss: 0.0438
350/500 [====================>.........] - ETA: 1:09 - loss: 0.2819 - regression_loss: 0.2381 - classification_loss: 0.0437
351/500 [====================>.........] - ETA: 1:09 - loss: 0.2817 - regression_loss: 0.2380 - classification_loss: 0.0437
352/500 [====================>.........] - ETA: 1:08 - loss: 0.2810 - regression_loss: 0.2374 - classification_loss: 0.0436
353/500 [====================>.........] - ETA: 1:08 - loss: 0.2817 - regression_loss: 0.2380 - classification_loss: 0.0437
354/500 [====================>.........] - ETA: 1:07 - loss: 0.2815 - regression_loss: 0.2378 - classification_loss: 0.0437
355/500 [====================>.........] - ETA: 1:07 - loss: 0.2814 - regression_loss: 0.2378 - classification_loss: 0.0436
356/500 [====================>.........] - ETA: 1:06 - loss: 0.2813 - regression_loss: 0.2377 - classification_loss: 0.0436
357/500 [====================>.........] - ETA: 1:06 - loss: 0.2819 - regression_loss: 0.2382 - classification_loss: 0.0437
358/500 [====================>.........] - ETA: 1:05 - loss: 0.2816 - regression_loss: 0.2380 - classification_loss: 0.0436
359/500 [====================>.........] - ETA: 1:05 - loss: 0.2812 - regression_loss: 0.2376 - classification_loss: 0.0436
360/500 [====================>.........] - ETA: 1:04 - loss: 0.2813 - regression_loss: 0.2378 - classification_loss: 0.0435
361/500 [====================>.........] - ETA: 1:04 - loss: 0.2812 - regression_loss: 0.2378 - classification_loss: 0.0434
362/500 [====================>.........] - ETA: 1:03 - loss: 0.2817 - regression_loss: 0.2382 - classification_loss: 0.0435
363/500 [====================>.........] - ETA: 1:03 - loss: 0.2811 - regression_loss: 0.2376 - classification_loss: 0.0435
364/500 [====================>.........] - ETA: 1:02 - loss: 0.2805 - regression_loss: 0.2371 - classification_loss: 0.0434
365/500 [====================>.........] - ETA: 1:02 - loss: 0.2802 - regression_loss: 0.2369 - classification_loss: 0.0433
366/500 [====================>.........] - ETA: 1:02 - loss: 0.2810 - regression_loss: 0.2376 - classification_loss: 0.0434
367/500 [=====================>........] - ETA: 1:01 - loss: 0.2808 - regression_loss: 0.2374 - classification_loss: 0.0434
368/500 [=====================>........] - ETA: 1:01 - loss: 0.2807 - regression_loss: 0.2374 - classification_loss: 0.0433
369/500 [=====================>........] - ETA: 1:00 - loss: 0.2807 - regression_loss: 0.2374 - classification_loss: 0.0433
370/500 [=====================>........] - ETA: 1:00 - loss: 0.2803 - regression_loss: 0.2371 - classification_loss: 0.0432
371/500 [=====================>........] - ETA: 59s - loss: 0.2799 - regression_loss: 0.2367 - classification_loss: 0.0432 
372/500 [=====================>........] - ETA: 59s - loss: 0.2793 - regression_loss: 0.2362 - classification_loss: 0.0431
373/500 [=====================>........] - ETA: 58s - loss: 0.2792 - regression_loss: 0.2362 - classification_loss: 0.0431
374/500 [=====================>........] - ETA: 58s - loss: 0.2789 - regression_loss: 0.2359 - classification_loss: 0.0430
375/500 [=====================>........] - ETA: 57s - loss: 0.2794 - regression_loss: 0.2363 - classification_loss: 0.0431
376/500 [=====================>........] - ETA: 57s - loss: 0.2799 - regression_loss: 0.2367 - classification_loss: 0.0432
377/500 [=====================>........] - ETA: 56s - loss: 0.2796 - regression_loss: 0.2365 - classification_loss: 0.0431
378/500 [=====================>........] - ETA: 56s - loss: 0.2796 - regression_loss: 0.2365 - classification_loss: 0.0431
379/500 [=====================>........] - ETA: 56s - loss: 0.2792 - regression_loss: 0.2362 - classification_loss: 0.0430
380/500 [=====================>........] - ETA: 55s - loss: 0.2794 - regression_loss: 0.2364 - classification_loss: 0.0430
381/500 [=====================>........] - ETA: 55s - loss: 0.2794 - regression_loss: 0.2365 - classification_loss: 0.0429
382/500 [=====================>........] - ETA: 54s - loss: 0.2790 - regression_loss: 0.2361 - classification_loss: 0.0428
383/500 [=====================>........] - ETA: 54s - loss: 0.2796 - regression_loss: 0.2367 - classification_loss: 0.0429
384/500 [======================>.......] - ETA: 53s - loss: 0.2793 - regression_loss: 0.2364 - classification_loss: 0.0429
385/500 [======================>.......] - ETA: 53s - loss: 0.2794 - regression_loss: 0.2365 - classification_loss: 0.0429
386/500 [======================>.......] - ETA: 52s - loss: 0.2787 - regression_loss: 0.2360 - classification_loss: 0.0428
387/500 [======================>.......] - ETA: 52s - loss: 0.2783 - regression_loss: 0.2356 - classification_loss: 0.0427
388/500 [======================>.......] - ETA: 51s - loss: 0.2782 - regression_loss: 0.2355 - classification_loss: 0.0427
389/500 [======================>.......] - ETA: 51s - loss: 0.2786 - regression_loss: 0.2358 - classification_loss: 0.0428
390/500 [======================>.......] - ETA: 50s - loss: 0.2783 - regression_loss: 0.2355 - classification_loss: 0.0427
391/500 [======================>.......] - ETA: 50s - loss: 0.2779 - regression_loss: 0.2353 - classification_loss: 0.0427
392/500 [======================>.......] - ETA: 50s - loss: 0.2778 - regression_loss: 0.2352 - classification_loss: 0.0426
393/500 [======================>.......] - ETA: 49s - loss: 0.2782 - regression_loss: 0.2355 - classification_loss: 0.0427
394/500 [======================>.......] - ETA: 49s - loss: 0.2777 - regression_loss: 0.2350 - classification_loss: 0.0427
395/500 [======================>.......] - ETA: 48s - loss: 0.2771 - regression_loss: 0.2345 - classification_loss: 0.0426
396/500 [======================>.......] - ETA: 48s - loss: 0.2765 - regression_loss: 0.2340 - classification_loss: 0.0425
397/500 [======================>.......] - ETA: 47s - loss: 0.2759 - regression_loss: 0.2334 - classification_loss: 0.0425
398/500 [======================>.......] - ETA: 47s - loss: 0.2756 - regression_loss: 0.2331 - classification_loss: 0.0424
399/500 [======================>.......] - ETA: 46s - loss: 0.2759 - regression_loss: 0.2334 - classification_loss: 0.0425
400/500 [=======================>......] - ETA: 46s - loss: 0.2759 - regression_loss: 0.2334 - classification_loss: 0.0425
401/500 [=======================>......] - ETA: 45s - loss: 0.2757 - regression_loss: 0.2333 - classification_loss: 0.0424
402/500 [=======================>......] - ETA: 45s - loss: 0.2760 - regression_loss: 0.2336 - classification_loss: 0.0425
403/500 [=======================>......] - ETA: 44s - loss: 0.2759 - regression_loss: 0.2335 - classification_loss: 0.0425
404/500 [=======================>......] - ETA: 44s - loss: 0.2756 - regression_loss: 0.2332 - classification_loss: 0.0424
405/500 [=======================>......] - ETA: 44s - loss: 0.2751 - regression_loss: 0.2328 - classification_loss: 0.0424
406/500 [=======================>......] - ETA: 43s - loss: 0.2746 - regression_loss: 0.2323 - classification_loss: 0.0423
407/500 [=======================>......] - ETA: 43s - loss: 0.2743 - regression_loss: 0.2320 - classification_loss: 0.0423
408/500 [=======================>......] - ETA: 42s - loss: 0.2742 - regression_loss: 0.2320 - classification_loss: 0.0422
409/500 [=======================>......] - ETA: 42s - loss: 0.2738 - regression_loss: 0.2316 - classification_loss: 0.0421
410/500 [=======================>......] - ETA: 41s - loss: 0.2742 - regression_loss: 0.2319 - classification_loss: 0.0422
411/500 [=======================>......] - ETA: 41s - loss: 0.2736 - regression_loss: 0.2315 - classification_loss: 0.0422
412/500 [=======================>......] - ETA: 40s - loss: 0.2736 - regression_loss: 0.2315 - classification_loss: 0.0421
413/500 [=======================>......] - ETA: 40s - loss: 0.2734 - regression_loss: 0.2313 - classification_loss: 0.0421
414/500 [=======================>......] - ETA: 39s - loss: 0.2737 - regression_loss: 0.2316 - classification_loss: 0.0421
415/500 [=======================>......] - ETA: 39s - loss: 0.2735 - regression_loss: 0.2314 - classification_loss: 0.0421
416/500 [=======================>......] - ETA: 38s - loss: 0.2733 - regression_loss: 0.2313 - classification_loss: 0.0421
417/500 [========================>.....] - ETA: 38s - loss: 0.2737 - regression_loss: 0.2315 - classification_loss: 0.0421
418/500 [========================>.....] - ETA: 38s - loss: 0.2733 - regression_loss: 0.2313 - classification_loss: 0.0421
419/500 [========================>.....] - ETA: 37s - loss: 0.2731 - regression_loss: 0.2311 - classification_loss: 0.0420
420/500 [========================>.....] - ETA: 37s - loss: 0.2731 - regression_loss: 0.2311 - classification_loss: 0.0420
421/500 [========================>.....] - ETA: 36s - loss: 0.2729 - regression_loss: 0.2310 - classification_loss: 0.0419
422/500 [========================>.....] - ETA: 36s - loss: 0.2723 - regression_loss: 0.2305 - classification_loss: 0.0418
423/500 [========================>.....] - ETA: 35s - loss: 0.2728 - regression_loss: 0.2309 - classification_loss: 0.0419
424/500 [========================>.....] - ETA: 35s - loss: 0.2726 - regression_loss: 0.2308 - classification_loss: 0.0419
425/500 [========================>.....] - ETA: 34s - loss: 0.2724 - regression_loss: 0.2306 - classification_loss: 0.0418
426/500 [========================>.....] - ETA: 34s - loss: 0.2727 - regression_loss: 0.2308 - classification_loss: 0.0419
427/500 [========================>.....] - ETA: 33s - loss: 0.2724 - regression_loss: 0.2306 - classification_loss: 0.0418
428/500 [========================>.....] - ETA: 33s - loss: 0.2720 - regression_loss: 0.2303 - classification_loss: 0.0418
429/500 [========================>.....] - ETA: 32s - loss: 0.2717 - regression_loss: 0.2300 - classification_loss: 0.0417
430/500 [========================>.....] - ETA: 32s - loss: 0.2718 - regression_loss: 0.2302 - classification_loss: 0.0417
431/500 [========================>.....] - ETA: 31s - loss: 0.2715 - regression_loss: 0.2299 - classification_loss: 0.0416
432/500 [========================>.....] - ETA: 31s - loss: 0.2711 - regression_loss: 0.2295 - classification_loss: 0.0416
433/500 [========================>.....] - ETA: 31s - loss: 0.2715 - regression_loss: 0.2298 - classification_loss: 0.0416
434/500 [=========================>....] - ETA: 30s - loss: 0.2715 - regression_loss: 0.2299 - classification_loss: 0.0416
435/500 [=========================>....] - ETA: 30s - loss: 0.2712 - regression_loss: 0.2296 - classification_loss: 0.0415
436/500 [=========================>....] - ETA: 29s - loss: 0.2711 - regression_loss: 0.2297 - classification_loss: 0.0415
437/500 [=========================>....] - ETA: 29s - loss: 0.2711 - regression_loss: 0.2297 - classification_loss: 0.0415
438/500 [=========================>....] - ETA: 28s - loss: 0.2708 - regression_loss: 0.2294 - classification_loss: 0.0414
439/500 [=========================>....] - ETA: 28s - loss: 0.2711 - regression_loss: 0.2296 - classification_loss: 0.0415
440/500 [=========================>....] - ETA: 27s - loss: 0.2707 - regression_loss: 0.2292 - classification_loss: 0.0414
441/500 [=========================>....] - ETA: 27s - loss: 0.2703 - regression_loss: 0.2289 - classification_loss: 0.0414
442/500 [=========================>....] - ETA: 26s - loss: 0.2698 - regression_loss: 0.2284 - classification_loss: 0.0413
443/500 [=========================>....] - ETA: 26s - loss: 0.2696 - regression_loss: 0.2283 - classification_loss: 0.0413
444/500 [=========================>....] - ETA: 25s - loss: 0.2700 - regression_loss: 0.2286 - classification_loss: 0.0414
445/500 [=========================>....] - ETA: 25s - loss: 0.2695 - regression_loss: 0.2282 - classification_loss: 0.0413
446/500 [=========================>....] - ETA: 25s - loss: 0.2690 - regression_loss: 0.2277 - classification_loss: 0.0413
447/500 [=========================>....] - ETA: 24s - loss: 0.2686 - regression_loss: 0.2274 - classification_loss: 0.0412
448/500 [=========================>....] - ETA: 24s - loss: 0.2690 - regression_loss: 0.2277 - classification_loss: 0.0413
449/500 [=========================>....] - ETA: 23s - loss: 0.2687 - regression_loss: 0.2275 - classification_loss: 0.0412
450/500 [==========================>...] - ETA: 23s - loss: 0.2687 - regression_loss: 0.2275 - classification_loss: 0.0412
451/500 [==========================>...] - ETA: 22s - loss: 0.2686 - regression_loss: 0.2274 - classification_loss: 0.0412
452/500 [==========================>...] - ETA: 22s - loss: 0.2684 - regression_loss: 0.2273 - classification_loss: 0.0411
453/500 [==========================>...] - ETA: 21s - loss: 0.2681 - regression_loss: 0.2270 - classification_loss: 0.0411
454/500 [==========================>...] - ETA: 21s - loss: 0.2676 - regression_loss: 0.2266 - classification_loss: 0.0410
455/500 [==========================>...] - ETA: 20s - loss: 0.2680 - regression_loss: 0.2270 - classification_loss: 0.0411
456/500 [==========================>...] - ETA: 20s - loss: 0.2677 - regression_loss: 0.2267 - classification_loss: 0.0410
457/500 [==========================>...] - ETA: 19s - loss: 0.2680 - regression_loss: 0.2269 - classification_loss: 0.0411
458/500 [==========================>...] - ETA: 19s - loss: 0.2678 - regression_loss: 0.2268 - classification_loss: 0.0410
459/500 [==========================>...] - ETA: 19s - loss: 0.2678 - regression_loss: 0.2268 - classification_loss: 0.0410
460/500 [==========================>...] - ETA: 18s - loss: 0.2675 - regression_loss: 0.2266 - classification_loss: 0.0409
461/500 [==========================>...] - ETA: 18s - loss: 0.2673 - regression_loss: 0.2264 - classification_loss: 0.0409
462/500 [==========================>...] - ETA: 17s - loss: 0.2673 - regression_loss: 0.2264 - classification_loss: 0.0409
463/500 [==========================>...] - ETA: 17s - loss: 0.2672 - regression_loss: 0.2264 - classification_loss: 0.0408
464/500 [==========================>...] - ETA: 16s - loss: 0.2678 - regression_loss: 0.2269 - classification_loss: 0.0409
465/500 [==========================>...] - ETA: 16s - loss: 0.2674 - regression_loss: 0.2266 - classification_loss: 0.0408
466/500 [==========================>...] - ETA: 15s - loss: 0.2671 - regression_loss: 0.2263 - classification_loss: 0.0408
467/500 [===========================>..] - ETA: 15s - loss: 0.2667 - regression_loss: 0.2260 - classification_loss: 0.0408
468/500 [===========================>..] - ETA: 14s - loss: 0.2670 - regression_loss: 0.2262 - classification_loss: 0.0408
469/500 [===========================>..] - ETA: 14s - loss: 0.2666 - regression_loss: 0.2258 - classification_loss: 0.0408
470/500 [===========================>..] - ETA: 13s - loss: 0.2666 - regression_loss: 0.2259 - classification_loss: 0.0407
471/500 [===========================>..] - ETA: 13s - loss: 0.2662 - regression_loss: 0.2255 - classification_loss: 0.0407
472/500 [===========================>..] - ETA: 12s - loss: 0.2659 - regression_loss: 0.2253 - classification_loss: 0.0406
473/500 [===========================>..] - ETA: 12s - loss: 0.2662 - regression_loss: 0.2255 - classification_loss: 0.0407
474/500 [===========================>..] - ETA: 12s - loss: 0.2662 - regression_loss: 0.2256 - classification_loss: 0.0406
475/500 [===========================>..] - ETA: 11s - loss: 0.2659 - regression_loss: 0.2253 - classification_loss: 0.0406
476/500 [===========================>..] - ETA: 11s - loss: 0.2655 - regression_loss: 0.2249 - classification_loss: 0.0405
477/500 [===========================>..] - ETA: 10s - loss: 0.2654 - regression_loss: 0.2249 - classification_loss: 0.0405
478/500 [===========================>..] - ETA: 10s - loss: 0.2658 - regression_loss: 0.2252 - classification_loss: 0.0406
479/500 [===========================>..] - ETA: 9s - loss: 0.2655 - regression_loss: 0.2250 - classification_loss: 0.0405 
480/500 [===========================>..] - ETA: 9s - loss: 0.2654 - regression_loss: 0.2249 - classification_loss: 0.0405
481/500 [===========================>..] - ETA: 8s - loss: 0.2652 - regression_loss: 0.2248 - classification_loss: 0.0404
482/500 [===========================>..] - ETA: 8s - loss: 0.2650 - regression_loss: 0.2246 - classification_loss: 0.0404
483/500 [===========================>..] - ETA: 7s - loss: 0.2646 - regression_loss: 0.2243 - classification_loss: 0.0403
484/500 [============================>.] - ETA: 7s - loss: 0.2642 - regression_loss: 0.2239 - classification_loss: 0.0403
485/500 [============================>.] - ETA: 6s - loss: 0.2644 - regression_loss: 0.2241 - classification_loss: 0.0403
486/500 [============================>.] - ETA: 6s - loss: 0.2641 - regression_loss: 0.2238 - classification_loss: 0.0403
487/500 [============================>.] - ETA: 6s - loss: 0.2645 - regression_loss: 0.2241 - classification_loss: 0.0404
488/500 [============================>.] - ETA: 5s - loss: 0.2645 - regression_loss: 0.2241 - classification_loss: 0.0403
489/500 [============================>.] - ETA: 5s - loss: 0.2640 - regression_loss: 0.2237 - classification_loss: 0.0403
490/500 [============================>.] - ETA: 4s - loss: 0.2638 - regression_loss: 0.2235 - classification_loss: 0.0402
491/500 [============================>.] - ETA: 4s - loss: 0.2634 - regression_loss: 0.2232 - classification_loss: 0.0402
492/500 [============================>.] - ETA: 3s - loss: 0.2631 - regression_loss: 0.2230 - classification_loss: 0.0401
493/500 [============================>.] - ETA: 3s - loss: 0.2626 - regression_loss: 0.2225 - classification_loss: 0.0401
494/500 [============================>.] - ETA: 2s - loss: 0.2626 - regression_loss: 0.2226 - classification_loss: 0.0401
495/500 [============================>.] - ETA: 2s - loss: 0.2630 - regression_loss: 0.2228 - classification_loss: 0.0401
496/500 [============================>.] - ETA: 1s - loss: 0.2627 - regression_loss: 0.2227 - classification_loss: 0.0401
497/500 [============================>.] - ETA: 1s - loss: 0.2623 - regression_loss: 0.2223 - classification_loss: 0.0400
498/500 [============================>.] - ETA: 0s - loss: 0.2621 - regression_loss: 0.2221 - classification_loss: 0.0400
499/500 [============================>.] - ETA: 0s - loss: 0.2623 - regression_loss: 0.2223 - classification_loss: 0.0400
500/500 [==============================] - 232s 464ms/step - loss: 0.2622 - regression_loss: 0.2222 - classification_loss: 0.0400
44 instances of class building with average precision: 0.7658
mAP: 0.7658

Epoch 00002: saving model to ./snapshots/resnet50_csv_02.h5
Epoch 3/8

  1/500 [..............................] - ETA: 3:49 - loss: 0.1097 - regression_loss: 0.0845 - classification_loss: 0.0252
  2/500 [..............................] - ETA: 3:49 - loss: 0.1033 - regression_loss: 0.0839 - classification_loss: 0.0194
  3/500 [..............................] - ETA: 3:48 - loss: 0.2053 - regression_loss: 0.1687 - classification_loss: 0.0366
  4/500 [..............................] - ETA: 3:49 - loss: 0.1688 - regression_loss: 0.1382 - classification_loss: 0.0306
  5/500 [..............................] - ETA: 3:48 - loss: 0.1782 - regression_loss: 0.1488 - classification_loss: 0.0294
  6/500 [..............................] - ETA: 3:48 - loss: 0.2082 - regression_loss: 0.1727 - classification_loss: 0.0356
  7/500 [..............................] - ETA: 3:48 - loss: 0.1809 - regression_loss: 0.1486 - classification_loss: 0.0323
  8/500 [..............................] - ETA: 3:47 - loss: 0.1937 - regression_loss: 0.1626 - classification_loss: 0.0310
  9/500 [..............................] - ETA: 3:47 - loss: 0.1878 - regression_loss: 0.1587 - classification_loss: 0.0291
 10/500 [..............................] - ETA: 3:46 - loss: 0.1802 - regression_loss: 0.1520 - classification_loss: 0.0282
 11/500 [..............................] - ETA: 3:46 - loss: 0.1738 - regression_loss: 0.1470 - classification_loss: 0.0268
 12/500 [..............................] - ETA: 3:46 - loss: 0.1652 - regression_loss: 0.1396 - classification_loss: 0.0256
 13/500 [..............................] - ETA: 3:45 - loss: 0.1862 - regression_loss: 0.1571 - classification_loss: 0.0291
 14/500 [..............................] - ETA: 3:45 - loss: 0.1797 - regression_loss: 0.1511 - classification_loss: 0.0285
 15/500 [..............................] - ETA: 3:44 - loss: 0.1821 - regression_loss: 0.1539 - classification_loss: 0.0282
 16/500 [..............................] - ETA: 3:44 - loss: 0.1757 - regression_loss: 0.1478 - classification_loss: 0.0279
 17/500 [>.............................] - ETA: 3:43 - loss: 0.1695 - regression_loss: 0.1425 - classification_loss: 0.0270
 18/500 [>.............................] - ETA: 3:43 - loss: 0.1710 - regression_loss: 0.1448 - classification_loss: 0.0262
 19/500 [>.............................] - ETA: 3:42 - loss: 0.1729 - regression_loss: 0.1468 - classification_loss: 0.0261
 20/500 [>.............................] - ETA: 3:42 - loss: 0.1841 - regression_loss: 0.1561 - classification_loss: 0.0280
 21/500 [>.............................] - ETA: 3:42 - loss: 0.1841 - regression_loss: 0.1564 - classification_loss: 0.0278
 22/500 [>.............................] - ETA: 3:41 - loss: 0.1770 - regression_loss: 0.1499 - classification_loss: 0.0271
 23/500 [>.............................] - ETA: 3:41 - loss: 0.1774 - regression_loss: 0.1510 - classification_loss: 0.0263
 24/500 [>.............................] - ETA: 3:40 - loss: 0.1849 - regression_loss: 0.1569 - classification_loss: 0.0279
 25/500 [>.............................] - ETA: 3:40 - loss: 0.1829 - regression_loss: 0.1551 - classification_loss: 0.0277
 26/500 [>.............................] - ETA: 3:40 - loss: 0.1859 - regression_loss: 0.1583 - classification_loss: 0.0275
 27/500 [>.............................] - ETA: 3:39 - loss: 0.1825 - regression_loss: 0.1552 - classification_loss: 0.0273
 28/500 [>.............................] - ETA: 3:39 - loss: 0.1779 - regression_loss: 0.1511 - classification_loss: 0.0268
 29/500 [>.............................] - ETA: 3:38 - loss: 0.1861 - regression_loss: 0.1580 - classification_loss: 0.0281
 30/500 [>.............................] - ETA: 3:38 - loss: 0.1829 - regression_loss: 0.1553 - classification_loss: 0.0276
 31/500 [>.............................] - ETA: 3:37 - loss: 0.1899 - regression_loss: 0.1610 - classification_loss: 0.0289
 32/500 [>.............................] - ETA: 3:37 - loss: 0.1849 - regression_loss: 0.1565 - classification_loss: 0.0283
 33/500 [>.............................] - ETA: 3:36 - loss: 0.1861 - regression_loss: 0.1579 - classification_loss: 0.0281
 34/500 [=>............................] - ETA: 3:36 - loss: 0.1820 - regression_loss: 0.1543 - classification_loss: 0.0277
 35/500 [=>............................] - ETA: 3:35 - loss: 0.1791 - regression_loss: 0.1516 - classification_loss: 0.0275
 36/500 [=>............................] - ETA: 3:35 - loss: 0.1793 - regression_loss: 0.1520 - classification_loss: 0.0273
 37/500 [=>............................] - ETA: 3:35 - loss: 0.1760 - regression_loss: 0.1492 - classification_loss: 0.0269
 38/500 [=>............................] - ETA: 3:34 - loss: 0.1805 - regression_loss: 0.1526 - classification_loss: 0.0279
 39/500 [=>............................] - ETA: 3:34 - loss: 0.1775 - regression_loss: 0.1501 - classification_loss: 0.0275
 40/500 [=>............................] - ETA: 3:33 - loss: 0.1753 - regression_loss: 0.1479 - classification_loss: 0.0273
 41/500 [=>............................] - ETA: 3:33 - loss: 0.1728 - regression_loss: 0.1456 - classification_loss: 0.0272
 42/500 [=>............................] - ETA: 3:33 - loss: 0.1784 - regression_loss: 0.1502 - classification_loss: 0.0282
 43/500 [=>............................] - ETA: 3:32 - loss: 0.1748 - regression_loss: 0.1470 - classification_loss: 0.0278
 44/500 [=>............................] - ETA: 3:32 - loss: 0.1761 - regression_loss: 0.1484 - classification_loss: 0.0277
 45/500 [=>............................] - ETA: 3:31 - loss: 0.1743 - regression_loss: 0.1470 - classification_loss: 0.0273
 46/500 [=>............................] - ETA: 3:31 - loss: 0.1789 - regression_loss: 0.1507 - classification_loss: 0.0282
 47/500 [=>............................] - ETA: 3:30 - loss: 0.1782 - regression_loss: 0.1502 - classification_loss: 0.0280
 48/500 [=>............................] - ETA: 3:30 - loss: 0.1775 - regression_loss: 0.1498 - classification_loss: 0.0277
 49/500 [=>............................] - ETA: 3:29 - loss: 0.1749 - regression_loss: 0.1476 - classification_loss: 0.0273
 50/500 [==>...........................] - ETA: 3:29 - loss: 0.1764 - regression_loss: 0.1492 - classification_loss: 0.0272
 51/500 [==>...........................] - ETA: 3:28 - loss: 0.1801 - regression_loss: 0.1522 - classification_loss: 0.0279
 52/500 [==>...........................] - ETA: 3:28 - loss: 0.1773 - regression_loss: 0.1497 - classification_loss: 0.0276
 53/500 [==>...........................] - ETA: 3:27 - loss: 0.1776 - regression_loss: 0.1501 - classification_loss: 0.0275
 54/500 [==>...........................] - ETA: 3:27 - loss: 0.1752 - regression_loss: 0.1480 - classification_loss: 0.0272
 55/500 [==>...........................] - ETA: 3:26 - loss: 0.1756 - regression_loss: 0.1485 - classification_loss: 0.0271
 56/500 [==>...........................] - ETA: 3:26 - loss: 0.1786 - regression_loss: 0.1508 - classification_loss: 0.0277
 57/500 [==>...........................] - ETA: 3:25 - loss: 0.1759 - regression_loss: 0.1485 - classification_loss: 0.0274
 58/500 [==>...........................] - ETA: 3:25 - loss: 0.1764 - regression_loss: 0.1491 - classification_loss: 0.0273
 59/500 [==>...........................] - ETA: 3:24 - loss: 0.1749 - regression_loss: 0.1477 - classification_loss: 0.0272
 60/500 [==>...........................] - ETA: 3:24 - loss: 0.1726 - regression_loss: 0.1456 - classification_loss: 0.0269
 61/500 [==>...........................] - ETA: 3:24 - loss: 0.1703 - regression_loss: 0.1436 - classification_loss: 0.0267
 62/500 [==>...........................] - ETA: 3:23 - loss: 0.1742 - regression_loss: 0.1469 - classification_loss: 0.0273
 63/500 [==>...........................] - ETA: 3:23 - loss: 0.1721 - regression_loss: 0.1450 - classification_loss: 0.0271
 64/500 [==>...........................] - ETA: 3:22 - loss: 0.1724 - regression_loss: 0.1454 - classification_loss: 0.0270
 65/500 [==>...........................] - ETA: 3:22 - loss: 0.1715 - regression_loss: 0.1446 - classification_loss: 0.0269
 66/500 [==>...........................] - ETA: 3:21 - loss: 0.1704 - regression_loss: 0.1436 - classification_loss: 0.0268
 67/500 [===>..........................] - ETA: 3:21 - loss: 0.1732 - regression_loss: 0.1458 - classification_loss: 0.0273
 68/500 [===>..........................] - ETA: 3:20 - loss: 0.1714 - regression_loss: 0.1443 - classification_loss: 0.0271
 69/500 [===>..........................] - ETA: 3:20 - loss: 0.1718 - regression_loss: 0.1447 - classification_loss: 0.0270
 70/500 [===>..........................] - ETA: 3:20 - loss: 0.1705 - regression_loss: 0.1437 - classification_loss: 0.0268
 71/500 [===>..........................] - ETA: 3:19 - loss: 0.1708 - regression_loss: 0.1440 - classification_loss: 0.0268
 72/500 [===>..........................] - ETA: 3:19 - loss: 0.1696 - regression_loss: 0.1430 - classification_loss: 0.0265
 73/500 [===>..........................] - ETA: 3:18 - loss: 0.1729 - regression_loss: 0.1457 - classification_loss: 0.0271
 74/500 [===>..........................] - ETA: 3:18 - loss: 0.1709 - regression_loss: 0.1440 - classification_loss: 0.0269
 75/500 [===>..........................] - ETA: 3:17 - loss: 0.1704 - regression_loss: 0.1436 - classification_loss: 0.0268
 76/500 [===>..........................] - ETA: 3:17 - loss: 0.1685 - regression_loss: 0.1419 - classification_loss: 0.0266
 77/500 [===>..........................] - ETA: 3:16 - loss: 0.1678 - regression_loss: 0.1413 - classification_loss: 0.0265
 78/500 [===>..........................] - ETA: 3:16 - loss: 0.1713 - regression_loss: 0.1442 - classification_loss: 0.0270
 79/500 [===>..........................] - ETA: 3:15 - loss: 0.1718 - regression_loss: 0.1450 - classification_loss: 0.0268
 80/500 [===>..........................] - ETA: 3:15 - loss: 0.1733 - regression_loss: 0.1465 - classification_loss: 0.0268
 81/500 [===>..........................] - ETA: 3:14 - loss: 0.1766 - regression_loss: 0.1493 - classification_loss: 0.0273
 82/500 [===>..........................] - ETA: 3:14 - loss: 0.1761 - regression_loss: 0.1490 - classification_loss: 0.0271
 83/500 [===>..........................] - ETA: 3:13 - loss: 0.1758 - regression_loss: 0.1488 - classification_loss: 0.0270
 84/500 [====>.........................] - ETA: 3:13 - loss: 0.1747 - regression_loss: 0.1479 - classification_loss: 0.0268
 85/500 [====>.........................] - ETA: 3:12 - loss: 0.1753 - regression_loss: 0.1485 - classification_loss: 0.0268
 86/500 [====>.........................] - ETA: 3:12 - loss: 0.1749 - regression_loss: 0.1482 - classification_loss: 0.0267
 87/500 [====>.........................] - ETA: 3:12 - loss: 0.1733 - regression_loss: 0.1468 - classification_loss: 0.0265
 88/500 [====>.........................] - ETA: 3:11 - loss: 0.1729 - regression_loss: 0.1465 - classification_loss: 0.0264
 89/500 [====>.........................] - ETA: 3:11 - loss: 0.1735 - regression_loss: 0.1471 - classification_loss: 0.0263
 90/500 [====>.........................] - ETA: 3:10 - loss: 0.1754 - regression_loss: 0.1487 - classification_loss: 0.0267
 91/500 [====>.........................] - ETA: 3:10 - loss: 0.1743 - regression_loss: 0.1478 - classification_loss: 0.0265
 92/500 [====>.........................] - ETA: 3:09 - loss: 0.1736 - regression_loss: 0.1473 - classification_loss: 0.0264
 93/500 [====>.........................] - ETA: 3:09 - loss: 0.1762 - regression_loss: 0.1495 - classification_loss: 0.0267
 94/500 [====>.........................] - ETA: 3:08 - loss: 0.1770 - regression_loss: 0.1504 - classification_loss: 0.0267
 95/500 [====>.........................] - ETA: 3:08 - loss: 0.1778 - regression_loss: 0.1512 - classification_loss: 0.0266
 96/500 [====>.........................] - ETA: 3:07 - loss: 0.1785 - regression_loss: 0.1519 - classification_loss: 0.0265
 97/500 [====>.........................] - ETA: 3:07 - loss: 0.1783 - regression_loss: 0.1519 - classification_loss: 0.0265
 98/500 [====>.........................] - ETA: 3:06 - loss: 0.1803 - regression_loss: 0.1534 - classification_loss: 0.0269
 99/500 [====>.........................] - ETA: 3:06 - loss: 0.1805 - regression_loss: 0.1536 - classification_loss: 0.0268
100/500 [=====>........................] - ETA: 3:05 - loss: 0.1799 - regression_loss: 0.1533 - classification_loss: 0.0267
101/500 [=====>........................] - ETA: 3:05 - loss: 0.1831 - regression_loss: 0.1561 - classification_loss: 0.0270
102/500 [=====>........................] - ETA: 3:05 - loss: 0.1826 - regression_loss: 0.1557 - classification_loss: 0.0269
103/500 [=====>........................] - ETA: 3:04 - loss: 0.1833 - regression_loss: 0.1565 - classification_loss: 0.0268
104/500 [=====>........................] - ETA: 3:04 - loss: 0.1821 - regression_loss: 0.1555 - classification_loss: 0.0266
105/500 [=====>........................] - ETA: 3:03 - loss: 0.1832 - regression_loss: 0.1566 - classification_loss: 0.0266
106/500 [=====>........................] - ETA: 3:03 - loss: 0.1823 - regression_loss: 0.1559 - classification_loss: 0.0264
107/500 [=====>........................] - ETA: 3:02 - loss: 0.1848 - regression_loss: 0.1580 - classification_loss: 0.0268
108/500 [=====>........................] - ETA: 3:02 - loss: 0.1840 - regression_loss: 0.1573 - classification_loss: 0.0267
109/500 [=====>........................] - ETA: 3:01 - loss: 0.1835 - regression_loss: 0.1570 - classification_loss: 0.0266
110/500 [=====>........................] - ETA: 3:01 - loss: 0.1842 - regression_loss: 0.1577 - classification_loss: 0.0265
111/500 [=====>........................] - ETA: 3:00 - loss: 0.1836 - regression_loss: 0.1571 - classification_loss: 0.0265
112/500 [=====>........................] - ETA: 3:00 - loss: 0.1839 - regression_loss: 0.1575 - classification_loss: 0.0264
113/500 [=====>........................] - ETA: 2:59 - loss: 0.1835 - regression_loss: 0.1572 - classification_loss: 0.0263
114/500 [=====>........................] - ETA: 2:59 - loss: 0.1851 - regression_loss: 0.1585 - classification_loss: 0.0266
115/500 [=====>........................] - ETA: 2:58 - loss: 0.1839 - regression_loss: 0.1574 - classification_loss: 0.0265
116/500 [=====>........................] - ETA: 2:58 - loss: 0.1834 - regression_loss: 0.1570 - classification_loss: 0.0264
117/500 [======>.......................] - ETA: 2:58 - loss: 0.1824 - regression_loss: 0.1561 - classification_loss: 0.0263
118/500 [======>.......................] - ETA: 2:57 - loss: 0.1810 - regression_loss: 0.1548 - classification_loss: 0.0262
119/500 [======>.......................] - ETA: 2:57 - loss: 0.1823 - regression_loss: 0.1559 - classification_loss: 0.0264
120/500 [======>.......................] - ETA: 2:56 - loss: 0.1828 - regression_loss: 0.1564 - classification_loss: 0.0264
121/500 [======>.......................] - ETA: 2:56 - loss: 0.1821 - regression_loss: 0.1557 - classification_loss: 0.0263
122/500 [======>.......................] - ETA: 2:55 - loss: 0.1821 - regression_loss: 0.1558 - classification_loss: 0.0263
123/500 [======>.......................] - ETA: 2:55 - loss: 0.1813 - regression_loss: 0.1551 - classification_loss: 0.0262
124/500 [======>.......................] - ETA: 2:54 - loss: 0.1830 - regression_loss: 0.1566 - classification_loss: 0.0265
125/500 [======>.......................] - ETA: 2:54 - loss: 0.1831 - regression_loss: 0.1568 - classification_loss: 0.0263
126/500 [======>.......................] - ETA: 2:53 - loss: 0.1824 - regression_loss: 0.1562 - classification_loss: 0.0262
127/500 [======>.......................] - ETA: 2:53 - loss: 0.1839 - regression_loss: 0.1574 - classification_loss: 0.0265
128/500 [======>.......................] - ETA: 2:52 - loss: 0.1831 - regression_loss: 0.1567 - classification_loss: 0.0264
129/500 [======>.......................] - ETA: 2:52 - loss: 0.1833 - regression_loss: 0.1570 - classification_loss: 0.0264
130/500 [======>.......................] - ETA: 2:51 - loss: 0.1823 - regression_loss: 0.1561 - classification_loss: 0.0263
131/500 [======>.......................] - ETA: 2:51 - loss: 0.1817 - regression_loss: 0.1555 - classification_loss: 0.0262
132/500 [======>.......................] - ETA: 2:50 - loss: 0.1819 - regression_loss: 0.1558 - classification_loss: 0.0262
133/500 [======>.......................] - ETA: 2:50 - loss: 0.1808 - regression_loss: 0.1548 - classification_loss: 0.0260
134/500 [=======>......................] - ETA: 2:50 - loss: 0.1820 - regression_loss: 0.1557 - classification_loss: 0.0263
135/500 [=======>......................] - ETA: 2:49 - loss: 0.1810 - regression_loss: 0.1548 - classification_loss: 0.0262
136/500 [=======>......................] - ETA: 2:49 - loss: 0.1809 - regression_loss: 0.1548 - classification_loss: 0.0261
137/500 [=======>......................] - ETA: 2:48 - loss: 0.1799 - regression_loss: 0.1539 - classification_loss: 0.0260
138/500 [=======>......................] - ETA: 2:48 - loss: 0.1813 - regression_loss: 0.1550 - classification_loss: 0.0263
139/500 [=======>......................] - ETA: 2:47 - loss: 0.1803 - regression_loss: 0.1541 - classification_loss: 0.0262
140/500 [=======>......................] - ETA: 2:47 - loss: 0.1796 - regression_loss: 0.1534 - classification_loss: 0.0261
141/500 [=======>......................] - ETA: 2:46 - loss: 0.1785 - regression_loss: 0.1524 - classification_loss: 0.0260
142/500 [=======>......................] - ETA: 2:46 - loss: 0.1799 - regression_loss: 0.1536 - classification_loss: 0.0263
143/500 [=======>......................] - ETA: 2:45 - loss: 0.1801 - regression_loss: 0.1538 - classification_loss: 0.0262
144/500 [=======>......................] - ETA: 2:45 - loss: 0.1793 - regression_loss: 0.1532 - classification_loss: 0.0261
145/500 [=======>......................] - ETA: 2:45 - loss: 0.1787 - regression_loss: 0.1526 - classification_loss: 0.0261
146/500 [=======>......................] - ETA: 2:44 - loss: 0.1787 - regression_loss: 0.1527 - classification_loss: 0.0260
147/500 [=======>......................] - ETA: 2:44 - loss: 0.1783 - regression_loss: 0.1524 - classification_loss: 0.0259
148/500 [=======>......................] - ETA: 2:43 - loss: 0.1796 - regression_loss: 0.1535 - classification_loss: 0.0262
149/500 [=======>......................] - ETA: 2:43 - loss: 0.1789 - regression_loss: 0.1529 - classification_loss: 0.0261
150/500 [========>.....................] - ETA: 2:42 - loss: 0.1787 - regression_loss: 0.1527 - classification_loss: 0.0260
151/500 [========>.....................] - ETA: 2:42 - loss: 0.1797 - regression_loss: 0.1535 - classification_loss: 0.0262
152/500 [========>.....................] - ETA: 2:41 - loss: 0.1787 - regression_loss: 0.1526 - classification_loss: 0.0261
153/500 [========>.....................] - ETA: 2:41 - loss: 0.1788 - regression_loss: 0.1528 - classification_loss: 0.0261
154/500 [========>.....................] - ETA: 2:40 - loss: 0.1782 - regression_loss: 0.1522 - classification_loss: 0.0260
155/500 [========>.....................] - ETA: 2:40 - loss: 0.1775 - regression_loss: 0.1516 - classification_loss: 0.0259
156/500 [========>.....................] - ETA: 2:39 - loss: 0.1768 - regression_loss: 0.1509 - classification_loss: 0.0259
157/500 [========>.....................] - ETA: 2:39 - loss: 0.1780 - regression_loss: 0.1519 - classification_loss: 0.0261
158/500 [========>.....................] - ETA: 2:38 - loss: 0.1772 - regression_loss: 0.1512 - classification_loss: 0.0260
159/500 [========>.....................] - ETA: 2:38 - loss: 0.1776 - regression_loss: 0.1516 - classification_loss: 0.0260
160/500 [========>.....................] - ETA: 2:38 - loss: 0.1774 - regression_loss: 0.1515 - classification_loss: 0.0259
161/500 [========>.....................] - ETA: 2:37 - loss: 0.1766 - regression_loss: 0.1509 - classification_loss: 0.0258
162/500 [========>.....................] - ETA: 2:37 - loss: 0.1762 - regression_loss: 0.1506 - classification_loss: 0.0257
163/500 [========>.....................] - ETA: 2:36 - loss: 0.1759 - regression_loss: 0.1503 - classification_loss: 0.0256
164/500 [========>.....................] - ETA: 2:36 - loss: 0.1758 - regression_loss: 0.1503 - classification_loss: 0.0256
165/500 [========>.....................] - ETA: 2:35 - loss: 0.1769 - regression_loss: 0.1511 - classification_loss: 0.0258
166/500 [========>.....................] - ETA: 2:35 - loss: 0.1761 - regression_loss: 0.1504 - classification_loss: 0.0257
167/500 [=========>....................] - ETA: 2:34 - loss: 0.1755 - regression_loss: 0.1499 - classification_loss: 0.0256
168/500 [=========>....................] - ETA: 2:34 - loss: 0.1756 - regression_loss: 0.1500 - classification_loss: 0.0256
169/500 [=========>....................] - ETA: 2:33 - loss: 0.1766 - regression_loss: 0.1508 - classification_loss: 0.0258
170/500 [=========>....................] - ETA: 2:33 - loss: 0.1766 - regression_loss: 0.1509 - classification_loss: 0.0257
171/500 [=========>....................] - ETA: 2:32 - loss: 0.1760 - regression_loss: 0.1505 - classification_loss: 0.0256
172/500 [=========>....................] - ETA: 2:32 - loss: 0.1755 - regression_loss: 0.1500 - classification_loss: 0.0255
173/500 [=========>....................] - ETA: 2:31 - loss: 0.1771 - regression_loss: 0.1514 - classification_loss: 0.0257
174/500 [=========>....................] - ETA: 2:31 - loss: 0.1772 - regression_loss: 0.1516 - classification_loss: 0.0256
175/500 [=========>....................] - ETA: 2:31 - loss: 0.1778 - regression_loss: 0.1522 - classification_loss: 0.0256
176/500 [=========>....................] - ETA: 2:30 - loss: 0.1774 - regression_loss: 0.1518 - classification_loss: 0.0255
177/500 [=========>....................] - ETA: 2:30 - loss: 0.1765 - regression_loss: 0.1510 - classification_loss: 0.0255
178/500 [=========>....................] - ETA: 2:29 - loss: 0.1766 - regression_loss: 0.1513 - classification_loss: 0.0254
179/500 [=========>....................] - ETA: 2:29 - loss: 0.1770 - regression_loss: 0.1516 - classification_loss: 0.0253
180/500 [=========>....................] - ETA: 2:28 - loss: 0.1782 - regression_loss: 0.1527 - classification_loss: 0.0255
181/500 [=========>....................] - ETA: 2:28 - loss: 0.1784 - regression_loss: 0.1529 - classification_loss: 0.0255
182/500 [=========>....................] - ETA: 2:27 - loss: 0.1794 - regression_loss: 0.1538 - classification_loss: 0.0257
183/500 [=========>....................] - ETA: 2:27 - loss: 0.1789 - regression_loss: 0.1533 - classification_loss: 0.0256
184/500 [==========>...................] - ETA: 2:26 - loss: 0.1788 - regression_loss: 0.1533 - classification_loss: 0.0255
185/500 [==========>...................] - ETA: 2:26 - loss: 0.1792 - regression_loss: 0.1537 - classification_loss: 0.0255
186/500 [==========>...................] - ETA: 2:25 - loss: 0.1791 - regression_loss: 0.1537 - classification_loss: 0.0254
187/500 [==========>...................] - ETA: 2:25 - loss: 0.1786 - regression_loss: 0.1533 - classification_loss: 0.0253
188/500 [==========>...................] - ETA: 2:24 - loss: 0.1781 - regression_loss: 0.1528 - classification_loss: 0.0253
189/500 [==========>...................] - ETA: 2:24 - loss: 0.1797 - regression_loss: 0.1543 - classification_loss: 0.0255
190/500 [==========>...................] - ETA: 2:24 - loss: 0.1808 - regression_loss: 0.1554 - classification_loss: 0.0254
191/500 [==========>...................] - ETA: 2:23 - loss: 0.1803 - regression_loss: 0.1549 - classification_loss: 0.0254
192/500 [==========>...................] - ETA: 2:23 - loss: 0.1796 - regression_loss: 0.1543 - classification_loss: 0.0253
193/500 [==========>...................] - ETA: 2:22 - loss: 0.1805 - regression_loss: 0.1550 - classification_loss: 0.0255
194/500 [==========>...................] - ETA: 2:22 - loss: 0.1808 - regression_loss: 0.1553 - classification_loss: 0.0255
195/500 [==========>...................] - ETA: 2:21 - loss: 0.1816 - regression_loss: 0.1563 - classification_loss: 0.0254
196/500 [==========>...................] - ETA: 2:21 - loss: 0.1827 - regression_loss: 0.1572 - classification_loss: 0.0255
197/500 [==========>...................] - ETA: 2:20 - loss: 0.1821 - regression_loss: 0.1566 - classification_loss: 0.0255
198/500 [==========>...................] - ETA: 2:20 - loss: 0.1827 - regression_loss: 0.1573 - classification_loss: 0.0254
199/500 [==========>...................] - ETA: 2:19 - loss: 0.1828 - regression_loss: 0.1575 - classification_loss: 0.0253
200/500 [===========>..................] - ETA: 2:19 - loss: 0.1826 - regression_loss: 0.1573 - classification_loss: 0.0253
201/500 [===========>..................] - ETA: 2:19 - loss: 0.1821 - regression_loss: 0.1569 - classification_loss: 0.0253
202/500 [===========>..................] - ETA: 2:18 - loss: 0.1814 - regression_loss: 0.1563 - classification_loss: 0.0252
203/500 [===========>..................] - ETA: 2:18 - loss: 0.1825 - regression_loss: 0.1572 - classification_loss: 0.0253
204/500 [===========>..................] - ETA: 2:17 - loss: 0.1823 - regression_loss: 0.1570 - classification_loss: 0.0253
205/500 [===========>..................] - ETA: 2:17 - loss: 0.1827 - regression_loss: 0.1574 - classification_loss: 0.0252
206/500 [===========>..................] - ETA: 2:16 - loss: 0.1837 - regression_loss: 0.1583 - classification_loss: 0.0254
207/500 [===========>..................] - ETA: 2:16 - loss: 0.1835 - regression_loss: 0.1582 - classification_loss: 0.0253
208/500 [===========>..................] - ETA: 2:15 - loss: 0.1828 - regression_loss: 0.1575 - classification_loss: 0.0253
209/500 [===========>..................] - ETA: 2:15 - loss: 0.1822 - regression_loss: 0.1570 - classification_loss: 0.0252
210/500 [===========>..................] - ETA: 2:14 - loss: 0.1823 - regression_loss: 0.1571 - classification_loss: 0.0252
211/500 [===========>..................] - ETA: 2:14 - loss: 0.1832 - regression_loss: 0.1579 - classification_loss: 0.0253
212/500 [===========>..................] - ETA: 2:13 - loss: 0.1832 - regression_loss: 0.1579 - classification_loss: 0.0253
213/500 [===========>..................] - ETA: 2:13 - loss: 0.1829 - regression_loss: 0.1577 - classification_loss: 0.0253
214/500 [===========>..................] - ETA: 2:13 - loss: 0.1822 - regression_loss: 0.1570 - classification_loss: 0.0252
215/500 [===========>..................] - ETA: 2:12 - loss: 0.1817 - regression_loss: 0.1565 - classification_loss: 0.0251
216/500 [===========>..................] - ETA: 2:12 - loss: 0.1809 - regression_loss: 0.1559 - classification_loss: 0.0250
217/500 [============>.................] - ETA: 2:11 - loss: 0.1808 - regression_loss: 0.1558 - classification_loss: 0.0250
218/500 [============>.................] - ETA: 2:11 - loss: 0.1815 - regression_loss: 0.1564 - classification_loss: 0.0251
219/500 [============>.................] - ETA: 2:10 - loss: 0.1820 - regression_loss: 0.1569 - classification_loss: 0.0251
220/500 [============>.................] - ETA: 2:10 - loss: 0.1816 - regression_loss: 0.1566 - classification_loss: 0.0251
221/500 [============>.................] - ETA: 2:09 - loss: 0.1818 - regression_loss: 0.1568 - classification_loss: 0.0250
222/500 [============>.................] - ETA: 2:09 - loss: 0.1825 - regression_loss: 0.1573 - classification_loss: 0.0252
223/500 [============>.................] - ETA: 2:08 - loss: 0.1820 - regression_loss: 0.1569 - classification_loss: 0.0251
224/500 [============>.................] - ETA: 2:08 - loss: 0.1815 - regression_loss: 0.1564 - classification_loss: 0.0250
225/500 [============>.................] - ETA: 2:07 - loss: 0.1810 - regression_loss: 0.1561 - classification_loss: 0.0250
226/500 [============>.................] - ETA: 2:07 - loss: 0.1820 - regression_loss: 0.1568 - classification_loss: 0.0251
227/500 [============>.................] - ETA: 2:06 - loss: 0.1819 - regression_loss: 0.1569 - classification_loss: 0.0251
228/500 [============>.................] - ETA: 2:06 - loss: 0.1817 - regression_loss: 0.1566 - classification_loss: 0.0250
229/500 [============>.................] - ETA: 2:06 - loss: 0.1810 - regression_loss: 0.1560 - classification_loss: 0.0250
230/500 [============>.................] - ETA: 2:05 - loss: 0.1805 - regression_loss: 0.1556 - classification_loss: 0.0249
231/500 [============>.................] - ETA: 2:05 - loss: 0.1801 - regression_loss: 0.1552 - classification_loss: 0.0249
232/500 [============>.................] - ETA: 2:04 - loss: 0.1800 - regression_loss: 0.1551 - classification_loss: 0.0248
233/500 [============>.................] - ETA: 2:04 - loss: 0.1794 - regression_loss: 0.1546 - classification_loss: 0.0248
234/500 [=============>................] - ETA: 2:03 - loss: 0.1788 - regression_loss: 0.1541 - classification_loss: 0.0247
235/500 [=============>................] - ETA: 2:03 - loss: 0.1794 - regression_loss: 0.1545 - classification_loss: 0.0248
236/500 [=============>................] - ETA: 2:02 - loss: 0.1794 - regression_loss: 0.1545 - classification_loss: 0.0248
237/500 [=============>................] - ETA: 2:02 - loss: 0.1789 - regression_loss: 0.1541 - classification_loss: 0.0248
238/500 [=============>................] - ETA: 2:01 - loss: 0.1782 - regression_loss: 0.1535 - classification_loss: 0.0247
239/500 [=============>................] - ETA: 2:01 - loss: 0.1788 - regression_loss: 0.1540 - classification_loss: 0.0248
240/500 [=============>................] - ETA: 2:00 - loss: 0.1790 - regression_loss: 0.1542 - classification_loss: 0.0248
241/500 [=============>................] - ETA: 2:00 - loss: 0.1796 - regression_loss: 0.1547 - classification_loss: 0.0249
242/500 [=============>................] - ETA: 1:59 - loss: 0.1792 - regression_loss: 0.1543 - classification_loss: 0.0249
243/500 [=============>................] - ETA: 1:59 - loss: 0.1786 - regression_loss: 0.1538 - classification_loss: 0.0248
244/500 [=============>................] - ETA: 1:59 - loss: 0.1788 - regression_loss: 0.1540 - classification_loss: 0.0248
245/500 [=============>................] - ETA: 1:58 - loss: 0.1783 - regression_loss: 0.1536 - classification_loss: 0.0247
246/500 [=============>................] - ETA: 1:58 - loss: 0.1784 - regression_loss: 0.1537 - classification_loss: 0.0247
247/500 [=============>................] - ETA: 1:57 - loss: 0.1778 - regression_loss: 0.1531 - classification_loss: 0.0246
248/500 [=============>................] - ETA: 1:57 - loss: 0.1777 - regression_loss: 0.1531 - classification_loss: 0.0246
249/500 [=============>................] - ETA: 1:56 - loss: 0.1783 - regression_loss: 0.1536 - classification_loss: 0.0247
250/500 [==============>...............] - ETA: 1:56 - loss: 0.1777 - regression_loss: 0.1531 - classification_loss: 0.0246
251/500 [==============>...............] - ETA: 1:55 - loss: 0.1773 - regression_loss: 0.1527 - classification_loss: 0.0246
252/500 [==============>...............] - ETA: 1:55 - loss: 0.1774 - regression_loss: 0.1528 - classification_loss: 0.0246
253/500 [==============>...............] - ETA: 1:54 - loss: 0.1780 - regression_loss: 0.1533 - classification_loss: 0.0247
254/500 [==============>...............] - ETA: 1:54 - loss: 0.1784 - regression_loss: 0.1538 - classification_loss: 0.0247
255/500 [==============>...............] - ETA: 1:53 - loss: 0.1779 - regression_loss: 0.1533 - classification_loss: 0.0246
256/500 [==============>...............] - ETA: 1:53 - loss: 0.1785 - regression_loss: 0.1538 - classification_loss: 0.0247
257/500 [==============>...............] - ETA: 1:52 - loss: 0.1783 - regression_loss: 0.1537 - classification_loss: 0.0247
258/500 [==============>...............] - ETA: 1:52 - loss: 0.1779 - regression_loss: 0.1533 - classification_loss: 0.0246
259/500 [==============>...............] - ETA: 1:52 - loss: 0.1773 - regression_loss: 0.1528 - classification_loss: 0.0246
260/500 [==============>...............] - ETA: 1:51 - loss: 0.1773 - regression_loss: 0.1528 - classification_loss: 0.0245
261/500 [==============>...............] - ETA: 1:51 - loss: 0.1771 - regression_loss: 0.1526 - classification_loss: 0.0245
262/500 [==============>...............] - ETA: 1:50 - loss: 0.1770 - regression_loss: 0.1526 - classification_loss: 0.0245
263/500 [==============>...............] - ETA: 1:50 - loss: 0.1766 - regression_loss: 0.1521 - classification_loss: 0.0244
264/500 [==============>...............] - ETA: 1:49 - loss: 0.1770 - regression_loss: 0.1525 - classification_loss: 0.0245
265/500 [==============>...............] - ETA: 1:49 - loss: 0.1765 - regression_loss: 0.1521 - classification_loss: 0.0245
266/500 [==============>...............] - ETA: 1:48 - loss: 0.1763 - regression_loss: 0.1518 - classification_loss: 0.0244
267/500 [===============>..............] - ETA: 1:48 - loss: 0.1767 - regression_loss: 0.1523 - classification_loss: 0.0244
268/500 [===============>..............] - ETA: 1:47 - loss: 0.1772 - regression_loss: 0.1527 - classification_loss: 0.0245
269/500 [===============>..............] - ETA: 1:47 - loss: 0.1768 - regression_loss: 0.1523 - classification_loss: 0.0245
270/500 [===============>..............] - ETA: 1:46 - loss: 0.1763 - regression_loss: 0.1519 - classification_loss: 0.0244
271/500 [===============>..............] - ETA: 1:46 - loss: 0.1764 - regression_loss: 0.1520 - classification_loss: 0.0244
272/500 [===============>..............] - ETA: 1:46 - loss: 0.1769 - regression_loss: 0.1524 - classification_loss: 0.0245
273/500 [===============>..............] - ETA: 1:45 - loss: 0.1766 - regression_loss: 0.1522 - classification_loss: 0.0244
274/500 [===============>..............] - ETA: 1:45 - loss: 0.1763 - regression_loss: 0.1519 - classification_loss: 0.0244
275/500 [===============>..............] - ETA: 1:44 - loss: 0.1761 - regression_loss: 0.1518 - classification_loss: 0.0243
276/500 [===============>..............] - ETA: 1:44 - loss: 0.1757 - regression_loss: 0.1514 - classification_loss: 0.0243
277/500 [===============>..............] - ETA: 1:43 - loss: 0.1762 - regression_loss: 0.1518 - classification_loss: 0.0244
278/500 [===============>..............] - ETA: 1:43 - loss: 0.1757 - regression_loss: 0.1513 - classification_loss: 0.0244
279/500 [===============>..............] - ETA: 1:42 - loss: 0.1751 - regression_loss: 0.1509 - classification_loss: 0.0243
280/500 [===============>..............] - ETA: 1:42 - loss: 0.1752 - regression_loss: 0.1509 - classification_loss: 0.0243
281/500 [===============>..............] - ETA: 1:41 - loss: 0.1749 - regression_loss: 0.1507 - classification_loss: 0.0242
282/500 [===============>..............] - ETA: 1:41 - loss: 0.1747 - regression_loss: 0.1505 - classification_loss: 0.0242
283/500 [===============>..............] - ETA: 1:40 - loss: 0.1745 - regression_loss: 0.1503 - classification_loss: 0.0241
284/500 [================>.............] - ETA: 1:40 - loss: 0.1744 - regression_loss: 0.1503 - classification_loss: 0.0241
285/500 [================>.............] - ETA: 1:39 - loss: 0.1749 - regression_loss: 0.1507 - classification_loss: 0.0242
286/500 [================>.............] - ETA: 1:39 - loss: 0.1748 - regression_loss: 0.1506 - classification_loss: 0.0242
287/500 [================>.............] - ETA: 1:39 - loss: 0.1743 - regression_loss: 0.1502 - classification_loss: 0.0241
288/500 [================>.............] - ETA: 1:38 - loss: 0.1739 - regression_loss: 0.1498 - classification_loss: 0.0241
289/500 [================>.............] - ETA: 1:38 - loss: 0.1737 - regression_loss: 0.1497 - classification_loss: 0.0240
290/500 [================>.............] - ETA: 1:37 - loss: 0.1742 - regression_loss: 0.1500 - classification_loss: 0.0241
291/500 [================>.............] - ETA: 1:37 - loss: 0.1741 - regression_loss: 0.1500 - classification_loss: 0.0241
292/500 [================>.............] - ETA: 1:36 - loss: 0.1737 - regression_loss: 0.1496 - classification_loss: 0.0241
293/500 [================>.............] - ETA: 1:36 - loss: 0.1736 - regression_loss: 0.1496 - classification_loss: 0.0240
294/500 [================>.............] - ETA: 1:35 - loss: 0.1743 - regression_loss: 0.1501 - classification_loss: 0.0241
295/500 [================>.............] - ETA: 1:35 - loss: 0.1741 - regression_loss: 0.1500 - classification_loss: 0.0241
296/500 [================>.............] - ETA: 1:34 - loss: 0.1737 - regression_loss: 0.1497 - classification_loss: 0.0240
297/500 [================>.............] - ETA: 1:34 - loss: 0.1737 - regression_loss: 0.1497 - classification_loss: 0.0240
298/500 [================>.............] - ETA: 1:33 - loss: 0.1737 - regression_loss: 0.1497 - classification_loss: 0.0240
299/500 [================>.............] - ETA: 1:33 - loss: 0.1734 - regression_loss: 0.1495 - classification_loss: 0.0239
300/500 [=================>............] - ETA: 1:32 - loss: 0.1739 - regression_loss: 0.1499 - classification_loss: 0.0240
301/500 [=================>............] - ETA: 1:32 - loss: 0.1737 - regression_loss: 0.1497 - classification_loss: 0.0240
302/500 [=================>............] - ETA: 1:32 - loss: 0.1737 - regression_loss: 0.1497 - classification_loss: 0.0240
303/500 [=================>............] - ETA: 1:31 - loss: 0.1735 - regression_loss: 0.1496 - classification_loss: 0.0239
304/500 [=================>............] - ETA: 1:31 - loss: 0.1740 - regression_loss: 0.1500 - classification_loss: 0.0240
305/500 [=================>............] - ETA: 1:30 - loss: 0.1737 - regression_loss: 0.1497 - classification_loss: 0.0239
306/500 [=================>............] - ETA: 1:30 - loss: 0.1736 - regression_loss: 0.1496 - classification_loss: 0.0239
307/500 [=================>............] - ETA: 1:29 - loss: 0.1736 - regression_loss: 0.1496 - classification_loss: 0.0239
308/500 [=================>............] - ETA: 1:29 - loss: 0.1735 - regression_loss: 0.1496 - classification_loss: 0.0239
309/500 [=================>............] - ETA: 1:28 - loss: 0.1730 - regression_loss: 0.1491 - classification_loss: 0.0238
310/500 [=================>............] - ETA: 1:28 - loss: 0.1734 - regression_loss: 0.1495 - classification_loss: 0.0239
311/500 [=================>............] - ETA: 1:27 - loss: 0.1732 - regression_loss: 0.1493 - classification_loss: 0.0238
312/500 [=================>............] - ETA: 1:27 - loss: 0.1732 - regression_loss: 0.1493 - classification_loss: 0.0238
313/500 [=================>............] - ETA: 1:26 - loss: 0.1728 - regression_loss: 0.1490 - classification_loss: 0.0238
314/500 [=================>............] - ETA: 1:26 - loss: 0.1733 - regression_loss: 0.1494 - classification_loss: 0.0239
315/500 [=================>............] - ETA: 1:26 - loss: 0.1729 - regression_loss: 0.1491 - classification_loss: 0.0238
316/500 [=================>............] - ETA: 1:25 - loss: 0.1733 - regression_loss: 0.1494 - classification_loss: 0.0239
317/500 [==================>...........] - ETA: 1:25 - loss: 0.1735 - regression_loss: 0.1496 - classification_loss: 0.0239
318/500 [==================>...........] - ETA: 1:24 - loss: 0.1731 - regression_loss: 0.1492 - classification_loss: 0.0239
319/500 [==================>...........] - ETA: 1:24 - loss: 0.1727 - regression_loss: 0.1488 - classification_loss: 0.0238
320/500 [==================>...........] - ETA: 1:23 - loss: 0.1724 - regression_loss: 0.1486 - classification_loss: 0.0238
321/500 [==================>...........] - ETA: 1:23 - loss: 0.1722 - regression_loss: 0.1485 - classification_loss: 0.0237
322/500 [==================>...........] - ETA: 1:22 - loss: 0.1729 - regression_loss: 0.1491 - classification_loss: 0.0238
323/500 [==================>...........] - ETA: 1:22 - loss: 0.1729 - regression_loss: 0.1492 - classification_loss: 0.0238
324/500 [==================>...........] - ETA: 1:21 - loss: 0.1730 - regression_loss: 0.1492 - classification_loss: 0.0238
325/500 [==================>...........] - ETA: 1:21 - loss: 0.1725 - regression_loss: 0.1488 - classification_loss: 0.0237
326/500 [==================>...........] - ETA: 1:20 - loss: 0.1723 - regression_loss: 0.1487 - classification_loss: 0.0237
327/500 [==================>...........] - ETA: 1:20 - loss: 0.1723 - regression_loss: 0.1486 - classification_loss: 0.0236
328/500 [==================>...........] - ETA: 1:19 - loss: 0.1720 - regression_loss: 0.1484 - classification_loss: 0.0236
329/500 [==================>...........] - ETA: 1:19 - loss: 0.1715 - regression_loss: 0.1480 - classification_loss: 0.0236
330/500 [==================>...........] - ETA: 1:19 - loss: 0.1719 - regression_loss: 0.1482 - classification_loss: 0.0236
331/500 [==================>...........] - ETA: 1:18 - loss: 0.1722 - regression_loss: 0.1485 - classification_loss: 0.0237
332/500 [==================>...........] - ETA: 1:18 - loss: 0.1718 - regression_loss: 0.1481 - classification_loss: 0.0237
333/500 [==================>...........] - ETA: 1:17 - loss: 0.1718 - regression_loss: 0.1481 - classification_loss: 0.0237
334/500 [===================>..........] - ETA: 1:17 - loss: 0.1714 - regression_loss: 0.1477 - classification_loss: 0.0236
335/500 [===================>..........] - ETA: 1:16 - loss: 0.1711 - regression_loss: 0.1476 - classification_loss: 0.0236
336/500 [===================>..........] - ETA: 1:16 - loss: 0.1711 - regression_loss: 0.1476 - classification_loss: 0.0236
337/500 [===================>..........] - ETA: 1:15 - loss: 0.1711 - regression_loss: 0.1476 - classification_loss: 0.0235
338/500 [===================>..........] - ETA: 1:15 - loss: 0.1707 - regression_loss: 0.1472 - classification_loss: 0.0235
339/500 [===================>..........] - ETA: 1:14 - loss: 0.1711 - regression_loss: 0.1475 - classification_loss: 0.0236
340/500 [===================>..........] - ETA: 1:14 - loss: 0.1707 - regression_loss: 0.1472 - classification_loss: 0.0235
341/500 [===================>..........] - ETA: 1:13 - loss: 0.1705 - regression_loss: 0.1470 - classification_loss: 0.0235
342/500 [===================>..........] - ETA: 1:13 - loss: 0.1709 - regression_loss: 0.1473 - classification_loss: 0.0236
343/500 [===================>..........] - ETA: 1:13 - loss: 0.1705 - regression_loss: 0.1470 - classification_loss: 0.0235
344/500 [===================>..........] - ETA: 1:12 - loss: 0.1705 - regression_loss: 0.1470 - classification_loss: 0.0235
345/500 [===================>..........] - ETA: 1:12 - loss: 0.1702 - regression_loss: 0.1467 - classification_loss: 0.0235
346/500 [===================>..........] - ETA: 1:11 - loss: 0.1700 - regression_loss: 0.1466 - classification_loss: 0.0234
347/500 [===================>..........] - ETA: 1:11 - loss: 0.1696 - regression_loss: 0.1462 - classification_loss: 0.0234
348/500 [===================>..........] - ETA: 1:10 - loss: 0.1695 - regression_loss: 0.1461 - classification_loss: 0.0234
349/500 [===================>..........] - ETA: 1:10 - loss: 0.1706 - regression_loss: 0.1471 - classification_loss: 0.0235
350/500 [====================>.........] - ETA: 1:09 - loss: 0.1702 - regression_loss: 0.1468 - classification_loss: 0.0234
351/500 [====================>.........] - ETA: 1:09 - loss: 0.1702 - regression_loss: 0.1468 - classification_loss: 0.0234
352/500 [====================>.........] - ETA: 1:08 - loss: 0.1698 - regression_loss: 0.1465 - classification_loss: 0.0233
353/500 [====================>.........] - ETA: 1:08 - loss: 0.1703 - regression_loss: 0.1469 - classification_loss: 0.0234
354/500 [====================>.........] - ETA: 1:07 - loss: 0.1701 - regression_loss: 0.1467 - classification_loss: 0.0234
355/500 [====================>.........] - ETA: 1:07 - loss: 0.1700 - regression_loss: 0.1467 - classification_loss: 0.0234
356/500 [====================>.........] - ETA: 1:06 - loss: 0.1698 - regression_loss: 0.1465 - classification_loss: 0.0233
357/500 [====================>.........] - ETA: 1:06 - loss: 0.1696 - regression_loss: 0.1463 - classification_loss: 0.0233
358/500 [====================>.........] - ETA: 1:06 - loss: 0.1697 - regression_loss: 0.1464 - classification_loss: 0.0232
359/500 [====================>.........] - ETA: 1:05 - loss: 0.1699 - regression_loss: 0.1467 - classification_loss: 0.0232
360/500 [====================>.........] - ETA: 1:05 - loss: 0.1705 - regression_loss: 0.1472 - classification_loss: 0.0233
361/500 [====================>.........] - ETA: 1:04 - loss: 0.1706 - regression_loss: 0.1473 - classification_loss: 0.0233
362/500 [====================>.........] - ETA: 1:04 - loss: 0.1706 - regression_loss: 0.1474 - classification_loss: 0.0232
363/500 [====================>.........] - ETA: 1:03 - loss: 0.1706 - regression_loss: 0.1474 - classification_loss: 0.0232
364/500 [====================>.........] - ETA: 1:03 - loss: 0.1711 - regression_loss: 0.1478 - classification_loss: 0.0233
365/500 [====================>.........] - ETA: 1:02 - loss: 0.1709 - regression_loss: 0.1477 - classification_loss: 0.0232
366/500 [====================>.........] - ETA: 1:02 - loss: 0.1707 - regression_loss: 0.1474 - classification_loss: 0.0232
367/500 [=====================>........] - ETA: 1:01 - loss: 0.1706 - regression_loss: 0.1474 - classification_loss: 0.0232
368/500 [=====================>........] - ETA: 1:01 - loss: 0.1707 - regression_loss: 0.1475 - classification_loss: 0.0232
369/500 [=====================>........] - ETA: 1:00 - loss: 0.1703 - regression_loss: 0.1472 - classification_loss: 0.0231
370/500 [=====================>........] - ETA: 1:00 - loss: 0.1706 - regression_loss: 0.1474 - classification_loss: 0.0232
371/500 [=====================>........] - ETA: 59s - loss: 0.1707 - regression_loss: 0.1475 - classification_loss: 0.0232 
372/500 [=====================>........] - ETA: 59s - loss: 0.1710 - regression_loss: 0.1477 - classification_loss: 0.0233
373/500 [=====================>........] - ETA: 59s - loss: 0.1707 - regression_loss: 0.1475 - classification_loss: 0.0232
374/500 [=====================>........] - ETA: 58s - loss: 0.1706 - regression_loss: 0.1474 - classification_loss: 0.0232
375/500 [=====================>........] - ETA: 58s - loss: 0.1704 - regression_loss: 0.1472 - classification_loss: 0.0232
376/500 [=====================>........] - ETA: 57s - loss: 0.1707 - regression_loss: 0.1475 - classification_loss: 0.0232
377/500 [=====================>........] - ETA: 57s - loss: 0.1703 - regression_loss: 0.1472 - classification_loss: 0.0232
378/500 [=====================>........] - ETA: 56s - loss: 0.1701 - regression_loss: 0.1470 - classification_loss: 0.0231
379/500 [=====================>........] - ETA: 56s - loss: 0.1698 - regression_loss: 0.1467 - classification_loss: 0.0231
380/500 [=====================>........] - ETA: 55s - loss: 0.1699 - regression_loss: 0.1468 - classification_loss: 0.0231
381/500 [=====================>........] - ETA: 55s - loss: 0.1699 - regression_loss: 0.1468 - classification_loss: 0.0231
382/500 [=====================>........] - ETA: 54s - loss: 0.1697 - regression_loss: 0.1466 - classification_loss: 0.0230
383/500 [=====================>........] - ETA: 54s - loss: 0.1695 - regression_loss: 0.1465 - classification_loss: 0.0230
384/500 [======================>.......] - ETA: 53s - loss: 0.1693 - regression_loss: 0.1463 - classification_loss: 0.0230
385/500 [======================>.......] - ETA: 53s - loss: 0.1697 - regression_loss: 0.1466 - classification_loss: 0.0230
386/500 [======================>.......] - ETA: 53s - loss: 0.1694 - regression_loss: 0.1464 - classification_loss: 0.0230
387/500 [======================>.......] - ETA: 52s - loss: 0.1691 - regression_loss: 0.1461 - classification_loss: 0.0230
388/500 [======================>.......] - ETA: 52s - loss: 0.1691 - regression_loss: 0.1461 - classification_loss: 0.0229
389/500 [======================>.......] - ETA: 51s - loss: 0.1687 - regression_loss: 0.1458 - classification_loss: 0.0229
390/500 [======================>.......] - ETA: 51s - loss: 0.1690 - regression_loss: 0.1460 - classification_loss: 0.0230
391/500 [======================>.......] - ETA: 50s - loss: 0.1687 - regression_loss: 0.1458 - classification_loss: 0.0229
392/500 [======================>.......] - ETA: 50s - loss: 0.1685 - regression_loss: 0.1456 - classification_loss: 0.0229
393/500 [======================>.......] - ETA: 49s - loss: 0.1684 - regression_loss: 0.1455 - classification_loss: 0.0229
394/500 [======================>.......] - ETA: 49s - loss: 0.1686 - regression_loss: 0.1458 - classification_loss: 0.0228
395/500 [======================>.......] - ETA: 48s - loss: 0.1689 - regression_loss: 0.1460 - classification_loss: 0.0229
396/500 [======================>.......] - ETA: 48s - loss: 0.1686 - regression_loss: 0.1457 - classification_loss: 0.0229
397/500 [======================>.......] - ETA: 47s - loss: 0.1689 - regression_loss: 0.1460 - classification_loss: 0.0229
398/500 [======================>.......] - ETA: 47s - loss: 0.1689 - regression_loss: 0.1460 - classification_loss: 0.0229
399/500 [======================>.......] - ETA: 46s - loss: 0.1686 - regression_loss: 0.1457 - classification_loss: 0.0229
400/500 [=======================>......] - ETA: 46s - loss: 0.1684 - regression_loss: 0.1455 - classification_loss: 0.0229
401/500 [=======================>......] - ETA: 46s - loss: 0.1682 - regression_loss: 0.1454 - classification_loss: 0.0228
402/500 [=======================>......] - ETA: 45s - loss: 0.1682 - regression_loss: 0.1454 - classification_loss: 0.0228
403/500 [=======================>......] - ETA: 45s - loss: 0.1680 - regression_loss: 0.1452 - classification_loss: 0.0228
404/500 [=======================>......] - ETA: 44s - loss: 0.1683 - regression_loss: 0.1455 - classification_loss: 0.0228
405/500 [=======================>......] - ETA: 44s - loss: 0.1681 - regression_loss: 0.1453 - classification_loss: 0.0228
406/500 [=======================>......] - ETA: 43s - loss: 0.1679 - regression_loss: 0.1451 - classification_loss: 0.0228
407/500 [=======================>......] - ETA: 43s - loss: 0.1682 - regression_loss: 0.1454 - classification_loss: 0.0228
408/500 [=======================>......] - ETA: 42s - loss: 0.1681 - regression_loss: 0.1453 - classification_loss: 0.0228
409/500 [=======================>......] - ETA: 42s - loss: 0.1681 - regression_loss: 0.1453 - classification_loss: 0.0228
410/500 [=======================>......] - ETA: 41s - loss: 0.1680 - regression_loss: 0.1453 - classification_loss: 0.0228
411/500 [=======================>......] - ETA: 41s - loss: 0.1680 - regression_loss: 0.1453 - classification_loss: 0.0227
412/500 [=======================>......] - ETA: 40s - loss: 0.1678 - regression_loss: 0.1451 - classification_loss: 0.0227
413/500 [=======================>......] - ETA: 40s - loss: 0.1676 - regression_loss: 0.1449 - classification_loss: 0.0227
414/500 [=======================>......] - ETA: 39s - loss: 0.1681 - regression_loss: 0.1453 - classification_loss: 0.0228
415/500 [=======================>......] - ETA: 39s - loss: 0.1678 - regression_loss: 0.1450 - classification_loss: 0.0227
416/500 [=======================>......] - ETA: 39s - loss: 0.1682 - regression_loss: 0.1454 - classification_loss: 0.0228
417/500 [========================>.....] - ETA: 38s - loss: 0.1680 - regression_loss: 0.1452 - classification_loss: 0.0227
418/500 [========================>.....] - ETA: 38s - loss: 0.1676 - regression_loss: 0.1449 - classification_loss: 0.0227
419/500 [========================>.....] - ETA: 37s - loss: 0.1674 - regression_loss: 0.1447 - classification_loss: 0.0227
420/500 [========================>.....] - ETA: 37s - loss: 0.1674 - regression_loss: 0.1447 - classification_loss: 0.0227
421/500 [========================>.....] - ETA: 36s - loss: 0.1671 - regression_loss: 0.1445 - classification_loss: 0.0226
422/500 [========================>.....] - ETA: 36s - loss: 0.1670 - regression_loss: 0.1444 - classification_loss: 0.0226
423/500 [========================>.....] - ETA: 35s - loss: 0.1668 - regression_loss: 0.1442 - classification_loss: 0.0226
424/500 [========================>.....] - ETA: 35s - loss: 0.1672 - regression_loss: 0.1446 - classification_loss: 0.0226
425/500 [========================>.....] - ETA: 34s - loss: 0.1670 - regression_loss: 0.1443 - classification_loss: 0.0226
426/500 [========================>.....] - ETA: 34s - loss: 0.1667 - regression_loss: 0.1442 - classification_loss: 0.0226
427/500 [========================>.....] - ETA: 33s - loss: 0.1669 - regression_loss: 0.1443 - classification_loss: 0.0226
428/500 [========================>.....] - ETA: 33s - loss: 0.1667 - regression_loss: 0.1440 - classification_loss: 0.0226
429/500 [========================>.....] - ETA: 33s - loss: 0.1668 - regression_loss: 0.1442 - classification_loss: 0.0226
430/500 [========================>.....] - ETA: 32s - loss: 0.1666 - regression_loss: 0.1440 - classification_loss: 0.0226
431/500 [========================>.....] - ETA: 32s - loss: 0.1663 - regression_loss: 0.1438 - classification_loss: 0.0225
432/500 [========================>.....] - ETA: 31s - loss: 0.1660 - regression_loss: 0.1435 - classification_loss: 0.0225
433/500 [========================>.....] - ETA: 31s - loss: 0.1661 - regression_loss: 0.1436 - classification_loss: 0.0225
434/500 [=========================>....] - ETA: 30s - loss: 0.1659 - regression_loss: 0.1434 - classification_loss: 0.0225
435/500 [=========================>....] - ETA: 30s - loss: 0.1662 - regression_loss: 0.1437 - classification_loss: 0.0225
436/500 [=========================>....] - ETA: 29s - loss: 0.1658 - regression_loss: 0.1434 - classification_loss: 0.0225
437/500 [=========================>....] - ETA: 29s - loss: 0.1656 - regression_loss: 0.1431 - classification_loss: 0.0224
438/500 [=========================>....] - ETA: 28s - loss: 0.1655 - regression_loss: 0.1431 - classification_loss: 0.0224
439/500 [=========================>....] - ETA: 28s - loss: 0.1653 - regression_loss: 0.1429 - classification_loss: 0.0224
440/500 [=========================>....] - ETA: 27s - loss: 0.1655 - regression_loss: 0.1431 - classification_loss: 0.0224
441/500 [=========================>....] - ETA: 27s - loss: 0.1652 - regression_loss: 0.1428 - classification_loss: 0.0224
442/500 [=========================>....] - ETA: 26s - loss: 0.1652 - regression_loss: 0.1428 - classification_loss: 0.0224
443/500 [=========================>....] - ETA: 26s - loss: 0.1650 - regression_loss: 0.1427 - classification_loss: 0.0224
444/500 [=========================>....] - ETA: 26s - loss: 0.1651 - regression_loss: 0.1428 - classification_loss: 0.0223
445/500 [=========================>....] - ETA: 25s - loss: 0.1653 - regression_loss: 0.1429 - classification_loss: 0.0224
446/500 [=========================>....] - ETA: 25s - loss: 0.1656 - regression_loss: 0.1432 - classification_loss: 0.0224
447/500 [=========================>....] - ETA: 24s - loss: 0.1656 - regression_loss: 0.1432 - classification_loss: 0.0224
448/500 [=========================>....] - ETA: 24s - loss: 0.1653 - regression_loss: 0.1429 - classification_loss: 0.0224
449/500 [=========================>....] - ETA: 23s - loss: 0.1652 - regression_loss: 0.1429 - classification_loss: 0.0224
450/500 [==========================>...] - ETA: 23s - loss: 0.1650 - regression_loss: 0.1426 - classification_loss: 0.0223
451/500 [==========================>...] - ETA: 22s - loss: 0.1646 - regression_loss: 0.1423 - classification_loss: 0.0223
452/500 [==========================>...] - ETA: 22s - loss: 0.1647 - regression_loss: 0.1424 - classification_loss: 0.0223
453/500 [==========================>...] - ETA: 21s - loss: 0.1646 - regression_loss: 0.1423 - classification_loss: 0.0223
454/500 [==========================>...] - ETA: 21s - loss: 0.1650 - regression_loss: 0.1427 - classification_loss: 0.0223
455/500 [==========================>...] - ETA: 20s - loss: 0.1650 - regression_loss: 0.1427 - classification_loss: 0.0223
456/500 [==========================>...] - ETA: 20s - loss: 0.1650 - regression_loss: 0.1428 - classification_loss: 0.0223
457/500 [==========================>...] - ETA: 19s - loss: 0.1654 - regression_loss: 0.1431 - classification_loss: 0.0223
458/500 [==========================>...] - ETA: 19s - loss: 0.1656 - regression_loss: 0.1433 - classification_loss: 0.0223
459/500 [==========================>...] - ETA: 19s - loss: 0.1655 - regression_loss: 0.1432 - classification_loss: 0.0223
460/500 [==========================>...] - ETA: 18s - loss: 0.1658 - regression_loss: 0.1435 - classification_loss: 0.0223
461/500 [==========================>...] - ETA: 18s - loss: 0.1656 - regression_loss: 0.1433 - classification_loss: 0.0222
462/500 [==========================>...] - ETA: 17s - loss: 0.1659 - regression_loss: 0.1436 - classification_loss: 0.0223
463/500 [==========================>...] - ETA: 17s - loss: 0.1659 - regression_loss: 0.1436 - classification_loss: 0.0223
464/500 [==========================>...] - ETA: 16s - loss: 0.1656 - regression_loss: 0.1434 - classification_loss: 0.0222
465/500 [==========================>...] - ETA: 16s - loss: 0.1656 - regression_loss: 0.1434 - classification_loss: 0.0222
466/500 [==========================>...] - ETA: 15s - loss: 0.1654 - regression_loss: 0.1432 - classification_loss: 0.0222
467/500 [===========================>..] - ETA: 15s - loss: 0.1655 - regression_loss: 0.1433 - classification_loss: 0.0222
468/500 [===========================>..] - ETA: 14s - loss: 0.1655 - regression_loss: 0.1434 - classification_loss: 0.0221
469/500 [===========================>..] - ETA: 14s - loss: 0.1661 - regression_loss: 0.1439 - classification_loss: 0.0222
470/500 [===========================>..] - ETA: 13s - loss: 0.1659 - regression_loss: 0.1437 - classification_loss: 0.0222
471/500 [===========================>..] - ETA: 13s - loss: 0.1659 - regression_loss: 0.1438 - classification_loss: 0.0222
472/500 [===========================>..] - ETA: 13s - loss: 0.1659 - regression_loss: 0.1438 - classification_loss: 0.0221
473/500 [===========================>..] - ETA: 12s - loss: 0.1657 - regression_loss: 0.1436 - classification_loss: 0.0221
474/500 [===========================>..] - ETA: 12s - loss: 0.1656 - regression_loss: 0.1435 - classification_loss: 0.0221
475/500 [===========================>..] - ETA: 11s - loss: 0.1658 - regression_loss: 0.1437 - classification_loss: 0.0221
476/500 [===========================>..] - ETA: 11s - loss: 0.1660 - regression_loss: 0.1438 - classification_loss: 0.0222
477/500 [===========================>..] - ETA: 10s - loss: 0.1657 - regression_loss: 0.1436 - classification_loss: 0.0221
478/500 [===========================>..] - ETA: 10s - loss: 0.1655 - regression_loss: 0.1433 - classification_loss: 0.0221
479/500 [===========================>..] - ETA: 9s - loss: 0.1652 - regression_loss: 0.1432 - classification_loss: 0.0221 
480/500 [===========================>..] - ETA: 9s - loss: 0.1652 - regression_loss: 0.1432 - classification_loss: 0.0221
481/500 [===========================>..] - ETA: 8s - loss: 0.1650 - regression_loss: 0.1430 - classification_loss: 0.0220
482/500 [===========================>..] - ETA: 8s - loss: 0.1653 - regression_loss: 0.1432 - classification_loss: 0.0221
483/500 [===========================>..] - ETA: 7s - loss: 0.1653 - regression_loss: 0.1432 - classification_loss: 0.0221
484/500 [============================>.] - ETA: 7s - loss: 0.1652 - regression_loss: 0.1431 - classification_loss: 0.0221
485/500 [============================>.] - ETA: 6s - loss: 0.1651 - regression_loss: 0.1430 - classification_loss: 0.0220
486/500 [============================>.] - ETA: 6s - loss: 0.1648 - regression_loss: 0.1428 - classification_loss: 0.0220
487/500 [============================>.] - ETA: 6s - loss: 0.1645 - regression_loss: 0.1425 - classification_loss: 0.0220
488/500 [============================>.] - ETA: 5s - loss: 0.1647 - regression_loss: 0.1427 - classification_loss: 0.0220
489/500 [============================>.] - ETA: 5s - loss: 0.1645 - regression_loss: 0.1425 - classification_loss: 0.0220
490/500 [============================>.] - ETA: 4s - loss: 0.1645 - regression_loss: 0.1425 - classification_loss: 0.0220
491/500 [============================>.] - ETA: 4s - loss: 0.1647 - regression_loss: 0.1427 - classification_loss: 0.0220
492/500 [============================>.] - ETA: 3s - loss: 0.1647 - regression_loss: 0.1427 - classification_loss: 0.0220
493/500 [============================>.] - ETA: 3s - loss: 0.1646 - regression_loss: 0.1426 - classification_loss: 0.0220
494/500 [============================>.] - ETA: 2s - loss: 0.1645 - regression_loss: 0.1425 - classification_loss: 0.0220
495/500 [============================>.] - ETA: 2s - loss: 0.1644 - regression_loss: 0.1425 - classification_loss: 0.0219
496/500 [============================>.] - ETA: 1s - loss: 0.1642 - regression_loss: 0.1423 - classification_loss: 0.0219
497/500 [============================>.] - ETA: 1s - loss: 0.1640 - regression_loss: 0.1421 - classification_loss: 0.0219
498/500 [============================>.] - ETA: 0s - loss: 0.1637 - regression_loss: 0.1419 - classification_loss: 0.0219
499/500 [============================>.] - ETA: 0s - loss: 0.1639 - regression_loss: 0.1420 - classification_loss: 0.0219
500/500 [==============================] - 232s 465ms/step - loss: 0.1639 - regression_loss: 0.1420 - classification_loss: 0.0219
44 instances of class building with average precision: 0.7980
mAP: 0.7980

Epoch 00003: saving model to ./snapshots/resnet50_csv_03.h5
Epoch 4/8

  1/500 [..............................] - ETA: 3:50 - loss: 0.0384 - regression_loss: 0.0321 - classification_loss: 0.0063
  2/500 [..............................] - ETA: 3:50 - loss: 0.0987 - regression_loss: 0.0889 - classification_loss: 0.0098
  3/500 [..............................] - ETA: 3:50 - loss: 0.1481 - regression_loss: 0.1280 - classification_loss: 0.0202
  4/500 [..............................] - ETA: 3:50 - loss: 0.1494 - regression_loss: 0.1308 - classification_loss: 0.0186
  5/500 [..............................] - ETA: 3:49 - loss: 0.1584 - regression_loss: 0.1419 - classification_loss: 0.0165
  6/500 [..............................] - ETA: 3:49 - loss: 0.1436 - regression_loss: 0.1286 - classification_loss: 0.0149
  7/500 [..............................] - ETA: 3:49 - loss: 0.1792 - regression_loss: 0.1602 - classification_loss: 0.0189
  8/500 [..............................] - ETA: 3:48 - loss: 0.1619 - regression_loss: 0.1444 - classification_loss: 0.0174
  9/500 [..............................] - ETA: 3:48 - loss: 0.1719 - regression_loss: 0.1547 - classification_loss: 0.0172
 10/500 [..............................] - ETA: 3:48 - loss: 0.1638 - regression_loss: 0.1471 - classification_loss: 0.0167
 11/500 [..............................] - ETA: 3:47 - loss: 0.1506 - regression_loss: 0.1348 - classification_loss: 0.0158
 12/500 [..............................] - ETA: 3:46 - loss: 0.1422 - regression_loss: 0.1267 - classification_loss: 0.0155
 13/500 [..............................] - ETA: 3:46 - loss: 0.1455 - regression_loss: 0.1306 - classification_loss: 0.0149
 14/500 [..............................] - ETA: 3:45 - loss: 0.1460 - regression_loss: 0.1311 - classification_loss: 0.0149
 15/500 [..............................] - ETA: 3:45 - loss: 0.1541 - regression_loss: 0.1374 - classification_loss: 0.0166
 16/500 [..............................] - ETA: 3:44 - loss: 0.1514 - regression_loss: 0.1351 - classification_loss: 0.0163
 17/500 [>.............................] - ETA: 3:44 - loss: 0.1562 - regression_loss: 0.1401 - classification_loss: 0.0161
 18/500 [>.............................] - ETA: 3:43 - loss: 0.1515 - regression_loss: 0.1359 - classification_loss: 0.0156
 19/500 [>.............................] - ETA: 3:43 - loss: 0.1591 - regression_loss: 0.1422 - classification_loss: 0.0169
 20/500 [>.............................] - ETA: 3:42 - loss: 0.1625 - regression_loss: 0.1458 - classification_loss: 0.0167
 21/500 [>.............................] - ETA: 3:42 - loss: 0.1624 - regression_loss: 0.1459 - classification_loss: 0.0165
 22/500 [>.............................] - ETA: 3:41 - loss: 0.1665 - regression_loss: 0.1489 - classification_loss: 0.0176
 23/500 [>.............................] - ETA: 3:41 - loss: 0.1638 - regression_loss: 0.1466 - classification_loss: 0.0172
 24/500 [>.............................] - ETA: 3:40 - loss: 0.1628 - regression_loss: 0.1458 - classification_loss: 0.0170
 25/500 [>.............................] - ETA: 3:40 - loss: 0.1602 - regression_loss: 0.1436 - classification_loss: 0.0166
 26/500 [>.............................] - ETA: 3:40 - loss: 0.1574 - regression_loss: 0.1411 - classification_loss: 0.0163
 27/500 [>.............................] - ETA: 3:40 - loss: 0.1624 - regression_loss: 0.1452 - classification_loss: 0.0172
 28/500 [>.............................] - ETA: 3:39 - loss: 0.1577 - regression_loss: 0.1409 - classification_loss: 0.0168
 29/500 [>.............................] - ETA: 3:39 - loss: 0.1539 - regression_loss: 0.1372 - classification_loss: 0.0167
 30/500 [>.............................] - ETA: 3:39 - loss: 0.1540 - regression_loss: 0.1375 - classification_loss: 0.0166
 31/500 [>.............................] - ETA: 3:38 - loss: 0.1539 - regression_loss: 0.1376 - classification_loss: 0.0163
 32/500 [>.............................] - ETA: 3:38 - loss: 0.1538 - regression_loss: 0.1376 - classification_loss: 0.0162
 33/500 [>.............................] - ETA: 3:37 - loss: 0.1566 - regression_loss: 0.1398 - classification_loss: 0.0168
 34/500 [=>............................] - ETA: 3:37 - loss: 0.1551 - regression_loss: 0.1386 - classification_loss: 0.0165
 35/500 [=>............................] - ETA: 3:36 - loss: 0.1522 - regression_loss: 0.1359 - classification_loss: 0.0163
 36/500 [=>............................] - ETA: 3:36 - loss: 0.1522 - regression_loss: 0.1359 - classification_loss: 0.0163
 37/500 [=>............................] - ETA: 3:35 - loss: 0.1495 - regression_loss: 0.1335 - classification_loss: 0.0160
 38/500 [=>............................] - ETA: 3:35 - loss: 0.1459 - regression_loss: 0.1301 - classification_loss: 0.0157
 39/500 [=>............................] - ETA: 3:34 - loss: 0.1505 - regression_loss: 0.1342 - classification_loss: 0.0163
 40/500 [=>............................] - ETA: 3:34 - loss: 0.1493 - regression_loss: 0.1331 - classification_loss: 0.0162
 41/500 [=>............................] - ETA: 3:34 - loss: 0.1467 - regression_loss: 0.1307 - classification_loss: 0.0160
 42/500 [=>............................] - ETA: 3:33 - loss: 0.1468 - regression_loss: 0.1309 - classification_loss: 0.0159
 43/500 [=>............................] - ETA: 3:33 - loss: 0.1449 - regression_loss: 0.1291 - classification_loss: 0.0158
 44/500 [=>............................] - ETA: 3:32 - loss: 0.1426 - regression_loss: 0.1270 - classification_loss: 0.0156
 45/500 [=>............................] - ETA: 3:32 - loss: 0.1455 - regression_loss: 0.1293 - classification_loss: 0.0162
 46/500 [=>............................] - ETA: 3:31 - loss: 0.1430 - regression_loss: 0.1270 - classification_loss: 0.0160
 47/500 [=>............................] - ETA: 3:31 - loss: 0.1418 - regression_loss: 0.1259 - classification_loss: 0.0159
 48/500 [=>............................] - ETA: 3:30 - loss: 0.1424 - regression_loss: 0.1266 - classification_loss: 0.0158
 49/500 [=>............................] - ETA: 3:30 - loss: 0.1445 - regression_loss: 0.1281 - classification_loss: 0.0164
 50/500 [==>...........................] - ETA: 3:30 - loss: 0.1418 - regression_loss: 0.1257 - classification_loss: 0.0162
 51/500 [==>...........................] - ETA: 3:29 - loss: 0.1394 - regression_loss: 0.1234 - classification_loss: 0.0159
 52/500 [==>...........................] - ETA: 3:29 - loss: 0.1421 - regression_loss: 0.1256 - classification_loss: 0.0165
 53/500 [==>...........................] - ETA: 3:28 - loss: 0.1409 - regression_loss: 0.1245 - classification_loss: 0.0164
 54/500 [==>...........................] - ETA: 3:28 - loss: 0.1410 - regression_loss: 0.1247 - classification_loss: 0.0163
 55/500 [==>...........................] - ETA: 3:27 - loss: 0.1431 - regression_loss: 0.1269 - classification_loss: 0.0162
 56/500 [==>...........................] - ETA: 3:27 - loss: 0.1452 - regression_loss: 0.1285 - classification_loss: 0.0167
 57/500 [==>...........................] - ETA: 3:26 - loss: 0.1449 - regression_loss: 0.1283 - classification_loss: 0.0166
 58/500 [==>...........................] - ETA: 3:26 - loss: 0.1463 - regression_loss: 0.1298 - classification_loss: 0.0165
 59/500 [==>...........................] - ETA: 3:25 - loss: 0.1450 - regression_loss: 0.1286 - classification_loss: 0.0164
 60/500 [==>...........................] - ETA: 3:25 - loss: 0.1451 - regression_loss: 0.1288 - classification_loss: 0.0162
 61/500 [==>...........................] - ETA: 3:24 - loss: 0.1477 - regression_loss: 0.1310 - classification_loss: 0.0167
 62/500 [==>...........................] - ETA: 3:24 - loss: 0.1464 - regression_loss: 0.1298 - classification_loss: 0.0165
 63/500 [==>...........................] - ETA: 3:23 - loss: 0.1467 - regression_loss: 0.1302 - classification_loss: 0.0165
 64/500 [==>...........................] - ETA: 3:23 - loss: 0.1451 - regression_loss: 0.1287 - classification_loss: 0.0164
 65/500 [==>...........................] - ETA: 3:22 - loss: 0.1438 - regression_loss: 0.1275 - classification_loss: 0.0162
 66/500 [==>...........................] - ETA: 3:22 - loss: 0.1424 - regression_loss: 0.1263 - classification_loss: 0.0161
 67/500 [===>..........................] - ETA: 3:21 - loss: 0.1408 - regression_loss: 0.1248 - classification_loss: 0.0159
 68/500 [===>..........................] - ETA: 3:21 - loss: 0.1396 - regression_loss: 0.1237 - classification_loss: 0.0159
 69/500 [===>..........................] - ETA: 3:20 - loss: 0.1397 - regression_loss: 0.1239 - classification_loss: 0.0158
 70/500 [===>..........................] - ETA: 3:20 - loss: 0.1410 - regression_loss: 0.1249 - classification_loss: 0.0161
 71/500 [===>..........................] - ETA: 3:20 - loss: 0.1397 - regression_loss: 0.1236 - classification_loss: 0.0161
 72/500 [===>..........................] - ETA: 3:19 - loss: 0.1384 - regression_loss: 0.1225 - classification_loss: 0.0159
 73/500 [===>..........................] - ETA: 3:19 - loss: 0.1385 - regression_loss: 0.1227 - classification_loss: 0.0158
 74/500 [===>..........................] - ETA: 3:18 - loss: 0.1397 - regression_loss: 0.1236 - classification_loss: 0.0161
 75/500 [===>..........................] - ETA: 3:18 - loss: 0.1400 - regression_loss: 0.1239 - classification_loss: 0.0161
 76/500 [===>..........................] - ETA: 3:17 - loss: 0.1394 - regression_loss: 0.1234 - classification_loss: 0.0159
 77/500 [===>..........................] - ETA: 3:17 - loss: 0.1405 - regression_loss: 0.1243 - classification_loss: 0.0162
 78/500 [===>..........................] - ETA: 3:16 - loss: 0.1396 - regression_loss: 0.1235 - classification_loss: 0.0161
 79/500 [===>..........................] - ETA: 3:16 - loss: 0.1386 - regression_loss: 0.1226 - classification_loss: 0.0160
 80/500 [===>..........................] - ETA: 3:15 - loss: 0.1384 - regression_loss: 0.1224 - classification_loss: 0.0160
 81/500 [===>..........................] - ETA: 3:15 - loss: 0.1383 - regression_loss: 0.1224 - classification_loss: 0.0159
 82/500 [===>..........................] - ETA: 3:14 - loss: 0.1396 - regression_loss: 0.1234 - classification_loss: 0.0162
 83/500 [===>..........................] - ETA: 3:14 - loss: 0.1382 - regression_loss: 0.1221 - classification_loss: 0.0161
 84/500 [====>.........................] - ETA: 3:14 - loss: 0.1368 - regression_loss: 0.1208 - classification_loss: 0.0160
 85/500 [====>.........................] - ETA: 3:13 - loss: 0.1359 - regression_loss: 0.1199 - classification_loss: 0.0159
 86/500 [====>.........................] - ETA: 3:13 - loss: 0.1344 - regression_loss: 0.1186 - classification_loss: 0.0158
 87/500 [====>.........................] - ETA: 3:12 - loss: 0.1335 - regression_loss: 0.1178 - classification_loss: 0.0157
 88/500 [====>.........................] - ETA: 3:12 - loss: 0.1335 - regression_loss: 0.1178 - classification_loss: 0.0156
 89/500 [====>.........................] - ETA: 3:11 - loss: 0.1341 - regression_loss: 0.1185 - classification_loss: 0.0156
 90/500 [====>.........................] - ETA: 3:11 - loss: 0.1352 - regression_loss: 0.1193 - classification_loss: 0.0159
 91/500 [====>.........................] - ETA: 3:10 - loss: 0.1363 - regression_loss: 0.1202 - classification_loss: 0.0161
 92/500 [====>.........................] - ETA: 3:10 - loss: 0.1352 - regression_loss: 0.1192 - classification_loss: 0.0160
 93/500 [====>.........................] - ETA: 3:09 - loss: 0.1345 - regression_loss: 0.1186 - classification_loss: 0.0159
 94/500 [====>.........................] - ETA: 3:09 - loss: 0.1339 - regression_loss: 0.1180 - classification_loss: 0.0159
 95/500 [====>.........................] - ETA: 3:08 - loss: 0.1340 - regression_loss: 0.1181 - classification_loss: 0.0158
 96/500 [====>.........................] - ETA: 3:08 - loss: 0.1343 - regression_loss: 0.1185 - classification_loss: 0.0158
 97/500 [====>.........................] - ETA: 3:07 - loss: 0.1336 - regression_loss: 0.1178 - classification_loss: 0.0157
 98/500 [====>.........................] - ETA: 3:07 - loss: 0.1326 - regression_loss: 0.1169 - classification_loss: 0.0157
 99/500 [====>.........................] - ETA: 3:06 - loss: 0.1340 - regression_loss: 0.1181 - classification_loss: 0.0159
100/500 [=====>........................] - ETA: 3:06 - loss: 0.1330 - regression_loss: 0.1172 - classification_loss: 0.0158
101/500 [=====>........................] - ETA: 3:06 - loss: 0.1341 - regression_loss: 0.1181 - classification_loss: 0.0160
102/500 [=====>........................] - ETA: 3:05 - loss: 0.1333 - regression_loss: 0.1173 - classification_loss: 0.0160
103/500 [=====>........................] - ETA: 3:05 - loss: 0.1339 - regression_loss: 0.1180 - classification_loss: 0.0159
104/500 [=====>........................] - ETA: 3:04 - loss: 0.1338 - regression_loss: 0.1179 - classification_loss: 0.0159
105/500 [=====>........................] - ETA: 3:04 - loss: 0.1329 - regression_loss: 0.1171 - classification_loss: 0.0158
106/500 [=====>........................] - ETA: 3:03 - loss: 0.1324 - regression_loss: 0.1166 - classification_loss: 0.0157
107/500 [=====>........................] - ETA: 3:03 - loss: 0.1327 - regression_loss: 0.1169 - classification_loss: 0.0157
108/500 [=====>........................] - ETA: 3:02 - loss: 0.1334 - regression_loss: 0.1175 - classification_loss: 0.0159
109/500 [=====>........................] - ETA: 3:02 - loss: 0.1328 - regression_loss: 0.1169 - classification_loss: 0.0158
110/500 [=====>........................] - ETA: 3:01 - loss: 0.1319 - regression_loss: 0.1162 - classification_loss: 0.0157
111/500 [=====>........................] - ETA: 3:01 - loss: 0.1312 - regression_loss: 0.1155 - classification_loss: 0.0156
112/500 [=====>........................] - ETA: 3:00 - loss: 0.1321 - regression_loss: 0.1163 - classification_loss: 0.0158
113/500 [=====>........................] - ETA: 3:00 - loss: 0.1310 - regression_loss: 0.1153 - classification_loss: 0.0157
114/500 [=====>........................] - ETA: 2:59 - loss: 0.1311 - regression_loss: 0.1154 - classification_loss: 0.0157
115/500 [=====>........................] - ETA: 2:59 - loss: 0.1305 - regression_loss: 0.1148 - classification_loss: 0.0157
116/500 [=====>........................] - ETA: 2:58 - loss: 0.1305 - regression_loss: 0.1149 - classification_loss: 0.0156
117/500 [======>.......................] - ETA: 2:58 - loss: 0.1315 - regression_loss: 0.1159 - classification_loss: 0.0156
118/500 [======>.......................] - ETA: 2:57 - loss: 0.1308 - regression_loss: 0.1153 - classification_loss: 0.0155
119/500 [======>.......................] - ETA: 2:57 - loss: 0.1322 - regression_loss: 0.1166 - classification_loss: 0.0157
120/500 [======>.......................] - ETA: 2:57 - loss: 0.1315 - regression_loss: 0.1159 - classification_loss: 0.0156
121/500 [======>.......................] - ETA: 2:56 - loss: 0.1311 - regression_loss: 0.1156 - classification_loss: 0.0155
122/500 [======>.......................] - ETA: 2:56 - loss: 0.1310 - regression_loss: 0.1155 - classification_loss: 0.0155
123/500 [======>.......................] - ETA: 2:55 - loss: 0.1307 - regression_loss: 0.1153 - classification_loss: 0.0154
124/500 [======>.......................] - ETA: 2:55 - loss: 0.1313 - regression_loss: 0.1159 - classification_loss: 0.0154
125/500 [======>.......................] - ETA: 2:54 - loss: 0.1321 - regression_loss: 0.1166 - classification_loss: 0.0156
126/500 [======>.......................] - ETA: 2:54 - loss: 0.1318 - regression_loss: 0.1163 - classification_loss: 0.0155
127/500 [======>.......................] - ETA: 2:53 - loss: 0.1320 - regression_loss: 0.1165 - classification_loss: 0.0155
128/500 [======>.......................] - ETA: 2:53 - loss: 0.1312 - regression_loss: 0.1158 - classification_loss: 0.0154
129/500 [======>.......................] - ETA: 2:52 - loss: 0.1312 - regression_loss: 0.1159 - classification_loss: 0.0153
130/500 [======>.......................] - ETA: 2:52 - loss: 0.1324 - regression_loss: 0.1169 - classification_loss: 0.0155
131/500 [======>.......................] - ETA: 2:51 - loss: 0.1316 - regression_loss: 0.1162 - classification_loss: 0.0154
132/500 [======>.......................] - ETA: 2:51 - loss: 0.1313 - regression_loss: 0.1159 - classification_loss: 0.0154
133/500 [======>.......................] - ETA: 2:50 - loss: 0.1316 - regression_loss: 0.1162 - classification_loss: 0.0154
134/500 [=======>......................] - ETA: 2:50 - loss: 0.1324 - regression_loss: 0.1168 - classification_loss: 0.0155
135/500 [=======>......................] - ETA: 2:49 - loss: 0.1315 - regression_loss: 0.1161 - classification_loss: 0.0154
136/500 [=======>......................] - ETA: 2:49 - loss: 0.1322 - regression_loss: 0.1166 - classification_loss: 0.0156
137/500 [=======>......................] - ETA: 2:49 - loss: 0.1321 - regression_loss: 0.1165 - classification_loss: 0.0156
138/500 [=======>......................] - ETA: 2:48 - loss: 0.1314 - regression_loss: 0.1159 - classification_loss: 0.0155
139/500 [=======>......................] - ETA: 2:48 - loss: 0.1309 - regression_loss: 0.1155 - classification_loss: 0.0154
140/500 [=======>......................] - ETA: 2:47 - loss: 0.1302 - regression_loss: 0.1149 - classification_loss: 0.0154
141/500 [=======>......................] - ETA: 2:47 - loss: 0.1303 - regression_loss: 0.1150 - classification_loss: 0.0153
142/500 [=======>......................] - ETA: 2:46 - loss: 0.1299 - regression_loss: 0.1146 - classification_loss: 0.0153
143/500 [=======>......................] - ETA: 2:46 - loss: 0.1307 - regression_loss: 0.1153 - classification_loss: 0.0155
144/500 [=======>......................] - ETA: 2:45 - loss: 0.1300 - regression_loss: 0.1146 - classification_loss: 0.0154
145/500 [=======>......................] - ETA: 2:45 - loss: 0.1293 - regression_loss: 0.1140 - classification_loss: 0.0153
146/500 [=======>......................] - ETA: 2:44 - loss: 0.1303 - regression_loss: 0.1148 - classification_loss: 0.0155
147/500 [=======>......................] - ETA: 2:44 - loss: 0.1299 - regression_loss: 0.1145 - classification_loss: 0.0154
148/500 [=======>......................] - ETA: 2:43 - loss: 0.1293 - regression_loss: 0.1140 - classification_loss: 0.0153
149/500 [=======>......................] - ETA: 2:43 - loss: 0.1289 - regression_loss: 0.1136 - classification_loss: 0.0153
150/500 [========>.....................] - ETA: 2:42 - loss: 0.1291 - regression_loss: 0.1138 - classification_loss: 0.0153
151/500 [========>.....................] - ETA: 2:42 - loss: 0.1285 - regression_loss: 0.1132 - classification_loss: 0.0152
152/500 [========>.....................] - ETA: 2:42 - loss: 0.1283 - regression_loss: 0.1131 - classification_loss: 0.0152
153/500 [========>.....................] - ETA: 2:41 - loss: 0.1282 - regression_loss: 0.1131 - classification_loss: 0.0152
154/500 [========>.....................] - ETA: 2:41 - loss: 0.1279 - regression_loss: 0.1128 - classification_loss: 0.0151
155/500 [========>.....................] - ETA: 2:40 - loss: 0.1285 - regression_loss: 0.1132 - classification_loss: 0.0152
156/500 [========>.....................] - ETA: 2:40 - loss: 0.1279 - regression_loss: 0.1128 - classification_loss: 0.0152
157/500 [========>.....................] - ETA: 2:39 - loss: 0.1285 - regression_loss: 0.1132 - classification_loss: 0.0153
158/500 [========>.....................] - ETA: 2:39 - loss: 0.1286 - regression_loss: 0.1133 - classification_loss: 0.0153
159/500 [========>.....................] - ETA: 2:38 - loss: 0.1281 - regression_loss: 0.1129 - classification_loss: 0.0152
160/500 [========>.....................] - ETA: 2:38 - loss: 0.1277 - regression_loss: 0.1125 - classification_loss: 0.0152
161/500 [========>.....................] - ETA: 2:37 - loss: 0.1276 - regression_loss: 0.1124 - classification_loss: 0.0151
162/500 [========>.....................] - ETA: 2:37 - loss: 0.1284 - regression_loss: 0.1131 - classification_loss: 0.0153
163/500 [========>.....................] - ETA: 2:36 - loss: 0.1279 - regression_loss: 0.1126 - classification_loss: 0.0152
164/500 [========>.....................] - ETA: 2:36 - loss: 0.1272 - regression_loss: 0.1121 - classification_loss: 0.0152
165/500 [========>.....................] - ETA: 2:36 - loss: 0.1267 - regression_loss: 0.1116 - classification_loss: 0.0151
166/500 [========>.....................] - ETA: 2:35 - loss: 0.1260 - regression_loss: 0.1110 - classification_loss: 0.0151
167/500 [=========>....................] - ETA: 2:35 - loss: 0.1264 - regression_loss: 0.1113 - classification_loss: 0.0150
168/500 [=========>....................] - ETA: 2:34 - loss: 0.1269 - regression_loss: 0.1117 - classification_loss: 0.0152
169/500 [=========>....................] - ETA: 2:34 - loss: 0.1264 - regression_loss: 0.1113 - classification_loss: 0.0151
170/500 [=========>....................] - ETA: 2:33 - loss: 0.1260 - regression_loss: 0.1109 - classification_loss: 0.0151
171/500 [=========>....................] - ETA: 2:33 - loss: 0.1256 - regression_loss: 0.1106 - classification_loss: 0.0150
172/500 [=========>....................] - ETA: 2:32 - loss: 0.1254 - regression_loss: 0.1104 - classification_loss: 0.0150
173/500 [=========>....................] - ETA: 2:32 - loss: 0.1256 - regression_loss: 0.1106 - classification_loss: 0.0150
174/500 [=========>....................] - ETA: 2:31 - loss: 0.1262 - regression_loss: 0.1111 - classification_loss: 0.0151
175/500 [=========>....................] - ETA: 2:31 - loss: 0.1260 - regression_loss: 0.1109 - classification_loss: 0.0150
176/500 [=========>....................] - ETA: 2:30 - loss: 0.1256 - regression_loss: 0.1106 - classification_loss: 0.0150
177/500 [=========>....................] - ETA: 2:30 - loss: 0.1261 - regression_loss: 0.1110 - classification_loss: 0.0151
178/500 [=========>....................] - ETA: 2:29 - loss: 0.1258 - regression_loss: 0.1107 - classification_loss: 0.0151
179/500 [=========>....................] - ETA: 2:29 - loss: 0.1260 - regression_loss: 0.1109 - classification_loss: 0.0151
180/500 [=========>....................] - ETA: 2:29 - loss: 0.1253 - regression_loss: 0.1104 - classification_loss: 0.0150
181/500 [=========>....................] - ETA: 2:28 - loss: 0.1249 - regression_loss: 0.1099 - classification_loss: 0.0149
182/500 [=========>....................] - ETA: 2:28 - loss: 0.1244 - regression_loss: 0.1095 - classification_loss: 0.0149
183/500 [=========>....................] - ETA: 2:27 - loss: 0.1238 - regression_loss: 0.1090 - classification_loss: 0.0149
184/500 [==========>...................] - ETA: 2:27 - loss: 0.1238 - regression_loss: 0.1089 - classification_loss: 0.0148
185/500 [==========>...................] - ETA: 2:26 - loss: 0.1242 - regression_loss: 0.1092 - classification_loss: 0.0149
186/500 [==========>...................] - ETA: 2:26 - loss: 0.1240 - regression_loss: 0.1091 - classification_loss: 0.0149
187/500 [==========>...................] - ETA: 2:25 - loss: 0.1236 - regression_loss: 0.1088 - classification_loss: 0.0149
188/500 [==========>...................] - ETA: 2:25 - loss: 0.1237 - regression_loss: 0.1089 - classification_loss: 0.0149
189/500 [==========>...................] - ETA: 2:24 - loss: 0.1232 - regression_loss: 0.1084 - classification_loss: 0.0148
190/500 [==========>...................] - ETA: 2:24 - loss: 0.1237 - regression_loss: 0.1088 - classification_loss: 0.0149
191/500 [==========>...................] - ETA: 2:23 - loss: 0.1233 - regression_loss: 0.1085 - classification_loss: 0.0149
192/500 [==========>...................] - ETA: 2:23 - loss: 0.1238 - regression_loss: 0.1088 - classification_loss: 0.0150
193/500 [==========>...................] - ETA: 2:23 - loss: 0.1238 - regression_loss: 0.1088 - classification_loss: 0.0150
194/500 [==========>...................] - ETA: 2:22 - loss: 0.1234 - regression_loss: 0.1085 - classification_loss: 0.0149
195/500 [==========>...................] - ETA: 2:22 - loss: 0.1229 - regression_loss: 0.1081 - classification_loss: 0.0149
196/500 [==========>...................] - ETA: 2:21 - loss: 0.1229 - regression_loss: 0.1081 - classification_loss: 0.0148
197/500 [==========>...................] - ETA: 2:21 - loss: 0.1224 - regression_loss: 0.1076 - classification_loss: 0.0148
198/500 [==========>...................] - ETA: 2:20 - loss: 0.1220 - regression_loss: 0.1073 - classification_loss: 0.0147
199/500 [==========>...................] - ETA: 2:20 - loss: 0.1225 - regression_loss: 0.1077 - classification_loss: 0.0149
200/500 [===========>..................] - ETA: 2:19 - loss: 0.1224 - regression_loss: 0.1075 - classification_loss: 0.0148
201/500 [===========>..................] - ETA: 2:19 - loss: 0.1225 - regression_loss: 0.1076 - classification_loss: 0.0148
202/500 [===========>..................] - ETA: 2:18 - loss: 0.1229 - regression_loss: 0.1080 - classification_loss: 0.0149
203/500 [===========>..................] - ETA: 2:18 - loss: 0.1225 - regression_loss: 0.1077 - classification_loss: 0.0149
204/500 [===========>..................] - ETA: 2:17 - loss: 0.1220 - regression_loss: 0.1072 - classification_loss: 0.0148
205/500 [===========>..................] - ETA: 2:17 - loss: 0.1216 - regression_loss: 0.1068 - classification_loss: 0.0148
206/500 [===========>..................] - ETA: 2:16 - loss: 0.1220 - regression_loss: 0.1071 - classification_loss: 0.0149
207/500 [===========>..................] - ETA: 2:16 - loss: 0.1215 - regression_loss: 0.1066 - classification_loss: 0.0148
208/500 [===========>..................] - ETA: 2:15 - loss: 0.1210 - regression_loss: 0.1063 - classification_loss: 0.0148
209/500 [===========>..................] - ETA: 2:15 - loss: 0.1210 - regression_loss: 0.1062 - classification_loss: 0.0148
210/500 [===========>..................] - ETA: 2:15 - loss: 0.1206 - regression_loss: 0.1059 - classification_loss: 0.0147
211/500 [===========>..................] - ETA: 2:14 - loss: 0.1203 - regression_loss: 0.1055 - classification_loss: 0.0147
212/500 [===========>..................] - ETA: 2:14 - loss: 0.1198 - regression_loss: 0.1051 - classification_loss: 0.0147
213/500 [===========>..................] - ETA: 2:13 - loss: 0.1194 - regression_loss: 0.1048 - classification_loss: 0.0146
214/500 [===========>..................] - ETA: 2:13 - loss: 0.1193 - regression_loss: 0.1047 - classification_loss: 0.0146
215/500 [===========>..................] - ETA: 2:12 - loss: 0.1199 - regression_loss: 0.1051 - classification_loss: 0.0147
216/500 [===========>..................] - ETA: 2:12 - loss: 0.1195 - regression_loss: 0.1048 - classification_loss: 0.0147
217/500 [============>.................] - ETA: 2:11 - loss: 0.1199 - regression_loss: 0.1051 - classification_loss: 0.0148
218/500 [============>.................] - ETA: 2:11 - loss: 0.1195 - regression_loss: 0.1048 - classification_loss: 0.0147
219/500 [============>.................] - ETA: 2:10 - loss: 0.1191 - regression_loss: 0.1044 - classification_loss: 0.0147
220/500 [============>.................] - ETA: 2:10 - loss: 0.1193 - regression_loss: 0.1046 - classification_loss: 0.0147
221/500 [============>.................] - ETA: 2:09 - loss: 0.1192 - regression_loss: 0.1045 - classification_loss: 0.0146
222/500 [============>.................] - ETA: 2:09 - loss: 0.1192 - regression_loss: 0.1046 - classification_loss: 0.0146
223/500 [============>.................] - ETA: 2:09 - loss: 0.1188 - regression_loss: 0.1042 - classification_loss: 0.0146
224/500 [============>.................] - ETA: 2:08 - loss: 0.1192 - regression_loss: 0.1046 - classification_loss: 0.0147
225/500 [============>.................] - ETA: 2:08 - loss: 0.1189 - regression_loss: 0.1042 - classification_loss: 0.0146
226/500 [============>.................] - ETA: 2:07 - loss: 0.1192 - regression_loss: 0.1045 - classification_loss: 0.0147
227/500 [============>.................] - ETA: 2:07 - loss: 0.1189 - regression_loss: 0.1042 - classification_loss: 0.0147
228/500 [============>.................] - ETA: 2:06 - loss: 0.1193 - regression_loss: 0.1046 - classification_loss: 0.0146
229/500 [============>.................] - ETA: 2:06 - loss: 0.1188 - regression_loss: 0.1042 - classification_loss: 0.0146
230/500 [============>.................] - ETA: 2:05 - loss: 0.1186 - regression_loss: 0.1040 - classification_loss: 0.0146
231/500 [============>.................] - ETA: 2:05 - loss: 0.1190 - regression_loss: 0.1044 - classification_loss: 0.0147
232/500 [============>.................] - ETA: 2:04 - loss: 0.1186 - regression_loss: 0.1040 - classification_loss: 0.0146
233/500 [============>.................] - ETA: 2:04 - loss: 0.1188 - regression_loss: 0.1042 - classification_loss: 0.0146
234/500 [=============>................] - ETA: 2:03 - loss: 0.1188 - regression_loss: 0.1042 - classification_loss: 0.0146
235/500 [=============>................] - ETA: 2:03 - loss: 0.1185 - regression_loss: 0.1040 - classification_loss: 0.0145
236/500 [=============>................] - ETA: 2:03 - loss: 0.1185 - regression_loss: 0.1040 - classification_loss: 0.0145
237/500 [=============>................] - ETA: 2:02 - loss: 0.1184 - regression_loss: 0.1039 - classification_loss: 0.0145
238/500 [=============>................] - ETA: 2:02 - loss: 0.1184 - regression_loss: 0.1039 - classification_loss: 0.0144
239/500 [=============>................] - ETA: 2:01 - loss: 0.1179 - regression_loss: 0.1035 - classification_loss: 0.0144
240/500 [=============>................] - ETA: 2:01 - loss: 0.1183 - regression_loss: 0.1038 - classification_loss: 0.0145
241/500 [=============>................] - ETA: 2:00 - loss: 0.1178 - regression_loss: 0.1034 - classification_loss: 0.0144
242/500 [=============>................] - ETA: 2:00 - loss: 0.1175 - regression_loss: 0.1031 - classification_loss: 0.0144
243/500 [=============>................] - ETA: 1:59 - loss: 0.1179 - regression_loss: 0.1035 - classification_loss: 0.0144
244/500 [=============>................] - ETA: 1:59 - loss: 0.1175 - regression_loss: 0.1032 - classification_loss: 0.0144
245/500 [=============>................] - ETA: 1:58 - loss: 0.1179 - regression_loss: 0.1035 - classification_loss: 0.0144
246/500 [=============>................] - ETA: 1:58 - loss: 0.1183 - regression_loss: 0.1038 - classification_loss: 0.0145
247/500 [=============>................] - ETA: 1:57 - loss: 0.1180 - regression_loss: 0.1035 - classification_loss: 0.0145
248/500 [=============>................] - ETA: 1:57 - loss: 0.1180 - regression_loss: 0.1035 - classification_loss: 0.0145
249/500 [=============>................] - ETA: 1:56 - loss: 0.1181 - regression_loss: 0.1037 - classification_loss: 0.0144
250/500 [==============>...............] - ETA: 1:56 - loss: 0.1178 - regression_loss: 0.1034 - classification_loss: 0.0144
251/500 [==============>...............] - ETA: 1:56 - loss: 0.1182 - regression_loss: 0.1038 - classification_loss: 0.0144
252/500 [==============>...............] - ETA: 1:55 - loss: 0.1181 - regression_loss: 0.1038 - classification_loss: 0.0143
253/500 [==============>...............] - ETA: 1:55 - loss: 0.1186 - regression_loss: 0.1042 - classification_loss: 0.0144
254/500 [==============>...............] - ETA: 1:54 - loss: 0.1184 - regression_loss: 0.1040 - classification_loss: 0.0144
255/500 [==============>...............] - ETA: 1:54 - loss: 0.1183 - regression_loss: 0.1039 - classification_loss: 0.0143
256/500 [==============>...............] - ETA: 1:53 - loss: 0.1179 - regression_loss: 0.1036 - classification_loss: 0.0143
257/500 [==============>...............] - ETA: 1:53 - loss: 0.1181 - regression_loss: 0.1038 - classification_loss: 0.0143
258/500 [==============>...............] - ETA: 1:52 - loss: 0.1179 - regression_loss: 0.1036 - classification_loss: 0.0143
259/500 [==============>...............] - ETA: 1:52 - loss: 0.1184 - regression_loss: 0.1041 - classification_loss: 0.0143
260/500 [==============>...............] - ETA: 1:51 - loss: 0.1182 - regression_loss: 0.1038 - classification_loss: 0.0143
261/500 [==============>...............] - ETA: 1:51 - loss: 0.1177 - regression_loss: 0.1035 - classification_loss: 0.0143
262/500 [==============>...............] - ETA: 1:50 - loss: 0.1175 - regression_loss: 0.1033 - classification_loss: 0.0142
263/500 [==============>...............] - ETA: 1:50 - loss: 0.1176 - regression_loss: 0.1034 - classification_loss: 0.0142
264/500 [==============>...............] - ETA: 1:49 - loss: 0.1178 - regression_loss: 0.1036 - classification_loss: 0.0143
265/500 [==============>...............] - ETA: 1:49 - loss: 0.1176 - regression_loss: 0.1033 - classification_loss: 0.0143
266/500 [==============>...............] - ETA: 1:49 - loss: 0.1180 - regression_loss: 0.1036 - classification_loss: 0.0143
267/500 [===============>..............] - ETA: 1:48 - loss: 0.1177 - regression_loss: 0.1034 - classification_loss: 0.0143
268/500 [===============>..............] - ETA: 1:48 - loss: 0.1178 - regression_loss: 0.1035 - classification_loss: 0.0143
269/500 [===============>..............] - ETA: 1:47 - loss: 0.1178 - regression_loss: 0.1036 - classification_loss: 0.0143
270/500 [===============>..............] - ETA: 1:47 - loss: 0.1175 - regression_loss: 0.1033 - classification_loss: 0.0142
271/500 [===============>..............] - ETA: 1:46 - loss: 0.1172 - regression_loss: 0.1030 - classification_loss: 0.0142
272/500 [===============>..............] - ETA: 1:46 - loss: 0.1168 - regression_loss: 0.1027 - classification_loss: 0.0142
273/500 [===============>..............] - ETA: 1:45 - loss: 0.1165 - regression_loss: 0.1024 - classification_loss: 0.0141
274/500 [===============>..............] - ETA: 1:45 - loss: 0.1166 - regression_loss: 0.1025 - classification_loss: 0.0141
275/500 [===============>..............] - ETA: 1:44 - loss: 0.1171 - regression_loss: 0.1029 - classification_loss: 0.0142
276/500 [===============>..............] - ETA: 1:44 - loss: 0.1172 - regression_loss: 0.1030 - classification_loss: 0.0142
277/500 [===============>..............] - ETA: 1:43 - loss: 0.1170 - regression_loss: 0.1029 - classification_loss: 0.0141
278/500 [===============>..............] - ETA: 1:43 - loss: 0.1173 - regression_loss: 0.1031 - classification_loss: 0.0142
279/500 [===============>..............] - ETA: 1:42 - loss: 0.1172 - regression_loss: 0.1030 - classification_loss: 0.0142
280/500 [===============>..............] - ETA: 1:42 - loss: 0.1171 - regression_loss: 0.1029 - classification_loss: 0.0142
281/500 [===============>..............] - ETA: 1:42 - loss: 0.1172 - regression_loss: 0.1030 - classification_loss: 0.0141
282/500 [===============>..............] - ETA: 1:41 - loss: 0.1175 - regression_loss: 0.1033 - classification_loss: 0.0142
283/500 [===============>..............] - ETA: 1:41 - loss: 0.1172 - regression_loss: 0.1030 - classification_loss: 0.0142
284/500 [================>.............] - ETA: 1:40 - loss: 0.1169 - regression_loss: 0.1027 - classification_loss: 0.0141
285/500 [================>.............] - ETA: 1:40 - loss: 0.1165 - regression_loss: 0.1024 - classification_loss: 0.0141
286/500 [================>.............] - ETA: 1:39 - loss: 0.1167 - regression_loss: 0.1026 - classification_loss: 0.0142
287/500 [================>.............] - ETA: 1:39 - loss: 0.1167 - regression_loss: 0.1026 - classification_loss: 0.0142
288/500 [================>.............] - ETA: 1:38 - loss: 0.1165 - regression_loss: 0.1024 - classification_loss: 0.0141
289/500 [================>.............] - ETA: 1:38 - loss: 0.1162 - regression_loss: 0.1021 - classification_loss: 0.0141
290/500 [================>.............] - ETA: 1:37 - loss: 0.1159 - regression_loss: 0.1018 - classification_loss: 0.0141
291/500 [================>.............] - ETA: 1:37 - loss: 0.1157 - regression_loss: 0.1016 - classification_loss: 0.0140
292/500 [================>.............] - ETA: 1:36 - loss: 0.1160 - regression_loss: 0.1019 - classification_loss: 0.0141
293/500 [================>.............] - ETA: 1:36 - loss: 0.1157 - regression_loss: 0.1016 - classification_loss: 0.0141
294/500 [================>.............] - ETA: 1:35 - loss: 0.1154 - regression_loss: 0.1013 - classification_loss: 0.0140
295/500 [================>.............] - ETA: 1:35 - loss: 0.1154 - regression_loss: 0.1014 - classification_loss: 0.0140
296/500 [================>.............] - ETA: 1:35 - loss: 0.1152 - regression_loss: 0.1012 - classification_loss: 0.0140
297/500 [================>.............] - ETA: 1:34 - loss: 0.1158 - regression_loss: 0.1017 - classification_loss: 0.0141
298/500 [================>.............] - ETA: 1:34 - loss: 0.1158 - regression_loss: 0.1017 - classification_loss: 0.0140
299/500 [================>.............] - ETA: 1:33 - loss: 0.1155 - regression_loss: 0.1015 - classification_loss: 0.0140
300/500 [=================>............] - ETA: 1:33 - loss: 0.1155 - regression_loss: 0.1015 - classification_loss: 0.0140
301/500 [=================>............] - ETA: 1:32 - loss: 0.1156 - regression_loss: 0.1016 - classification_loss: 0.0140
302/500 [=================>............] - ETA: 1:32 - loss: 0.1152 - regression_loss: 0.1013 - classification_loss: 0.0140
303/500 [=================>............] - ETA: 1:31 - loss: 0.1151 - regression_loss: 0.1012 - classification_loss: 0.0139
304/500 [=================>............] - ETA: 1:31 - loss: 0.1150 - regression_loss: 0.1011 - classification_loss: 0.0139
305/500 [=================>............] - ETA: 1:30 - loss: 0.1154 - regression_loss: 0.1014 - classification_loss: 0.0140
306/500 [=================>............] - ETA: 1:30 - loss: 0.1151 - regression_loss: 0.1011 - classification_loss: 0.0139
307/500 [=================>............] - ETA: 1:29 - loss: 0.1154 - regression_loss: 0.1014 - classification_loss: 0.0140
308/500 [=================>............] - ETA: 1:29 - loss: 0.1151 - regression_loss: 0.1011 - classification_loss: 0.0140
309/500 [=================>............] - ETA: 1:28 - loss: 0.1151 - regression_loss: 0.1011 - classification_loss: 0.0140
310/500 [=================>............] - ETA: 1:28 - loss: 0.1148 - regression_loss: 0.1008 - classification_loss: 0.0139
311/500 [=================>............] - ETA: 1:28 - loss: 0.1144 - regression_loss: 0.1005 - classification_loss: 0.0139
312/500 [=================>............] - ETA: 1:27 - loss: 0.1150 - regression_loss: 0.1010 - classification_loss: 0.0140
313/500 [=================>............] - ETA: 1:27 - loss: 0.1148 - regression_loss: 0.1009 - classification_loss: 0.0140
314/500 [=================>............] - ETA: 1:26 - loss: 0.1148 - regression_loss: 0.1009 - classification_loss: 0.0140
315/500 [=================>............] - ETA: 1:26 - loss: 0.1148 - regression_loss: 0.1008 - classification_loss: 0.0139
316/500 [=================>............] - ETA: 1:25 - loss: 0.1148 - regression_loss: 0.1008 - classification_loss: 0.0139
317/500 [==================>...........] - ETA: 1:25 - loss: 0.1146 - regression_loss: 0.1007 - classification_loss: 0.0139
318/500 [==================>...........] - ETA: 1:24 - loss: 0.1148 - regression_loss: 0.1009 - classification_loss: 0.0140
319/500 [==================>...........] - ETA: 1:24 - loss: 0.1149 - regression_loss: 0.1010 - classification_loss: 0.0139
320/500 [==================>...........] - ETA: 1:23 - loss: 0.1147 - regression_loss: 0.1008 - classification_loss: 0.0139
321/500 [==================>...........] - ETA: 1:23 - loss: 0.1146 - regression_loss: 0.1007 - classification_loss: 0.0139
322/500 [==================>...........] - ETA: 1:22 - loss: 0.1146 - regression_loss: 0.1007 - classification_loss: 0.0139
323/500 [==================>...........] - ETA: 1:22 - loss: 0.1149 - regression_loss: 0.1010 - classification_loss: 0.0139
324/500 [==================>...........] - ETA: 1:21 - loss: 0.1147 - regression_loss: 0.1008 - classification_loss: 0.0139
325/500 [==================>...........] - ETA: 1:21 - loss: 0.1148 - regression_loss: 0.1009 - classification_loss: 0.0139
326/500 [==================>...........] - ETA: 1:21 - loss: 0.1146 - regression_loss: 0.1007 - classification_loss: 0.0139
327/500 [==================>...........] - ETA: 1:20 - loss: 0.1145 - regression_loss: 0.1007 - classification_loss: 0.0138
328/500 [==================>...........] - ETA: 1:20 - loss: 0.1148 - regression_loss: 0.1009 - classification_loss: 0.0139
329/500 [==================>...........] - ETA: 1:19 - loss: 0.1146 - regression_loss: 0.1008 - classification_loss: 0.0139
330/500 [==================>...........] - ETA: 1:19 - loss: 0.1146 - regression_loss: 0.1008 - classification_loss: 0.0138
331/500 [==================>...........] - ETA: 1:18 - loss: 0.1144 - regression_loss: 0.1006 - classification_loss: 0.0138
332/500 [==================>...........] - ETA: 1:18 - loss: 0.1146 - regression_loss: 0.1008 - classification_loss: 0.0139
333/500 [==================>...........] - ETA: 1:17 - loss: 0.1144 - regression_loss: 0.1006 - classification_loss: 0.0138
334/500 [===================>..........] - ETA: 1:17 - loss: 0.1144 - regression_loss: 0.1006 - classification_loss: 0.0138
335/500 [===================>..........] - ETA: 1:16 - loss: 0.1142 - regression_loss: 0.1004 - classification_loss: 0.0138
336/500 [===================>..........] - ETA: 1:16 - loss: 0.1140 - regression_loss: 0.1002 - classification_loss: 0.0138
337/500 [===================>..........] - ETA: 1:15 - loss: 0.1140 - regression_loss: 0.1002 - classification_loss: 0.0138
338/500 [===================>..........] - ETA: 1:15 - loss: 0.1137 - regression_loss: 0.1000 - classification_loss: 0.0137
339/500 [===================>..........] - ETA: 1:14 - loss: 0.1140 - regression_loss: 0.1002 - classification_loss: 0.0138
340/500 [===================>..........] - ETA: 1:14 - loss: 0.1137 - regression_loss: 0.1000 - classification_loss: 0.0138
341/500 [===================>..........] - ETA: 1:14 - loss: 0.1135 - regression_loss: 0.0998 - classification_loss: 0.0138
342/500 [===================>..........] - ETA: 1:13 - loss: 0.1136 - regression_loss: 0.0998 - classification_loss: 0.0137
343/500 [===================>..........] - ETA: 1:13 - loss: 0.1138 - regression_loss: 0.1000 - classification_loss: 0.0138
344/500 [===================>..........] - ETA: 1:12 - loss: 0.1137 - regression_loss: 0.0999 - classification_loss: 0.0138
345/500 [===================>..........] - ETA: 1:12 - loss: 0.1135 - regression_loss: 0.0997 - classification_loss: 0.0137
346/500 [===================>..........] - ETA: 1:11 - loss: 0.1132 - regression_loss: 0.0995 - classification_loss: 0.0137
347/500 [===================>..........] - ETA: 1:11 - loss: 0.1129 - regression_loss: 0.0992 - classification_loss: 0.0137
348/500 [===================>..........] - ETA: 1:10 - loss: 0.1129 - regression_loss: 0.0992 - classification_loss: 0.0137
349/500 [===================>..........] - ETA: 1:10 - loss: 0.1127 - regression_loss: 0.0990 - classification_loss: 0.0137
350/500 [====================>.........] - ETA: 1:09 - loss: 0.1129 - regression_loss: 0.0992 - classification_loss: 0.0137
351/500 [====================>.........] - ETA: 1:09 - loss: 0.1129 - regression_loss: 0.0993 - classification_loss: 0.0137
352/500 [====================>.........] - ETA: 1:08 - loss: 0.1131 - regression_loss: 0.0994 - classification_loss: 0.0137
353/500 [====================>.........] - ETA: 1:08 - loss: 0.1131 - regression_loss: 0.0994 - classification_loss: 0.0137
354/500 [====================>.........] - ETA: 1:07 - loss: 0.1129 - regression_loss: 0.0992 - classification_loss: 0.0137
355/500 [====================>.........] - ETA: 1:07 - loss: 0.1131 - regression_loss: 0.0994 - classification_loss: 0.0137
356/500 [====================>.........] - ETA: 1:07 - loss: 0.1134 - regression_loss: 0.0997 - classification_loss: 0.0137
357/500 [====================>.........] - ETA: 1:06 - loss: 0.1131 - regression_loss: 0.0994 - classification_loss: 0.0137
358/500 [====================>.........] - ETA: 1:06 - loss: 0.1132 - regression_loss: 0.0995 - classification_loss: 0.0137
359/500 [====================>.........] - ETA: 1:05 - loss: 0.1132 - regression_loss: 0.0996 - classification_loss: 0.0137
360/500 [====================>.........] - ETA: 1:05 - loss: 0.1131 - regression_loss: 0.0994 - classification_loss: 0.0136
361/500 [====================>.........] - ETA: 1:04 - loss: 0.1131 - regression_loss: 0.0995 - classification_loss: 0.0136
362/500 [====================>.........] - ETA: 1:04 - loss: 0.1133 - regression_loss: 0.0996 - classification_loss: 0.0137
363/500 [====================>.........] - ETA: 1:03 - loss: 0.1130 - regression_loss: 0.0994 - classification_loss: 0.0137
364/500 [====================>.........] - ETA: 1:03 - loss: 0.1128 - regression_loss: 0.0992 - classification_loss: 0.0136
365/500 [====================>.........] - ETA: 1:02 - loss: 0.1126 - regression_loss: 0.0990 - classification_loss: 0.0136
366/500 [====================>.........] - ETA: 1:02 - loss: 0.1124 - regression_loss: 0.0988 - classification_loss: 0.0136
367/500 [=====================>........] - ETA: 1:01 - loss: 0.1126 - regression_loss: 0.0990 - classification_loss: 0.0136
368/500 [=====================>........] - ETA: 1:01 - loss: 0.1124 - regression_loss: 0.0988 - classification_loss: 0.0136
369/500 [=====================>........] - ETA: 1:00 - loss: 0.1124 - regression_loss: 0.0988 - classification_loss: 0.0136
370/500 [=====================>........] - ETA: 1:00 - loss: 0.1123 - regression_loss: 0.0987 - classification_loss: 0.0136
371/500 [=====================>........] - ETA: 1:00 - loss: 0.1125 - regression_loss: 0.0989 - classification_loss: 0.0136
372/500 [=====================>........] - ETA: 59s - loss: 0.1127 - regression_loss: 0.0991 - classification_loss: 0.0136 
373/500 [=====================>........] - ETA: 59s - loss: 0.1125 - regression_loss: 0.0989 - classification_loss: 0.0136
374/500 [=====================>........] - ETA: 58s - loss: 0.1123 - regression_loss: 0.0987 - classification_loss: 0.0136
375/500 [=====================>........] - ETA: 58s - loss: 0.1123 - regression_loss: 0.0988 - classification_loss: 0.0136
376/500 [=====================>........] - ETA: 57s - loss: 0.1123 - regression_loss: 0.0987 - classification_loss: 0.0135
377/500 [=====================>........] - ETA: 57s - loss: 0.1120 - regression_loss: 0.0985 - classification_loss: 0.0135
378/500 [=====================>........] - ETA: 56s - loss: 0.1119 - regression_loss: 0.0984 - classification_loss: 0.0135
379/500 [=====================>........] - ETA: 56s - loss: 0.1118 - regression_loss: 0.0984 - classification_loss: 0.0135
380/500 [=====================>........] - ETA: 55s - loss: 0.1121 - regression_loss: 0.0985 - classification_loss: 0.0135
381/500 [=====================>........] - ETA: 55s - loss: 0.1118 - regression_loss: 0.0983 - classification_loss: 0.0135
382/500 [=====================>........] - ETA: 54s - loss: 0.1116 - regression_loss: 0.0982 - classification_loss: 0.0135
383/500 [=====================>........] - ETA: 54s - loss: 0.1119 - regression_loss: 0.0984 - classification_loss: 0.0135
384/500 [======================>.......] - ETA: 53s - loss: 0.1117 - regression_loss: 0.0982 - classification_loss: 0.0135
385/500 [======================>.......] - ETA: 53s - loss: 0.1117 - regression_loss: 0.0982 - classification_loss: 0.0135
386/500 [======================>.......] - ETA: 53s - loss: 0.1119 - regression_loss: 0.0984 - classification_loss: 0.0135
387/500 [======================>.......] - ETA: 52s - loss: 0.1117 - regression_loss: 0.0982 - classification_loss: 0.0135
388/500 [======================>.......] - ETA: 52s - loss: 0.1115 - regression_loss: 0.0980 - classification_loss: 0.0135
389/500 [======================>.......] - ETA: 51s - loss: 0.1115 - regression_loss: 0.0980 - classification_loss: 0.0135
390/500 [======================>.......] - ETA: 51s - loss: 0.1113 - regression_loss: 0.0978 - classification_loss: 0.0135
391/500 [======================>.......] - ETA: 50s - loss: 0.1111 - regression_loss: 0.0977 - classification_loss: 0.0134
392/500 [======================>.......] - ETA: 50s - loss: 0.1109 - regression_loss: 0.0975 - classification_loss: 0.0134
393/500 [======================>.......] - ETA: 49s - loss: 0.1108 - regression_loss: 0.0974 - classification_loss: 0.0134
394/500 [======================>.......] - ETA: 49s - loss: 0.1111 - regression_loss: 0.0977 - classification_loss: 0.0135
395/500 [======================>.......] - ETA: 48s - loss: 0.1109 - regression_loss: 0.0975 - classification_loss: 0.0134
396/500 [======================>.......] - ETA: 48s - loss: 0.1109 - regression_loss: 0.0975 - classification_loss: 0.0134
397/500 [======================>.......] - ETA: 47s - loss: 0.1109 - regression_loss: 0.0975 - classification_loss: 0.0134
398/500 [======================>.......] - ETA: 47s - loss: 0.1111 - regression_loss: 0.0977 - classification_loss: 0.0134
399/500 [======================>.......] - ETA: 47s - loss: 0.1109 - regression_loss: 0.0975 - classification_loss: 0.0134
400/500 [=======================>......] - ETA: 46s - loss: 0.1107 - regression_loss: 0.0973 - classification_loss: 0.0134
401/500 [=======================>......] - ETA: 46s - loss: 0.1105 - regression_loss: 0.0971 - classification_loss: 0.0134
402/500 [=======================>......] - ETA: 45s - loss: 0.1103 - regression_loss: 0.0969 - classification_loss: 0.0133
403/500 [=======================>......] - ETA: 45s - loss: 0.1105 - regression_loss: 0.0971 - classification_loss: 0.0134
404/500 [=======================>......] - ETA: 44s - loss: 0.1105 - regression_loss: 0.0972 - classification_loss: 0.0134
405/500 [=======================>......] - ETA: 44s - loss: 0.1103 - regression_loss: 0.0970 - classification_loss: 0.0134
406/500 [=======================>......] - ETA: 43s - loss: 0.1102 - regression_loss: 0.0968 - classification_loss: 0.0133
407/500 [=======================>......] - ETA: 43s - loss: 0.1105 - regression_loss: 0.0971 - classification_loss: 0.0134
408/500 [=======================>......] - ETA: 42s - loss: 0.1103 - regression_loss: 0.0970 - classification_loss: 0.0133
409/500 [=======================>......] - ETA: 42s - loss: 0.1104 - regression_loss: 0.0970 - classification_loss: 0.0133
410/500 [=======================>......] - ETA: 41s - loss: 0.1105 - regression_loss: 0.0972 - classification_loss: 0.0133
411/500 [=======================>......] - ETA: 41s - loss: 0.1104 - regression_loss: 0.0971 - classification_loss: 0.0133
412/500 [=======================>......] - ETA: 40s - loss: 0.1107 - regression_loss: 0.0973 - classification_loss: 0.0133
413/500 [=======================>......] - ETA: 40s - loss: 0.1107 - regression_loss: 0.0974 - classification_loss: 0.0133
414/500 [=======================>......] - ETA: 40s - loss: 0.1106 - regression_loss: 0.0973 - classification_loss: 0.0133
415/500 [=======================>......] - ETA: 39s - loss: 0.1107 - regression_loss: 0.0974 - classification_loss: 0.0133
416/500 [=======================>......] - ETA: 39s - loss: 0.1105 - regression_loss: 0.0973 - classification_loss: 0.0133
417/500 [========================>.....] - ETA: 38s - loss: 0.1106 - regression_loss: 0.0973 - classification_loss: 0.0133
418/500 [========================>.....] - ETA: 38s - loss: 0.1106 - regression_loss: 0.0973 - classification_loss: 0.0133
419/500 [========================>.....] - ETA: 37s - loss: 0.1108 - regression_loss: 0.0975 - classification_loss: 0.0133
420/500 [========================>.....] - ETA: 37s - loss: 0.1105 - regression_loss: 0.0973 - classification_loss: 0.0133
421/500 [========================>.....] - ETA: 36s - loss: 0.1105 - regression_loss: 0.0972 - classification_loss: 0.0133
422/500 [========================>.....] - ETA: 36s - loss: 0.1102 - regression_loss: 0.0970 - classification_loss: 0.0132
423/500 [========================>.....] - ETA: 35s - loss: 0.1105 - regression_loss: 0.0973 - classification_loss: 0.0132
424/500 [========================>.....] - ETA: 35s - loss: 0.1108 - regression_loss: 0.0976 - classification_loss: 0.0133
425/500 [========================>.....] - ETA: 34s - loss: 0.1109 - regression_loss: 0.0976 - classification_loss: 0.0133
426/500 [========================>.....] - ETA: 34s - loss: 0.1107 - regression_loss: 0.0975 - classification_loss: 0.0132
427/500 [========================>.....] - ETA: 33s - loss: 0.1108 - regression_loss: 0.0975 - classification_loss: 0.0132
428/500 [========================>.....] - ETA: 33s - loss: 0.1107 - regression_loss: 0.0974 - classification_loss: 0.0132
429/500 [========================>.....] - ETA: 33s - loss: 0.1110 - regression_loss: 0.0978 - classification_loss: 0.0133
430/500 [========================>.....] - ETA: 32s - loss: 0.1109 - regression_loss: 0.0977 - classification_loss: 0.0132
431/500 [========================>.....] - ETA: 32s - loss: 0.1113 - regression_loss: 0.0980 - classification_loss: 0.0133
432/500 [========================>.....] - ETA: 31s - loss: 0.1113 - regression_loss: 0.0980 - classification_loss: 0.0133
433/500 [========================>.....] - ETA: 31s - loss: 0.1111 - regression_loss: 0.0978 - classification_loss: 0.0132
434/500 [=========================>....] - ETA: 30s - loss: 0.1109 - regression_loss: 0.0977 - classification_loss: 0.0132
435/500 [=========================>....] - ETA: 30s - loss: 0.1110 - regression_loss: 0.0978 - classification_loss: 0.0132
436/500 [=========================>....] - ETA: 29s - loss: 0.1108 - regression_loss: 0.0976 - classification_loss: 0.0132
437/500 [=========================>....] - ETA: 29s - loss: 0.1106 - regression_loss: 0.0975 - classification_loss: 0.0132
438/500 [=========================>....] - ETA: 28s - loss: 0.1105 - regression_loss: 0.0973 - classification_loss: 0.0132
439/500 [=========================>....] - ETA: 28s - loss: 0.1104 - regression_loss: 0.0973 - classification_loss: 0.0131
440/500 [=========================>....] - ETA: 27s - loss: 0.1105 - regression_loss: 0.0974 - classification_loss: 0.0132
441/500 [=========================>....] - ETA: 27s - loss: 0.1103 - regression_loss: 0.0972 - classification_loss: 0.0132
442/500 [=========================>....] - ETA: 26s - loss: 0.1105 - regression_loss: 0.0973 - classification_loss: 0.0132
443/500 [=========================>....] - ETA: 26s - loss: 0.1106 - regression_loss: 0.0975 - classification_loss: 0.0132
444/500 [=========================>....] - ETA: 26s - loss: 0.1106 - regression_loss: 0.0975 - classification_loss: 0.0132
445/500 [=========================>....] - ETA: 25s - loss: 0.1105 - regression_loss: 0.0973 - classification_loss: 0.0131
446/500 [=========================>....] - ETA: 25s - loss: 0.1108 - regression_loss: 0.0976 - classification_loss: 0.0132
447/500 [=========================>....] - ETA: 24s - loss: 0.1107 - regression_loss: 0.0976 - classification_loss: 0.0132
448/500 [=========================>....] - ETA: 24s - loss: 0.1105 - regression_loss: 0.0974 - classification_loss: 0.0132
449/500 [=========================>....] - ETA: 23s - loss: 0.1104 - regression_loss: 0.0973 - classification_loss: 0.0131
450/500 [==========================>...] - ETA: 23s - loss: 0.1104 - regression_loss: 0.0973 - classification_loss: 0.0131
451/500 [==========================>...] - ETA: 22s - loss: 0.1106 - regression_loss: 0.0974 - classification_loss: 0.0132
452/500 [==========================>...] - ETA: 22s - loss: 0.1104 - regression_loss: 0.0973 - classification_loss: 0.0132
453/500 [==========================>...] - ETA: 21s - loss: 0.1105 - regression_loss: 0.0973 - classification_loss: 0.0131
454/500 [==========================>...] - ETA: 21s - loss: 0.1104 - regression_loss: 0.0972 - classification_loss: 0.0131
455/500 [==========================>...] - ETA: 20s - loss: 0.1103 - regression_loss: 0.0972 - classification_loss: 0.0131
456/500 [==========================>...] - ETA: 20s - loss: 0.1103 - regression_loss: 0.0972 - classification_loss: 0.0131
457/500 [==========================>...] - ETA: 20s - loss: 0.1101 - regression_loss: 0.0971 - classification_loss: 0.0131
458/500 [==========================>...] - ETA: 19s - loss: 0.1100 - regression_loss: 0.0969 - classification_loss: 0.0130
459/500 [==========================>...] - ETA: 19s - loss: 0.1099 - regression_loss: 0.0968 - classification_loss: 0.0130
460/500 [==========================>...] - ETA: 18s - loss: 0.1101 - regression_loss: 0.0970 - classification_loss: 0.0131
461/500 [==========================>...] - ETA: 18s - loss: 0.1099 - regression_loss: 0.0969 - classification_loss: 0.0131
462/500 [==========================>...] - ETA: 17s - loss: 0.1101 - regression_loss: 0.0971 - classification_loss: 0.0131
463/500 [==========================>...] - ETA: 17s - loss: 0.1102 - regression_loss: 0.0972 - classification_loss: 0.0130
464/500 [==========================>...] - ETA: 16s - loss: 0.1106 - regression_loss: 0.0975 - classification_loss: 0.0131
465/500 [==========================>...] - ETA: 16s - loss: 0.1106 - regression_loss: 0.0975 - classification_loss: 0.0131
466/500 [==========================>...] - ETA: 15s - loss: 0.1107 - regression_loss: 0.0976 - classification_loss: 0.0130
467/500 [===========================>..] - ETA: 15s - loss: 0.1106 - regression_loss: 0.0976 - classification_loss: 0.0130
468/500 [===========================>..] - ETA: 14s - loss: 0.1106 - regression_loss: 0.0976 - classification_loss: 0.0130
469/500 [===========================>..] - ETA: 14s - loss: 0.1104 - regression_loss: 0.0974 - classification_loss: 0.0130
470/500 [===========================>..] - ETA: 13s - loss: 0.1107 - regression_loss: 0.0977 - classification_loss: 0.0130
471/500 [===========================>..] - ETA: 13s - loss: 0.1110 - regression_loss: 0.0980 - classification_loss: 0.0131
472/500 [===========================>..] - ETA: 13s - loss: 0.1109 - regression_loss: 0.0978 - classification_loss: 0.0130
473/500 [===========================>..] - ETA: 12s - loss: 0.1107 - regression_loss: 0.0977 - classification_loss: 0.0130
474/500 [===========================>..] - ETA: 12s - loss: 0.1106 - regression_loss: 0.0976 - classification_loss: 0.0130
475/500 [===========================>..] - ETA: 11s - loss: 0.1107 - regression_loss: 0.0977 - classification_loss: 0.0130
476/500 [===========================>..] - ETA: 11s - loss: 0.1104 - regression_loss: 0.0975 - classification_loss: 0.0130
477/500 [===========================>..] - ETA: 10s - loss: 0.1103 - regression_loss: 0.0974 - classification_loss: 0.0130
478/500 [===========================>..] - ETA: 10s - loss: 0.1104 - regression_loss: 0.0974 - classification_loss: 0.0130
479/500 [===========================>..] - ETA: 9s - loss: 0.1111 - regression_loss: 0.0981 - classification_loss: 0.0130 
480/500 [===========================>..] - ETA: 9s - loss: 0.1113 - regression_loss: 0.0983 - classification_loss: 0.0130
481/500 [===========================>..] - ETA: 8s - loss: 0.1112 - regression_loss: 0.0983 - classification_loss: 0.0130
482/500 [===========================>..] - ETA: 8s - loss: 0.1112 - regression_loss: 0.0983 - classification_loss: 0.0130
483/500 [===========================>..] - ETA: 7s - loss: 0.1111 - regression_loss: 0.0982 - classification_loss: 0.0129
484/500 [============================>.] - ETA: 7s - loss: 0.1110 - regression_loss: 0.0980 - classification_loss: 0.0129
485/500 [============================>.] - ETA: 6s - loss: 0.1111 - regression_loss: 0.0982 - classification_loss: 0.0130
486/500 [============================>.] - ETA: 6s - loss: 0.1113 - regression_loss: 0.0983 - classification_loss: 0.0130
487/500 [============================>.] - ETA: 6s - loss: 0.1111 - regression_loss: 0.0982 - classification_loss: 0.0129
488/500 [============================>.] - ETA: 5s - loss: 0.1112 - regression_loss: 0.0983 - classification_loss: 0.0130
489/500 [============================>.] - ETA: 5s - loss: 0.1111 - regression_loss: 0.0982 - classification_loss: 0.0129
490/500 [============================>.] - ETA: 4s - loss: 0.1110 - regression_loss: 0.0981 - classification_loss: 0.0129
491/500 [============================>.] - ETA: 4s - loss: 0.1113 - regression_loss: 0.0983 - classification_loss: 0.0130
492/500 [============================>.] - ETA: 3s - loss: 0.1112 - regression_loss: 0.0982 - classification_loss: 0.0129
493/500 [============================>.] - ETA: 3s - loss: 0.1111 - regression_loss: 0.0982 - classification_loss: 0.0129
494/500 [============================>.] - ETA: 2s - loss: 0.1109 - regression_loss: 0.0980 - classification_loss: 0.0129
495/500 [============================>.] - ETA: 2s - loss: 0.1109 - regression_loss: 0.0980 - classification_loss: 0.0129
496/500 [============================>.] - ETA: 1s - loss: 0.1107 - regression_loss: 0.0978 - classification_loss: 0.0129
497/500 [============================>.] - ETA: 1s - loss: 0.1107 - regression_loss: 0.0978 - classification_loss: 0.0129
498/500 [============================>.] - ETA: 0s - loss: 0.1106 - regression_loss: 0.0977 - classification_loss: 0.0129
499/500 [============================>.] - ETA: 0s - loss: 0.1107 - regression_loss: 0.0978 - classification_loss: 0.0129
500/500 [==============================] - 233s 465ms/step - loss: 0.1106 - regression_loss: 0.0977 - classification_loss: 0.0129
44 instances of class building with average precision: 0.8137
mAP: 0.8137

Epoch 00004: saving model to ./snapshots/resnet50_csv_04.h5
Epoch 5/8

  1/500 [..............................] - ETA: 3:50 - loss: 0.0390 - regression_loss: 0.0364 - classification_loss: 0.0027
  2/500 [..............................] - ETA: 3:51 - loss: 0.1009 - regression_loss: 0.0946 - classification_loss: 0.0063
  3/500 [..............................] - ETA: 3:50 - loss: 0.0824 - regression_loss: 0.0759 - classification_loss: 0.0065
  4/500 [..............................] - ETA: 3:49 - loss: 0.0695 - regression_loss: 0.0638 - classification_loss: 0.0056
  5/500 [..............................] - ETA: 3:49 - loss: 0.0953 - regression_loss: 0.0853 - classification_loss: 0.0100
  6/500 [..............................] - ETA: 3:48 - loss: 0.1080 - regression_loss: 0.0952 - classification_loss: 0.0128
  7/500 [..............................] - ETA: 3:48 - loss: 0.0982 - regression_loss: 0.0866 - classification_loss: 0.0116
  8/500 [..............................] - ETA: 3:47 - loss: 0.0880 - regression_loss: 0.0776 - classification_loss: 0.0105
  9/500 [..............................] - ETA: 3:47 - loss: 0.0903 - regression_loss: 0.0800 - classification_loss: 0.0103
 10/500 [..............................] - ETA: 3:46 - loss: 0.0870 - regression_loss: 0.0771 - classification_loss: 0.0099
 11/500 [..............................] - ETA: 3:46 - loss: 0.0826 - regression_loss: 0.0733 - classification_loss: 0.0093
 12/500 [..............................] - ETA: 3:45 - loss: 0.0813 - regression_loss: 0.0721 - classification_loss: 0.0091
 13/500 [..............................] - ETA: 3:45 - loss: 0.0828 - regression_loss: 0.0737 - classification_loss: 0.0091
 14/500 [..............................] - ETA: 3:44 - loss: 0.0904 - regression_loss: 0.0800 - classification_loss: 0.0104
 15/500 [..............................] - ETA: 3:44 - loss: 0.0885 - regression_loss: 0.0786 - classification_loss: 0.0099
 16/500 [..............................] - ETA: 3:43 - loss: 0.0859 - regression_loss: 0.0764 - classification_loss: 0.0095
 17/500 [>.............................] - ETA: 3:43 - loss: 0.0869 - regression_loss: 0.0777 - classification_loss: 0.0093
 18/500 [>.............................] - ETA: 3:42 - loss: 0.0846 - regression_loss: 0.0757 - classification_loss: 0.0089
 19/500 [>.............................] - ETA: 3:42 - loss: 0.0886 - regression_loss: 0.0797 - classification_loss: 0.0089
 20/500 [>.............................] - ETA: 3:42 - loss: 0.0927 - regression_loss: 0.0829 - classification_loss: 0.0098
 21/500 [>.............................] - ETA: 3:41 - loss: 0.0932 - regression_loss: 0.0835 - classification_loss: 0.0097
 22/500 [>.............................] - ETA: 3:41 - loss: 0.0937 - regression_loss: 0.0843 - classification_loss: 0.0094
 23/500 [>.............................] - ETA: 3:41 - loss: 0.0972 - regression_loss: 0.0871 - classification_loss: 0.0101
 24/500 [>.............................] - ETA: 3:40 - loss: 0.0958 - regression_loss: 0.0859 - classification_loss: 0.0099
 25/500 [>.............................] - ETA: 3:40 - loss: 0.0947 - regression_loss: 0.0849 - classification_loss: 0.0097
 26/500 [>.............................] - ETA: 3:40 - loss: 0.0990 - regression_loss: 0.0885 - classification_loss: 0.0105
 27/500 [>.............................] - ETA: 3:40 - loss: 0.0964 - regression_loss: 0.0860 - classification_loss: 0.0104
 28/500 [>.............................] - ETA: 3:39 - loss: 0.0962 - regression_loss: 0.0859 - classification_loss: 0.0103
 29/500 [>.............................] - ETA: 3:39 - loss: 0.0944 - regression_loss: 0.0844 - classification_loss: 0.0100
 30/500 [>.............................] - ETA: 3:39 - loss: 0.0947 - regression_loss: 0.0849 - classification_loss: 0.0098
 31/500 [>.............................] - ETA: 3:38 - loss: 0.0956 - regression_loss: 0.0859 - classification_loss: 0.0097
 32/500 [>.............................] - ETA: 3:38 - loss: 0.0937 - regression_loss: 0.0842 - classification_loss: 0.0095
 33/500 [>.............................] - ETA: 3:37 - loss: 0.0941 - regression_loss: 0.0847 - classification_loss: 0.0095
 34/500 [=>............................] - ETA: 3:37 - loss: 0.0975 - regression_loss: 0.0873 - classification_loss: 0.0101
 35/500 [=>............................] - ETA: 3:36 - loss: 0.0994 - regression_loss: 0.0894 - classification_loss: 0.0100
 36/500 [=>............................] - ETA: 3:36 - loss: 0.0977 - regression_loss: 0.0878 - classification_loss: 0.0099
 37/500 [=>............................] - ETA: 3:35 - loss: 0.0967 - regression_loss: 0.0870 - classification_loss: 0.0097
 38/500 [=>............................] - ETA: 3:35 - loss: 0.0991 - regression_loss: 0.0889 - classification_loss: 0.0102
 39/500 [=>............................] - ETA: 3:34 - loss: 0.0983 - regression_loss: 0.0883 - classification_loss: 0.0100
 40/500 [=>............................] - ETA: 3:34 - loss: 0.1000 - regression_loss: 0.0900 - classification_loss: 0.0100
 41/500 [=>............................] - ETA: 3:33 - loss: 0.1007 - regression_loss: 0.0907 - classification_loss: 0.0100
 42/500 [=>............................] - ETA: 3:33 - loss: 0.1030 - regression_loss: 0.0926 - classification_loss: 0.0105
 43/500 [=>............................] - ETA: 3:32 - loss: 0.1011 - regression_loss: 0.0908 - classification_loss: 0.0103
 44/500 [=>............................] - ETA: 3:32 - loss: 0.1007 - regression_loss: 0.0905 - classification_loss: 0.0101
 45/500 [=>............................] - ETA: 3:31 - loss: 0.1021 - regression_loss: 0.0921 - classification_loss: 0.0101
 46/500 [=>............................] - ETA: 3:31 - loss: 0.1028 - regression_loss: 0.0927 - classification_loss: 0.0100
 47/500 [=>............................] - ETA: 3:30 - loss: 0.1047 - regression_loss: 0.0943 - classification_loss: 0.0104
 48/500 [=>............................] - ETA: 3:30 - loss: 0.1034 - regression_loss: 0.0931 - classification_loss: 0.0103
 49/500 [=>............................] - ETA: 3:29 - loss: 0.1018 - regression_loss: 0.0917 - classification_loss: 0.0101
 50/500 [==>...........................] - ETA: 3:29 - loss: 0.1032 - regression_loss: 0.0932 - classification_loss: 0.0100
 51/500 [==>...........................] - ETA: 3:28 - loss: 0.1041 - regression_loss: 0.0941 - classification_loss: 0.0100
 52/500 [==>...........................] - ETA: 3:28 - loss: 0.1046 - regression_loss: 0.0948 - classification_loss: 0.0098
 53/500 [==>...........................] - ETA: 3:27 - loss: 0.1042 - regression_loss: 0.0944 - classification_loss: 0.0097
 54/500 [==>...........................] - ETA: 3:27 - loss: 0.1073 - regression_loss: 0.0971 - classification_loss: 0.0101
 55/500 [==>...........................] - ETA: 3:26 - loss: 0.1055 - regression_loss: 0.0955 - classification_loss: 0.0100
 56/500 [==>...........................] - ETA: 3:26 - loss: 0.1039 - regression_loss: 0.0940 - classification_loss: 0.0099
 57/500 [==>...........................] - ETA: 3:26 - loss: 0.1040 - regression_loss: 0.0942 - classification_loss: 0.0098
 58/500 [==>...........................] - ETA: 3:25 - loss: 0.1029 - regression_loss: 0.0932 - classification_loss: 0.0097
 59/500 [==>...........................] - ETA: 3:25 - loss: 0.1039 - regression_loss: 0.0939 - classification_loss: 0.0100
 60/500 [==>...........................] - ETA: 3:24 - loss: 0.1044 - regression_loss: 0.0944 - classification_loss: 0.0099
 61/500 [==>...........................] - ETA: 3:24 - loss: 0.1033 - regression_loss: 0.0935 - classification_loss: 0.0098
 62/500 [==>...........................] - ETA: 3:23 - loss: 0.1023 - regression_loss: 0.0926 - classification_loss: 0.0097
 63/500 [==>...........................] - ETA: 3:23 - loss: 0.1030 - regression_loss: 0.0933 - classification_loss: 0.0097
 64/500 [==>...........................] - ETA: 3:22 - loss: 0.1029 - regression_loss: 0.0932 - classification_loss: 0.0097
 65/500 [==>...........................] - ETA: 3:22 - loss: 0.1044 - regression_loss: 0.0945 - classification_loss: 0.0099
 66/500 [==>...........................] - ETA: 3:21 - loss: 0.1032 - regression_loss: 0.0933 - classification_loss: 0.0098
 67/500 [===>..........................] - ETA: 3:21 - loss: 0.1030 - regression_loss: 0.0932 - classification_loss: 0.0098
 68/500 [===>..........................] - ETA: 3:20 - loss: 0.1019 - regression_loss: 0.0921 - classification_loss: 0.0097
 69/500 [===>..........................] - ETA: 3:20 - loss: 0.1030 - regression_loss: 0.0930 - classification_loss: 0.0100
 70/500 [===>..........................] - ETA: 3:19 - loss: 0.1020 - regression_loss: 0.0921 - classification_loss: 0.0099
 71/500 [===>..........................] - ETA: 3:19 - loss: 0.1025 - regression_loss: 0.0926 - classification_loss: 0.0099
 72/500 [===>..........................] - ETA: 3:18 - loss: 0.1017 - regression_loss: 0.0918 - classification_loss: 0.0098
 73/500 [===>..........................] - ETA: 3:18 - loss: 0.1028 - regression_loss: 0.0928 - classification_loss: 0.0100
 74/500 [===>..........................] - ETA: 3:18 - loss: 0.1024 - regression_loss: 0.0924 - classification_loss: 0.0100
 75/500 [===>..........................] - ETA: 3:17 - loss: 0.1027 - regression_loss: 0.0928 - classification_loss: 0.0099
 76/500 [===>..........................] - ETA: 3:17 - loss: 0.1025 - regression_loss: 0.0926 - classification_loss: 0.0098
 77/500 [===>..........................] - ETA: 3:16 - loss: 0.1017 - regression_loss: 0.0920 - classification_loss: 0.0097
 78/500 [===>..........................] - ETA: 3:16 - loss: 0.1030 - regression_loss: 0.0931 - classification_loss: 0.0099
 79/500 [===>..........................] - ETA: 3:15 - loss: 0.1026 - regression_loss: 0.0927 - classification_loss: 0.0099
 80/500 [===>..........................] - ETA: 3:15 - loss: 0.1032 - regression_loss: 0.0934 - classification_loss: 0.0099
 81/500 [===>..........................] - ETA: 3:14 - loss: 0.1032 - regression_loss: 0.0934 - classification_loss: 0.0098
 82/500 [===>..........................] - ETA: 3:14 - loss: 0.1029 - regression_loss: 0.0931 - classification_loss: 0.0097
 83/500 [===>..........................] - ETA: 3:13 - loss: 0.1027 - regression_loss: 0.0931 - classification_loss: 0.0097
 84/500 [====>.........................] - ETA: 3:13 - loss: 0.1028 - regression_loss: 0.0931 - classification_loss: 0.0096
 85/500 [====>.........................] - ETA: 3:12 - loss: 0.1038 - regression_loss: 0.0939 - classification_loss: 0.0099
 86/500 [====>.........................] - ETA: 3:12 - loss: 0.1038 - regression_loss: 0.0939 - classification_loss: 0.0098
 87/500 [====>.........................] - ETA: 3:11 - loss: 0.1029 - regression_loss: 0.0932 - classification_loss: 0.0098
 88/500 [====>.........................] - ETA: 3:11 - loss: 0.1024 - regression_loss: 0.0927 - classification_loss: 0.0097
 89/500 [====>.........................] - ETA: 3:10 - loss: 0.1038 - regression_loss: 0.0939 - classification_loss: 0.0099
 90/500 [====>.........................] - ETA: 3:10 - loss: 0.1033 - regression_loss: 0.0934 - classification_loss: 0.0099
 91/500 [====>.........................] - ETA: 3:10 - loss: 0.1026 - regression_loss: 0.0928 - classification_loss: 0.0098
 92/500 [====>.........................] - ETA: 3:09 - loss: 0.1037 - regression_loss: 0.0937 - classification_loss: 0.0100
 93/500 [====>.........................] - ETA: 3:09 - loss: 0.1031 - regression_loss: 0.0931 - classification_loss: 0.0100
 94/500 [====>.........................] - ETA: 3:08 - loss: 0.1033 - regression_loss: 0.0933 - classification_loss: 0.0100
 95/500 [====>.........................] - ETA: 3:08 - loss: 0.1032 - regression_loss: 0.0933 - classification_loss: 0.0099
 96/500 [====>.........................] - ETA: 3:07 - loss: 0.1028 - regression_loss: 0.0930 - classification_loss: 0.0099
 97/500 [====>.........................] - ETA: 3:07 - loss: 0.1041 - regression_loss: 0.0940 - classification_loss: 0.0101
 98/500 [====>.........................] - ETA: 3:06 - loss: 0.1033 - regression_loss: 0.0933 - classification_loss: 0.0100
 99/500 [====>.........................] - ETA: 3:06 - loss: 0.1031 - regression_loss: 0.0931 - classification_loss: 0.0100
100/500 [=====>........................] - ETA: 3:05 - loss: 0.1024 - regression_loss: 0.0925 - classification_loss: 0.0099
101/500 [=====>........................] - ETA: 3:05 - loss: 0.1031 - regression_loss: 0.0931 - classification_loss: 0.0101
102/500 [=====>........................] - ETA: 3:04 - loss: 0.1033 - regression_loss: 0.0932 - classification_loss: 0.0100
103/500 [=====>........................] - ETA: 3:04 - loss: 0.1026 - regression_loss: 0.0926 - classification_loss: 0.0100
104/500 [=====>........................] - ETA: 3:03 - loss: 0.1032 - regression_loss: 0.0933 - classification_loss: 0.0099
105/500 [=====>........................] - ETA: 3:03 - loss: 0.1024 - regression_loss: 0.0925 - classification_loss: 0.0099
106/500 [=====>........................] - ETA: 3:03 - loss: 0.1040 - regression_loss: 0.0941 - classification_loss: 0.0098
107/500 [=====>........................] - ETA: 3:02 - loss: 0.1030 - regression_loss: 0.0933 - classification_loss: 0.0097
108/500 [=====>........................] - ETA: 3:02 - loss: 0.1030 - regression_loss: 0.0932 - classification_loss: 0.0097
109/500 [=====>........................] - ETA: 3:01 - loss: 0.1035 - regression_loss: 0.0936 - classification_loss: 0.0099
110/500 [=====>........................] - ETA: 3:01 - loss: 0.1031 - regression_loss: 0.0932 - classification_loss: 0.0098
111/500 [=====>........................] - ETA: 3:00 - loss: 0.1031 - regression_loss: 0.0933 - classification_loss: 0.0098
112/500 [=====>........................] - ETA: 3:00 - loss: 0.1037 - regression_loss: 0.0937 - classification_loss: 0.0100
113/500 [=====>........................] - ETA: 2:59 - loss: 0.1033 - regression_loss: 0.0933 - classification_loss: 0.0099
114/500 [=====>........................] - ETA: 2:59 - loss: 0.1030 - regression_loss: 0.0931 - classification_loss: 0.0099
115/500 [=====>........................] - ETA: 2:58 - loss: 0.1023 - regression_loss: 0.0925 - classification_loss: 0.0098
116/500 [=====>........................] - ETA: 2:58 - loss: 0.1029 - regression_loss: 0.0930 - classification_loss: 0.0100
117/500 [======>.......................] - ETA: 2:58 - loss: 0.1022 - regression_loss: 0.0923 - classification_loss: 0.0099
118/500 [======>.......................] - ETA: 2:57 - loss: 0.1017 - regression_loss: 0.0918 - classification_loss: 0.0099
119/500 [======>.......................] - ETA: 2:57 - loss: 0.1016 - regression_loss: 0.0918 - classification_loss: 0.0098
120/500 [======>.......................] - ETA: 2:56 - loss: 0.1017 - regression_loss: 0.0919 - classification_loss: 0.0098
121/500 [======>.......................] - ETA: 2:56 - loss: 0.1011 - regression_loss: 0.0913 - classification_loss: 0.0098
122/500 [======>.......................] - ETA: 2:55 - loss: 0.1007 - regression_loss: 0.0909 - classification_loss: 0.0097
123/500 [======>.......................] - ETA: 2:55 - loss: 0.1007 - regression_loss: 0.0909 - classification_loss: 0.0097
124/500 [======>.......................] - ETA: 2:54 - loss: 0.1013 - regression_loss: 0.0915 - classification_loss: 0.0099
125/500 [======>.......................] - ETA: 2:54 - loss: 0.1006 - regression_loss: 0.0908 - classification_loss: 0.0098
126/500 [======>.......................] - ETA: 2:53 - loss: 0.1010 - regression_loss: 0.0911 - classification_loss: 0.0099
127/500 [======>.......................] - ETA: 2:53 - loss: 0.1005 - regression_loss: 0.0906 - classification_loss: 0.0099
128/500 [======>.......................] - ETA: 2:52 - loss: 0.0999 - regression_loss: 0.0901 - classification_loss: 0.0098
129/500 [======>.......................] - ETA: 2:52 - loss: 0.0998 - regression_loss: 0.0900 - classification_loss: 0.0098
130/500 [======>.......................] - ETA: 2:51 - loss: 0.0993 - regression_loss: 0.0895 - classification_loss: 0.0098
131/500 [======>.......................] - ETA: 2:51 - loss: 0.0989 - regression_loss: 0.0891 - classification_loss: 0.0097
132/500 [======>.......................] - ETA: 2:50 - loss: 0.1002 - regression_loss: 0.0904 - classification_loss: 0.0099
133/500 [======>.......................] - ETA: 2:50 - loss: 0.0997 - regression_loss: 0.0899 - classification_loss: 0.0098
134/500 [=======>......................] - ETA: 2:50 - loss: 0.0993 - regression_loss: 0.0895 - classification_loss: 0.0098
135/500 [=======>......................] - ETA: 2:49 - loss: 0.0992 - regression_loss: 0.0894 - classification_loss: 0.0098
136/500 [=======>......................] - ETA: 2:49 - loss: 0.0993 - regression_loss: 0.0895 - classification_loss: 0.0098
137/500 [=======>......................] - ETA: 2:48 - loss: 0.0990 - regression_loss: 0.0893 - classification_loss: 0.0098
138/500 [=======>......................] - ETA: 2:48 - loss: 0.0996 - regression_loss: 0.0898 - classification_loss: 0.0099
139/500 [=======>......................] - ETA: 2:47 - loss: 0.0996 - regression_loss: 0.0897 - classification_loss: 0.0098
140/500 [=======>......................] - ETA: 2:47 - loss: 0.0994 - regression_loss: 0.0896 - classification_loss: 0.0098
141/500 [=======>......................] - ETA: 2:46 - loss: 0.1000 - regression_loss: 0.0901 - classification_loss: 0.0099
142/500 [=======>......................] - ETA: 2:46 - loss: 0.1000 - regression_loss: 0.0901 - classification_loss: 0.0099
143/500 [=======>......................] - ETA: 2:45 - loss: 0.0996 - regression_loss: 0.0898 - classification_loss: 0.0099
144/500 [=======>......................] - ETA: 2:45 - loss: 0.0994 - regression_loss: 0.0895 - classification_loss: 0.0098
145/500 [=======>......................] - ETA: 2:44 - loss: 0.0991 - regression_loss: 0.0893 - classification_loss: 0.0098
146/500 [=======>......................] - ETA: 2:44 - loss: 0.0987 - regression_loss: 0.0890 - classification_loss: 0.0097
147/500 [=======>......................] - ETA: 2:43 - loss: 0.0996 - regression_loss: 0.0897 - classification_loss: 0.0099
148/500 [=======>......................] - ETA: 2:43 - loss: 0.0990 - regression_loss: 0.0892 - classification_loss: 0.0098
149/500 [=======>......................] - ETA: 2:43 - loss: 0.0990 - regression_loss: 0.0892 - classification_loss: 0.0098
150/500 [========>.....................] - ETA: 2:42 - loss: 0.0984 - regression_loss: 0.0887 - classification_loss: 0.0098
151/500 [========>.....................] - ETA: 2:42 - loss: 0.0981 - regression_loss: 0.0883 - classification_loss: 0.0097
152/500 [========>.....................] - ETA: 2:41 - loss: 0.0983 - regression_loss: 0.0886 - classification_loss: 0.0097
153/500 [========>.....................] - ETA: 2:41 - loss: 0.0988 - regression_loss: 0.0890 - classification_loss: 0.0098
154/500 [========>.....................] - ETA: 2:40 - loss: 0.0984 - regression_loss: 0.0886 - classification_loss: 0.0098
155/500 [========>.....................] - ETA: 2:40 - loss: 0.0984 - regression_loss: 0.0887 - classification_loss: 0.0097
156/500 [========>.....................] - ETA: 2:39 - loss: 0.0983 - regression_loss: 0.0886 - classification_loss: 0.0097
157/500 [========>.....................] - ETA: 2:39 - loss: 0.0979 - regression_loss: 0.0883 - classification_loss: 0.0097
158/500 [========>.....................] - ETA: 2:38 - loss: 0.0976 - regression_loss: 0.0879 - classification_loss: 0.0096
159/500 [========>.....................] - ETA: 2:38 - loss: 0.0982 - regression_loss: 0.0885 - classification_loss: 0.0097
160/500 [========>.....................] - ETA: 2:37 - loss: 0.0979 - regression_loss: 0.0882 - classification_loss: 0.0097
161/500 [========>.....................] - ETA: 2:37 - loss: 0.0975 - regression_loss: 0.0878 - classification_loss: 0.0097
162/500 [========>.....................] - ETA: 2:36 - loss: 0.0972 - regression_loss: 0.0876 - classification_loss: 0.0096
163/500 [========>.....................] - ETA: 2:36 - loss: 0.0972 - regression_loss: 0.0876 - classification_loss: 0.0096
164/500 [========>.....................] - ETA: 2:36 - loss: 0.0976 - regression_loss: 0.0879 - classification_loss: 0.0097
165/500 [========>.....................] - ETA: 2:35 - loss: 0.0975 - regression_loss: 0.0878 - classification_loss: 0.0097
166/500 [========>.....................] - ETA: 2:35 - loss: 0.0975 - regression_loss: 0.0878 - classification_loss: 0.0097
167/500 [=========>....................] - ETA: 2:34 - loss: 0.0982 - regression_loss: 0.0885 - classification_loss: 0.0098
168/500 [=========>....................] - ETA: 2:34 - loss: 0.0977 - regression_loss: 0.0880 - classification_loss: 0.0097
169/500 [=========>....................] - ETA: 2:33 - loss: 0.0977 - regression_loss: 0.0880 - classification_loss: 0.0097
170/500 [=========>....................] - ETA: 2:33 - loss: 0.0978 - regression_loss: 0.0881 - classification_loss: 0.0096
171/500 [=========>....................] - ETA: 2:32 - loss: 0.0978 - regression_loss: 0.0882 - classification_loss: 0.0096
172/500 [=========>....................] - ETA: 2:32 - loss: 0.0975 - regression_loss: 0.0879 - classification_loss: 0.0096
173/500 [=========>....................] - ETA: 2:31 - loss: 0.0975 - regression_loss: 0.0879 - classification_loss: 0.0096
174/500 [=========>....................] - ETA: 2:31 - loss: 0.0980 - regression_loss: 0.0884 - classification_loss: 0.0096
175/500 [=========>....................] - ETA: 2:31 - loss: 0.0981 - regression_loss: 0.0884 - classification_loss: 0.0096
176/500 [=========>....................] - ETA: 2:30 - loss: 0.0978 - regression_loss: 0.0882 - classification_loss: 0.0096
177/500 [=========>....................] - ETA: 2:30 - loss: 0.0974 - regression_loss: 0.0879 - classification_loss: 0.0095
178/500 [=========>....................] - ETA: 2:29 - loss: 0.0971 - regression_loss: 0.0876 - classification_loss: 0.0095
179/500 [=========>....................] - ETA: 2:29 - loss: 0.0973 - regression_loss: 0.0878 - classification_loss: 0.0095
180/500 [=========>....................] - ETA: 2:28 - loss: 0.0979 - regression_loss: 0.0883 - classification_loss: 0.0096
181/500 [=========>....................] - ETA: 2:28 - loss: 0.0974 - regression_loss: 0.0879 - classification_loss: 0.0096
182/500 [=========>....................] - ETA: 2:27 - loss: 0.0975 - regression_loss: 0.0879 - classification_loss: 0.0096
183/500 [=========>....................] - ETA: 2:27 - loss: 0.0974 - regression_loss: 0.0879 - classification_loss: 0.0095
184/500 [==========>...................] - ETA: 2:26 - loss: 0.0979 - regression_loss: 0.0883 - classification_loss: 0.0096
185/500 [==========>...................] - ETA: 2:26 - loss: 0.0977 - regression_loss: 0.0881 - classification_loss: 0.0096
186/500 [==========>...................] - ETA: 2:25 - loss: 0.0973 - regression_loss: 0.0877 - classification_loss: 0.0096
187/500 [==========>...................] - ETA: 2:25 - loss: 0.0969 - regression_loss: 0.0874 - classification_loss: 0.0095
188/500 [==========>...................] - ETA: 2:24 - loss: 0.0965 - regression_loss: 0.0870 - classification_loss: 0.0095
189/500 [==========>...................] - ETA: 2:24 - loss: 0.0969 - regression_loss: 0.0873 - classification_loss: 0.0096
190/500 [==========>...................] - ETA: 2:24 - loss: 0.0968 - regression_loss: 0.0872 - classification_loss: 0.0096
191/500 [==========>...................] - ETA: 2:23 - loss: 0.0968 - regression_loss: 0.0873 - classification_loss: 0.0096
192/500 [==========>...................] - ETA: 2:23 - loss: 0.0967 - regression_loss: 0.0871 - classification_loss: 0.0096
193/500 [==========>...................] - ETA: 2:22 - loss: 0.0970 - regression_loss: 0.0874 - classification_loss: 0.0096
194/500 [==========>...................] - ETA: 2:22 - loss: 0.0968 - regression_loss: 0.0872 - classification_loss: 0.0096
195/500 [==========>...................] - ETA: 2:21 - loss: 0.0965 - regression_loss: 0.0869 - classification_loss: 0.0096
196/500 [==========>...................] - ETA: 2:21 - loss: 0.0965 - regression_loss: 0.0870 - classification_loss: 0.0095
197/500 [==========>...................] - ETA: 2:20 - loss: 0.0972 - regression_loss: 0.0876 - classification_loss: 0.0096
198/500 [==========>...................] - ETA: 2:20 - loss: 0.0968 - regression_loss: 0.0872 - classification_loss: 0.0096
199/500 [==========>...................] - ETA: 2:19 - loss: 0.0965 - regression_loss: 0.0869 - classification_loss: 0.0096
200/500 [===========>..................] - ETA: 2:19 - loss: 0.0963 - regression_loss: 0.0868 - classification_loss: 0.0096
201/500 [===========>..................] - ETA: 2:18 - loss: 0.0967 - regression_loss: 0.0870 - classification_loss: 0.0096
202/500 [===========>..................] - ETA: 2:18 - loss: 0.0963 - regression_loss: 0.0867 - classification_loss: 0.0096
203/500 [===========>..................] - ETA: 2:18 - loss: 0.0964 - regression_loss: 0.0868 - classification_loss: 0.0096
204/500 [===========>..................] - ETA: 2:17 - loss: 0.0962 - regression_loss: 0.0866 - classification_loss: 0.0096
205/500 [===========>..................] - ETA: 2:17 - loss: 0.0960 - regression_loss: 0.0865 - classification_loss: 0.0095
206/500 [===========>..................] - ETA: 2:16 - loss: 0.0957 - regression_loss: 0.0861 - classification_loss: 0.0095
207/500 [===========>..................] - ETA: 2:16 - loss: 0.0954 - regression_loss: 0.0859 - classification_loss: 0.0095
208/500 [===========>..................] - ETA: 2:15 - loss: 0.0952 - regression_loss: 0.0858 - classification_loss: 0.0095
209/500 [===========>..................] - ETA: 2:15 - loss: 0.0955 - regression_loss: 0.0860 - classification_loss: 0.0095
210/500 [===========>..................] - ETA: 2:14 - loss: 0.0955 - regression_loss: 0.0859 - classification_loss: 0.0095
211/500 [===========>..................] - ETA: 2:14 - loss: 0.0954 - regression_loss: 0.0859 - classification_loss: 0.0095
212/500 [===========>..................] - ETA: 2:13 - loss: 0.0957 - regression_loss: 0.0861 - classification_loss: 0.0096
213/500 [===========>..................] - ETA: 2:13 - loss: 0.0953 - regression_loss: 0.0857 - classification_loss: 0.0095
214/500 [===========>..................] - ETA: 2:12 - loss: 0.0951 - regression_loss: 0.0856 - classification_loss: 0.0095
215/500 [===========>..................] - ETA: 2:12 - loss: 0.0948 - regression_loss: 0.0853 - classification_loss: 0.0095
216/500 [===========>..................] - ETA: 2:12 - loss: 0.0944 - regression_loss: 0.0849 - classification_loss: 0.0095
217/500 [============>.................] - ETA: 2:11 - loss: 0.0949 - regression_loss: 0.0854 - classification_loss: 0.0095
218/500 [============>.................] - ETA: 2:11 - loss: 0.0948 - regression_loss: 0.0853 - classification_loss: 0.0095
219/500 [============>.................] - ETA: 2:10 - loss: 0.0945 - regression_loss: 0.0850 - classification_loss: 0.0095
220/500 [============>.................] - ETA: 2:10 - loss: 0.0949 - regression_loss: 0.0854 - classification_loss: 0.0095
221/500 [============>.................] - ETA: 2:09 - loss: 0.0953 - regression_loss: 0.0858 - classification_loss: 0.0096
222/500 [============>.................] - ETA: 2:09 - loss: 0.0951 - regression_loss: 0.0856 - classification_loss: 0.0095
223/500 [============>.................] - ETA: 2:08 - loss: 0.0952 - regression_loss: 0.0856 - classification_loss: 0.0095
224/500 [============>.................] - ETA: 2:08 - loss: 0.0953 - regression_loss: 0.0857 - classification_loss: 0.0095
225/500 [============>.................] - ETA: 2:07 - loss: 0.0952 - regression_loss: 0.0857 - classification_loss: 0.0095
226/500 [============>.................] - ETA: 2:07 - loss: 0.0957 - regression_loss: 0.0862 - classification_loss: 0.0095
227/500 [============>.................] - ETA: 2:06 - loss: 0.0955 - regression_loss: 0.0861 - classification_loss: 0.0094
228/500 [============>.................] - ETA: 2:06 - loss: 0.0954 - regression_loss: 0.0860 - classification_loss: 0.0094
229/500 [============>.................] - ETA: 2:06 - loss: 0.0957 - regression_loss: 0.0863 - classification_loss: 0.0094
230/500 [============>.................] - ETA: 2:05 - loss: 0.0962 - regression_loss: 0.0868 - classification_loss: 0.0095
231/500 [============>.................] - ETA: 2:05 - loss: 0.0962 - regression_loss: 0.0868 - classification_loss: 0.0095
232/500 [============>.................] - ETA: 2:04 - loss: 0.0961 - regression_loss: 0.0867 - classification_loss: 0.0094
233/500 [============>.................] - ETA: 2:04 - loss: 0.0958 - regression_loss: 0.0864 - classification_loss: 0.0094
234/500 [=============>................] - ETA: 2:03 - loss: 0.0962 - regression_loss: 0.0869 - classification_loss: 0.0094
235/500 [=============>................] - ETA: 2:03 - loss: 0.0967 - regression_loss: 0.0872 - classification_loss: 0.0095
236/500 [=============>................] - ETA: 2:02 - loss: 0.0963 - regression_loss: 0.0869 - classification_loss: 0.0094
237/500 [=============>................] - ETA: 2:02 - loss: 0.0963 - regression_loss: 0.0869 - classification_loss: 0.0094
238/500 [=============>................] - ETA: 2:01 - loss: 0.0964 - regression_loss: 0.0870 - classification_loss: 0.0094
239/500 [=============>................] - ETA: 2:01 - loss: 0.0969 - regression_loss: 0.0875 - classification_loss: 0.0094
240/500 [=============>................] - ETA: 2:00 - loss: 0.0972 - regression_loss: 0.0877 - classification_loss: 0.0095
241/500 [=============>................] - ETA: 2:00 - loss: 0.0969 - regression_loss: 0.0874 - classification_loss: 0.0095
242/500 [=============>................] - ETA: 1:59 - loss: 0.0966 - regression_loss: 0.0872 - classification_loss: 0.0094
243/500 [=============>................] - ETA: 1:59 - loss: 0.0969 - regression_loss: 0.0875 - classification_loss: 0.0094
244/500 [=============>................] - ETA: 1:59 - loss: 0.0968 - regression_loss: 0.0874 - classification_loss: 0.0094
245/500 [=============>................] - ETA: 1:58 - loss: 0.0978 - regression_loss: 0.0883 - classification_loss: 0.0095
246/500 [=============>................] - ETA: 1:58 - loss: 0.0979 - regression_loss: 0.0884 - classification_loss: 0.0095
247/500 [=============>................] - ETA: 1:57 - loss: 0.0976 - regression_loss: 0.0882 - classification_loss: 0.0094
248/500 [=============>................] - ETA: 1:57 - loss: 0.0977 - regression_loss: 0.0882 - classification_loss: 0.0094
249/500 [=============>................] - ETA: 1:56 - loss: 0.0975 - regression_loss: 0.0881 - classification_loss: 0.0094
250/500 [==============>...............] - ETA: 1:56 - loss: 0.0978 - regression_loss: 0.0884 - classification_loss: 0.0095
251/500 [==============>...............] - ETA: 1:55 - loss: 0.0977 - regression_loss: 0.0882 - classification_loss: 0.0094
252/500 [==============>...............] - ETA: 1:55 - loss: 0.0977 - regression_loss: 0.0883 - classification_loss: 0.0094
253/500 [==============>...............] - ETA: 1:54 - loss: 0.0975 - regression_loss: 0.0881 - classification_loss: 0.0094
254/500 [==============>...............] - ETA: 1:54 - loss: 0.0978 - regression_loss: 0.0883 - classification_loss: 0.0095
255/500 [==============>...............] - ETA: 1:53 - loss: 0.0980 - regression_loss: 0.0885 - classification_loss: 0.0094
256/500 [==============>...............] - ETA: 1:53 - loss: 0.0984 - regression_loss: 0.0889 - classification_loss: 0.0095
257/500 [==============>...............] - ETA: 1:53 - loss: 0.0982 - regression_loss: 0.0887 - classification_loss: 0.0095
258/500 [==============>...............] - ETA: 1:52 - loss: 0.0980 - regression_loss: 0.0885 - classification_loss: 0.0095
259/500 [==============>...............] - ETA: 1:52 - loss: 0.0978 - regression_loss: 0.0883 - classification_loss: 0.0094
260/500 [==============>...............] - ETA: 1:51 - loss: 0.0980 - regression_loss: 0.0886 - classification_loss: 0.0094
261/500 [==============>...............] - ETA: 1:51 - loss: 0.0985 - regression_loss: 0.0890 - classification_loss: 0.0095
262/500 [==============>...............] - ETA: 1:50 - loss: 0.0986 - regression_loss: 0.0891 - classification_loss: 0.0095
263/500 [==============>...............] - ETA: 1:50 - loss: 0.0984 - regression_loss: 0.0889 - classification_loss: 0.0095
264/500 [==============>...............] - ETA: 1:49 - loss: 0.0981 - regression_loss: 0.0886 - classification_loss: 0.0094
265/500 [==============>...............] - ETA: 1:49 - loss: 0.0980 - regression_loss: 0.0885 - classification_loss: 0.0094
266/500 [==============>...............] - ETA: 1:48 - loss: 0.0978 - regression_loss: 0.0884 - classification_loss: 0.0094
267/500 [===============>..............] - ETA: 1:48 - loss: 0.0980 - regression_loss: 0.0886 - classification_loss: 0.0095
268/500 [===============>..............] - ETA: 1:47 - loss: 0.0978 - regression_loss: 0.0883 - classification_loss: 0.0094
269/500 [===============>..............] - ETA: 1:47 - loss: 0.0978 - regression_loss: 0.0883 - classification_loss: 0.0094
270/500 [===============>..............] - ETA: 1:46 - loss: 0.0975 - regression_loss: 0.0881 - classification_loss: 0.0094
271/500 [===============>..............] - ETA: 1:46 - loss: 0.0979 - regression_loss: 0.0884 - classification_loss: 0.0095
272/500 [===============>..............] - ETA: 1:46 - loss: 0.0980 - regression_loss: 0.0886 - classification_loss: 0.0094
273/500 [===============>..............] - ETA: 1:45 - loss: 0.0979 - regression_loss: 0.0885 - classification_loss: 0.0094
274/500 [===============>..............] - ETA: 1:45 - loss: 0.0979 - regression_loss: 0.0885 - classification_loss: 0.0094
275/500 [===============>..............] - ETA: 1:44 - loss: 0.0976 - regression_loss: 0.0882 - classification_loss: 0.0094
276/500 [===============>..............] - ETA: 1:44 - loss: 0.0973 - regression_loss: 0.0879 - classification_loss: 0.0094
277/500 [===============>..............] - ETA: 1:43 - loss: 0.0976 - regression_loss: 0.0882 - classification_loss: 0.0094
278/500 [===============>..............] - ETA: 1:43 - loss: 0.0974 - regression_loss: 0.0880 - classification_loss: 0.0094
279/500 [===============>..............] - ETA: 1:42 - loss: 0.0975 - regression_loss: 0.0881 - classification_loss: 0.0094
280/500 [===============>..............] - ETA: 1:42 - loss: 0.0974 - regression_loss: 0.0880 - classification_loss: 0.0094
281/500 [===============>..............] - ETA: 1:41 - loss: 0.0978 - regression_loss: 0.0884 - classification_loss: 0.0094
282/500 [===============>..............] - ETA: 1:41 - loss: 0.0975 - regression_loss: 0.0881 - classification_loss: 0.0094
283/500 [===============>..............] - ETA: 1:40 - loss: 0.0976 - regression_loss: 0.0882 - classification_loss: 0.0094
284/500 [================>.............] - ETA: 1:40 - loss: 0.0975 - regression_loss: 0.0881 - classification_loss: 0.0094
285/500 [================>.............] - ETA: 1:39 - loss: 0.0974 - regression_loss: 0.0881 - classification_loss: 0.0093
286/500 [================>.............] - ETA: 1:39 - loss: 0.0972 - regression_loss: 0.0878 - classification_loss: 0.0093
287/500 [================>.............] - ETA: 1:39 - loss: 0.0971 - regression_loss: 0.0878 - classification_loss: 0.0093
288/500 [================>.............] - ETA: 1:38 - loss: 0.0975 - regression_loss: 0.0881 - classification_loss: 0.0094
289/500 [================>.............] - ETA: 1:38 - loss: 0.0981 - regression_loss: 0.0887 - classification_loss: 0.0093
290/500 [================>.............] - ETA: 1:37 - loss: 0.0983 - regression_loss: 0.0890 - classification_loss: 0.0093
291/500 [================>.............] - ETA: 1:37 - loss: 0.0982 - regression_loss: 0.0889 - classification_loss: 0.0093
292/500 [================>.............] - ETA: 1:36 - loss: 0.0980 - regression_loss: 0.0887 - classification_loss: 0.0093
293/500 [================>.............] - ETA: 1:36 - loss: 0.0980 - regression_loss: 0.0887 - classification_loss: 0.0093
294/500 [================>.............] - ETA: 1:35 - loss: 0.0981 - regression_loss: 0.0888 - classification_loss: 0.0093
295/500 [================>.............] - ETA: 1:35 - loss: 0.0985 - regression_loss: 0.0892 - classification_loss: 0.0093
296/500 [================>.............] - ETA: 1:34 - loss: 0.0983 - regression_loss: 0.0890 - classification_loss: 0.0093
297/500 [================>.............] - ETA: 1:34 - loss: 0.0984 - regression_loss: 0.0891 - classification_loss: 0.0093
298/500 [================>.............] - ETA: 1:33 - loss: 0.0983 - regression_loss: 0.0890 - classification_loss: 0.0093
299/500 [================>.............] - ETA: 1:33 - loss: 0.0982 - regression_loss: 0.0889 - classification_loss: 0.0093
300/500 [=================>............] - ETA: 1:32 - loss: 0.0984 - regression_loss: 0.0891 - classification_loss: 0.0093
301/500 [=================>............] - ETA: 1:32 - loss: 0.0981 - regression_loss: 0.0889 - classification_loss: 0.0093
302/500 [=================>............] - ETA: 1:32 - loss: 0.0981 - regression_loss: 0.0889 - classification_loss: 0.0093
303/500 [=================>............] - ETA: 1:31 - loss: 0.0985 - regression_loss: 0.0892 - classification_loss: 0.0093
304/500 [=================>............] - ETA: 1:31 - loss: 0.0984 - regression_loss: 0.0891 - classification_loss: 0.0093
305/500 [=================>............] - ETA: 1:30 - loss: 0.0985 - regression_loss: 0.0892 - classification_loss: 0.0093
306/500 [=================>............] - ETA: 1:30 - loss: 0.0986 - regression_loss: 0.0893 - classification_loss: 0.0093
307/500 [=================>............] - ETA: 1:29 - loss: 0.0984 - regression_loss: 0.0891 - classification_loss: 0.0093
308/500 [=================>............] - ETA: 1:29 - loss: 0.0983 - regression_loss: 0.0890 - classification_loss: 0.0092
309/500 [=================>............] - ETA: 1:28 - loss: 0.0986 - regression_loss: 0.0893 - classification_loss: 0.0093
310/500 [=================>............] - ETA: 1:28 - loss: 0.0987 - regression_loss: 0.0894 - classification_loss: 0.0093
311/500 [=================>............] - ETA: 1:27 - loss: 0.0985 - regression_loss: 0.0893 - classification_loss: 0.0093
312/500 [=================>............] - ETA: 1:27 - loss: 0.0986 - regression_loss: 0.0893 - classification_loss: 0.0092
313/500 [=================>............] - ETA: 1:26 - loss: 0.0988 - regression_loss: 0.0895 - classification_loss: 0.0093
314/500 [=================>............] - ETA: 1:26 - loss: 0.0985 - regression_loss: 0.0892 - classification_loss: 0.0093
315/500 [=================>............] - ETA: 1:26 - loss: 0.0983 - regression_loss: 0.0890 - classification_loss: 0.0093
316/500 [=================>............] - ETA: 1:25 - loss: 0.0981 - regression_loss: 0.0889 - classification_loss: 0.0092
317/500 [==================>...........] - ETA: 1:25 - loss: 0.0981 - regression_loss: 0.0888 - classification_loss: 0.0092
318/500 [==================>...........] - ETA: 1:24 - loss: 0.0983 - regression_loss: 0.0890 - classification_loss: 0.0093
319/500 [==================>...........] - ETA: 1:24 - loss: 0.0982 - regression_loss: 0.0890 - classification_loss: 0.0093
320/500 [==================>...........] - ETA: 1:23 - loss: 0.0981 - regression_loss: 0.0888 - classification_loss: 0.0092
321/500 [==================>...........] - ETA: 1:23 - loss: 0.0978 - regression_loss: 0.0886 - classification_loss: 0.0092
322/500 [==================>...........] - ETA: 1:22 - loss: 0.0980 - regression_loss: 0.0887 - classification_loss: 0.0093
323/500 [==================>...........] - ETA: 1:22 - loss: 0.0977 - regression_loss: 0.0885 - classification_loss: 0.0092
324/500 [==================>...........] - ETA: 1:21 - loss: 0.0977 - regression_loss: 0.0885 - classification_loss: 0.0092
325/500 [==================>...........] - ETA: 1:21 - loss: 0.0977 - regression_loss: 0.0885 - classification_loss: 0.0092
326/500 [==================>...........] - ETA: 1:20 - loss: 0.0975 - regression_loss: 0.0883 - classification_loss: 0.0092
327/500 [==================>...........] - ETA: 1:20 - loss: 0.0974 - regression_loss: 0.0882 - classification_loss: 0.0092
328/500 [==================>...........] - ETA: 1:19 - loss: 0.0977 - regression_loss: 0.0885 - classification_loss: 0.0092
329/500 [==================>...........] - ETA: 1:19 - loss: 0.0978 - regression_loss: 0.0885 - classification_loss: 0.0092
330/500 [==================>...........] - ETA: 1:19 - loss: 0.0978 - regression_loss: 0.0886 - classification_loss: 0.0092
331/500 [==================>...........] - ETA: 1:18 - loss: 0.0977 - regression_loss: 0.0885 - classification_loss: 0.0092
332/500 [==================>...........] - ETA: 1:18 - loss: 0.0977 - regression_loss: 0.0885 - classification_loss: 0.0092
333/500 [==================>...........] - ETA: 1:17 - loss: 0.0979 - regression_loss: 0.0887 - classification_loss: 0.0092
334/500 [===================>..........] - ETA: 1:17 - loss: 0.0976 - regression_loss: 0.0884 - classification_loss: 0.0092
335/500 [===================>..........] - ETA: 1:16 - loss: 0.0975 - regression_loss: 0.0883 - classification_loss: 0.0092
336/500 [===================>..........] - ETA: 1:16 - loss: 0.0975 - regression_loss: 0.0883 - classification_loss: 0.0092
337/500 [===================>..........] - ETA: 1:15 - loss: 0.0975 - regression_loss: 0.0883 - classification_loss: 0.0092
338/500 [===================>..........] - ETA: 1:15 - loss: 0.0973 - regression_loss: 0.0881 - classification_loss: 0.0091
339/500 [===================>..........] - ETA: 1:14 - loss: 0.0971 - regression_loss: 0.0880 - classification_loss: 0.0091
340/500 [===================>..........] - ETA: 1:14 - loss: 0.0973 - regression_loss: 0.0881 - classification_loss: 0.0092
341/500 [===================>..........] - ETA: 1:13 - loss: 0.0975 - regression_loss: 0.0883 - classification_loss: 0.0092
342/500 [===================>..........] - ETA: 1:13 - loss: 0.0972 - regression_loss: 0.0880 - classification_loss: 0.0092
343/500 [===================>..........] - ETA: 1:12 - loss: 0.0970 - regression_loss: 0.0878 - classification_loss: 0.0092
344/500 [===================>..........] - ETA: 1:12 - loss: 0.0970 - regression_loss: 0.0878 - classification_loss: 0.0092
345/500 [===================>..........] - ETA: 1:12 - loss: 0.0971 - regression_loss: 0.0880 - classification_loss: 0.0092
346/500 [===================>..........] - ETA: 1:11 - loss: 0.0969 - regression_loss: 0.0878 - classification_loss: 0.0091
347/500 [===================>..........] - ETA: 1:11 - loss: 0.0968 - regression_loss: 0.0877 - classification_loss: 0.0091
348/500 [===================>..........] - ETA: 1:10 - loss: 0.0967 - regression_loss: 0.0876 - classification_loss: 0.0091
349/500 [===================>..........] - ETA: 1:10 - loss: 0.0966 - regression_loss: 0.0875 - classification_loss: 0.0091
350/500 [====================>.........] - ETA: 1:09 - loss: 0.0967 - regression_loss: 0.0876 - classification_loss: 0.0091
351/500 [====================>.........] - ETA: 1:09 - loss: 0.0967 - regression_loss: 0.0876 - classification_loss: 0.0091
352/500 [====================>.........] - ETA: 1:08 - loss: 0.0965 - regression_loss: 0.0874 - classification_loss: 0.0091
353/500 [====================>.........] - ETA: 1:08 - loss: 0.0963 - regression_loss: 0.0872 - classification_loss: 0.0091
354/500 [====================>.........] - ETA: 1:07 - loss: 0.0961 - regression_loss: 0.0870 - classification_loss: 0.0091
355/500 [====================>.........] - ETA: 1:07 - loss: 0.0962 - regression_loss: 0.0871 - classification_loss: 0.0091
356/500 [====================>.........] - ETA: 1:06 - loss: 0.0962 - regression_loss: 0.0871 - classification_loss: 0.0091
357/500 [====================>.........] - ETA: 1:06 - loss: 0.0962 - regression_loss: 0.0871 - classification_loss: 0.0091
358/500 [====================>.........] - ETA: 1:06 - loss: 0.0962 - regression_loss: 0.0871 - classification_loss: 0.0091
359/500 [====================>.........] - ETA: 1:05 - loss: 0.0960 - regression_loss: 0.0869 - classification_loss: 0.0091
360/500 [====================>.........] - ETA: 1:05 - loss: 0.0961 - regression_loss: 0.0870 - classification_loss: 0.0091
361/500 [====================>.........] - ETA: 1:04 - loss: 0.0959 - regression_loss: 0.0868 - classification_loss: 0.0091
362/500 [====================>.........] - ETA: 1:04 - loss: 0.0956 - regression_loss: 0.0866 - classification_loss: 0.0091
363/500 [====================>.........] - ETA: 1:03 - loss: 0.0954 - regression_loss: 0.0864 - classification_loss: 0.0090
364/500 [====================>.........] - ETA: 1:03 - loss: 0.0955 - regression_loss: 0.0864 - classification_loss: 0.0091
365/500 [====================>.........] - ETA: 1:02 - loss: 0.0957 - regression_loss: 0.0866 - classification_loss: 0.0091
366/500 [====================>.........] - ETA: 1:02 - loss: 0.0955 - regression_loss: 0.0864 - classification_loss: 0.0090
367/500 [=====================>........] - ETA: 1:01 - loss: 0.0953 - regression_loss: 0.0863 - classification_loss: 0.0090
368/500 [=====================>........] - ETA: 1:01 - loss: 0.0954 - regression_loss: 0.0864 - classification_loss: 0.0090
369/500 [=====================>........] - ETA: 1:00 - loss: 0.0954 - regression_loss: 0.0864 - classification_loss: 0.0090
370/500 [=====================>........] - ETA: 1:00 - loss: 0.0957 - regression_loss: 0.0866 - classification_loss: 0.0091
371/500 [=====================>........] - ETA: 59s - loss: 0.0956 - regression_loss: 0.0866 - classification_loss: 0.0091 
372/500 [=====================>........] - ETA: 59s - loss: 0.0958 - regression_loss: 0.0867 - classification_loss: 0.0091
373/500 [=====================>........] - ETA: 59s - loss: 0.0956 - regression_loss: 0.0865 - classification_loss: 0.0091
374/500 [=====================>........] - ETA: 58s - loss: 0.0954 - regression_loss: 0.0864 - classification_loss: 0.0091
375/500 [=====================>........] - ETA: 58s - loss: 0.0953 - regression_loss: 0.0863 - classification_loss: 0.0090
376/500 [=====================>........] - ETA: 57s - loss: 0.0951 - regression_loss: 0.0861 - classification_loss: 0.0090
377/500 [=====================>........] - ETA: 57s - loss: 0.0953 - regression_loss: 0.0862 - classification_loss: 0.0090
378/500 [=====================>........] - ETA: 56s - loss: 0.0952 - regression_loss: 0.0862 - classification_loss: 0.0090
379/500 [=====================>........] - ETA: 56s - loss: 0.0953 - regression_loss: 0.0863 - classification_loss: 0.0090
380/500 [=====================>........] - ETA: 55s - loss: 0.0955 - regression_loss: 0.0864 - classification_loss: 0.0090
381/500 [=====================>........] - ETA: 55s - loss: 0.0954 - regression_loss: 0.0864 - classification_loss: 0.0090
382/500 [=====================>........] - ETA: 54s - loss: 0.0956 - regression_loss: 0.0866 - classification_loss: 0.0091
383/500 [=====================>........] - ETA: 54s - loss: 0.0955 - regression_loss: 0.0865 - classification_loss: 0.0090
384/500 [======================>.......] - ETA: 53s - loss: 0.0954 - regression_loss: 0.0863 - classification_loss: 0.0090
385/500 [======================>.......] - ETA: 53s - loss: 0.0953 - regression_loss: 0.0863 - classification_loss: 0.0090
386/500 [======================>.......] - ETA: 53s - loss: 0.0954 - regression_loss: 0.0864 - classification_loss: 0.0090
387/500 [======================>.......] - ETA: 52s - loss: 0.0952 - regression_loss: 0.0862 - classification_loss: 0.0090
388/500 [======================>.......] - ETA: 52s - loss: 0.0952 - regression_loss: 0.0862 - classification_loss: 0.0090
389/500 [======================>.......] - ETA: 51s - loss: 0.0951 - regression_loss: 0.0860 - classification_loss: 0.0090
390/500 [======================>.......] - ETA: 51s - loss: 0.0949 - regression_loss: 0.0859 - classification_loss: 0.0090
391/500 [======================>.......] - ETA: 50s - loss: 0.0948 - regression_loss: 0.0858 - classification_loss: 0.0090
392/500 [======================>.......] - ETA: 50s - loss: 0.0951 - regression_loss: 0.0860 - classification_loss: 0.0090
393/500 [======================>.......] - ETA: 49s - loss: 0.0948 - regression_loss: 0.0858 - classification_loss: 0.0090
394/500 [======================>.......] - ETA: 49s - loss: 0.0948 - regression_loss: 0.0858 - classification_loss: 0.0090
395/500 [======================>.......] - ETA: 48s - loss: 0.0946 - regression_loss: 0.0857 - classification_loss: 0.0090
396/500 [======================>.......] - ETA: 48s - loss: 0.0945 - regression_loss: 0.0855 - classification_loss: 0.0090
397/500 [======================>.......] - ETA: 47s - loss: 0.0943 - regression_loss: 0.0853 - classification_loss: 0.0090
398/500 [======================>.......] - ETA: 47s - loss: 0.0941 - regression_loss: 0.0852 - classification_loss: 0.0089
399/500 [======================>.......] - ETA: 46s - loss: 0.0943 - regression_loss: 0.0854 - classification_loss: 0.0090
400/500 [=======================>......] - ETA: 46s - loss: 0.0943 - regression_loss: 0.0854 - classification_loss: 0.0090
401/500 [=======================>......] - ETA: 46s - loss: 0.0941 - regression_loss: 0.0852 - classification_loss: 0.0089
402/500 [=======================>......] - ETA: 45s - loss: 0.0942 - regression_loss: 0.0852 - classification_loss: 0.0090
403/500 [=======================>......] - ETA: 45s - loss: 0.0940 - regression_loss: 0.0851 - classification_loss: 0.0090
404/500 [=======================>......] - ETA: 44s - loss: 0.0939 - regression_loss: 0.0849 - classification_loss: 0.0090
405/500 [=======================>......] - ETA: 44s - loss: 0.0939 - regression_loss: 0.0849 - classification_loss: 0.0090
406/500 [=======================>......] - ETA: 43s - loss: 0.0938 - regression_loss: 0.0848 - classification_loss: 0.0089
407/500 [=======================>......] - ETA: 43s - loss: 0.0936 - regression_loss: 0.0847 - classification_loss: 0.0089
408/500 [=======================>......] - ETA: 42s - loss: 0.0938 - regression_loss: 0.0848 - classification_loss: 0.0090
409/500 [=======================>......] - ETA: 42s - loss: 0.0937 - regression_loss: 0.0848 - classification_loss: 0.0090
410/500 [=======================>......] - ETA: 41s - loss: 0.0936 - regression_loss: 0.0846 - classification_loss: 0.0089
411/500 [=======================>......] - ETA: 41s - loss: 0.0935 - regression_loss: 0.0845 - classification_loss: 0.0089
412/500 [=======================>......] - ETA: 40s - loss: 0.0934 - regression_loss: 0.0845 - classification_loss: 0.0089
413/500 [=======================>......] - ETA: 40s - loss: 0.0936 - regression_loss: 0.0846 - classification_loss: 0.0090
414/500 [=======================>......] - ETA: 39s - loss: 0.0935 - regression_loss: 0.0846 - classification_loss: 0.0089
415/500 [=======================>......] - ETA: 39s - loss: 0.0934 - regression_loss: 0.0844 - classification_loss: 0.0089
416/500 [=======================>......] - ETA: 39s - loss: 0.0932 - regression_loss: 0.0843 - classification_loss: 0.0089
417/500 [========================>.....] - ETA: 38s - loss: 0.0933 - regression_loss: 0.0844 - classification_loss: 0.0090
418/500 [========================>.....] - ETA: 38s - loss: 0.0931 - regression_loss: 0.0842 - classification_loss: 0.0089
419/500 [========================>.....] - ETA: 37s - loss: 0.0930 - regression_loss: 0.0840 - classification_loss: 0.0089
420/500 [========================>.....] - ETA: 37s - loss: 0.0930 - regression_loss: 0.0841 - classification_loss: 0.0089
421/500 [========================>.....] - ETA: 36s - loss: 0.0928 - regression_loss: 0.0839 - classification_loss: 0.0089
422/500 [========================>.....] - ETA: 36s - loss: 0.0927 - regression_loss: 0.0838 - classification_loss: 0.0089
423/500 [========================>.....] - ETA: 35s - loss: 0.0927 - regression_loss: 0.0838 - classification_loss: 0.0089
424/500 [========================>.....] - ETA: 35s - loss: 0.0928 - regression_loss: 0.0839 - classification_loss: 0.0089
425/500 [========================>.....] - ETA: 34s - loss: 0.0927 - regression_loss: 0.0838 - classification_loss: 0.0089
426/500 [========================>.....] - ETA: 34s - loss: 0.0926 - regression_loss: 0.0837 - classification_loss: 0.0089
427/500 [========================>.....] - ETA: 33s - loss: 0.0927 - regression_loss: 0.0838 - classification_loss: 0.0089
428/500 [========================>.....] - ETA: 33s - loss: 0.0927 - regression_loss: 0.0837 - classification_loss: 0.0089
429/500 [========================>.....] - ETA: 33s - loss: 0.0926 - regression_loss: 0.0837 - classification_loss: 0.0089
430/500 [========================>.....] - ETA: 32s - loss: 0.0924 - regression_loss: 0.0835 - classification_loss: 0.0089
431/500 [========================>.....] - ETA: 32s - loss: 0.0926 - regression_loss: 0.0837 - classification_loss: 0.0089
432/500 [========================>.....] - ETA: 31s - loss: 0.0925 - regression_loss: 0.0836 - classification_loss: 0.0089
433/500 [========================>.....] - ETA: 31s - loss: 0.0924 - regression_loss: 0.0835 - classification_loss: 0.0089
434/500 [=========================>....] - ETA: 30s - loss: 0.0922 - regression_loss: 0.0834 - classification_loss: 0.0089
435/500 [=========================>....] - ETA: 30s - loss: 0.0922 - regression_loss: 0.0833 - classification_loss: 0.0089
436/500 [=========================>....] - ETA: 29s - loss: 0.0924 - regression_loss: 0.0835 - classification_loss: 0.0089
437/500 [=========================>....] - ETA: 29s - loss: 0.0922 - regression_loss: 0.0834 - classification_loss: 0.0089
438/500 [=========================>....] - ETA: 28s - loss: 0.0922 - regression_loss: 0.0833 - classification_loss: 0.0089
439/500 [=========================>....] - ETA: 28s - loss: 0.0924 - regression_loss: 0.0836 - classification_loss: 0.0089
440/500 [=========================>....] - ETA: 27s - loss: 0.0924 - regression_loss: 0.0835 - classification_loss: 0.0088
441/500 [=========================>....] - ETA: 27s - loss: 0.0923 - regression_loss: 0.0835 - classification_loss: 0.0088
442/500 [=========================>....] - ETA: 26s - loss: 0.0922 - regression_loss: 0.0833 - classification_loss: 0.0088
443/500 [=========================>....] - ETA: 26s - loss: 0.0922 - regression_loss: 0.0834 - classification_loss: 0.0088
444/500 [=========================>....] - ETA: 26s - loss: 0.0922 - regression_loss: 0.0834 - classification_loss: 0.0088
445/500 [=========================>....] - ETA: 25s - loss: 0.0925 - regression_loss: 0.0837 - classification_loss: 0.0088
446/500 [=========================>....] - ETA: 25s - loss: 0.0928 - regression_loss: 0.0839 - classification_loss: 0.0089
447/500 [=========================>....] - ETA: 24s - loss: 0.0928 - regression_loss: 0.0840 - classification_loss: 0.0089
448/500 [=========================>....] - ETA: 24s - loss: 0.0931 - regression_loss: 0.0842 - classification_loss: 0.0088
449/500 [=========================>....] - ETA: 23s - loss: 0.0931 - regression_loss: 0.0842 - classification_loss: 0.0088
450/500 [==========================>...] - ETA: 23s - loss: 0.0929 - regression_loss: 0.0841 - classification_loss: 0.0088
451/500 [==========================>...] - ETA: 22s - loss: 0.0930 - regression_loss: 0.0842 - classification_loss: 0.0088
452/500 [==========================>...] - ETA: 22s - loss: 0.0934 - regression_loss: 0.0845 - classification_loss: 0.0089
453/500 [==========================>...] - ETA: 21s - loss: 0.0932 - regression_loss: 0.0844 - classification_loss: 0.0088
454/500 [==========================>...] - ETA: 21s - loss: 0.0932 - regression_loss: 0.0843 - classification_loss: 0.0088
455/500 [==========================>...] - ETA: 20s - loss: 0.0931 - regression_loss: 0.0843 - classification_loss: 0.0088
456/500 [==========================>...] - ETA: 20s - loss: 0.0933 - regression_loss: 0.0845 - classification_loss: 0.0088
457/500 [==========================>...] - ETA: 19s - loss: 0.0932 - regression_loss: 0.0844 - classification_loss: 0.0088
458/500 [==========================>...] - ETA: 19s - loss: 0.0933 - regression_loss: 0.0845 - classification_loss: 0.0088
459/500 [==========================>...] - ETA: 19s - loss: 0.0933 - regression_loss: 0.0845 - classification_loss: 0.0088
460/500 [==========================>...] - ETA: 18s - loss: 0.0932 - regression_loss: 0.0844 - classification_loss: 0.0088
461/500 [==========================>...] - ETA: 18s - loss: 0.0932 - regression_loss: 0.0844 - classification_loss: 0.0088
462/500 [==========================>...] - ETA: 17s - loss: 0.0931 - regression_loss: 0.0843 - classification_loss: 0.0088
463/500 [==========================>...] - ETA: 17s - loss: 0.0930 - regression_loss: 0.0842 - classification_loss: 0.0088
464/500 [==========================>...] - ETA: 16s - loss: 0.0930 - regression_loss: 0.0842 - classification_loss: 0.0088
465/500 [==========================>...] - ETA: 16s - loss: 0.0929 - regression_loss: 0.0841 - classification_loss: 0.0088
466/500 [==========================>...] - ETA: 15s - loss: 0.0929 - regression_loss: 0.0841 - classification_loss: 0.0088
467/500 [===========================>..] - ETA: 15s - loss: 0.0929 - regression_loss: 0.0841 - classification_loss: 0.0088
468/500 [===========================>..] - ETA: 14s - loss: 0.0927 - regression_loss: 0.0840 - classification_loss: 0.0088
469/500 [===========================>..] - ETA: 14s - loss: 0.0926 - regression_loss: 0.0838 - classification_loss: 0.0088
470/500 [===========================>..] - ETA: 13s - loss: 0.0924 - regression_loss: 0.0837 - classification_loss: 0.0088
471/500 [===========================>..] - ETA: 13s - loss: 0.0925 - regression_loss: 0.0837 - classification_loss: 0.0088
472/500 [===========================>..] - ETA: 13s - loss: 0.0924 - regression_loss: 0.0836 - classification_loss: 0.0087
473/500 [===========================>..] - ETA: 12s - loss: 0.0926 - regression_loss: 0.0838 - classification_loss: 0.0088
474/500 [===========================>..] - ETA: 12s - loss: 0.0927 - regression_loss: 0.0839 - classification_loss: 0.0088
475/500 [===========================>..] - ETA: 11s - loss: 0.0926 - regression_loss: 0.0838 - classification_loss: 0.0087
476/500 [===========================>..] - ETA: 11s - loss: 0.0926 - regression_loss: 0.0838 - classification_loss: 0.0087
477/500 [===========================>..] - ETA: 10s - loss: 0.0925 - regression_loss: 0.0838 - classification_loss: 0.0087
478/500 [===========================>..] - ETA: 10s - loss: 0.0923 - regression_loss: 0.0836 - classification_loss: 0.0087
479/500 [===========================>..] - ETA: 9s - loss: 0.0924 - regression_loss: 0.0837 - classification_loss: 0.0087 
480/500 [===========================>..] - ETA: 9s - loss: 0.0923 - regression_loss: 0.0836 - classification_loss: 0.0087
481/500 [===========================>..] - ETA: 8s - loss: 0.0924 - regression_loss: 0.0836 - classification_loss: 0.0088
482/500 [===========================>..] - ETA: 8s - loss: 0.0924 - regression_loss: 0.0836 - classification_loss: 0.0087
483/500 [===========================>..] - ETA: 7s - loss: 0.0925 - regression_loss: 0.0838 - classification_loss: 0.0087
484/500 [============================>.] - ETA: 7s - loss: 0.0924 - regression_loss: 0.0837 - classification_loss: 0.0087
485/500 [============================>.] - ETA: 6s - loss: 0.0923 - regression_loss: 0.0836 - classification_loss: 0.0087
486/500 [============================>.] - ETA: 6s - loss: 0.0924 - regression_loss: 0.0837 - classification_loss: 0.0087
487/500 [============================>.] - ETA: 6s - loss: 0.0923 - regression_loss: 0.0835 - classification_loss: 0.0087
488/500 [============================>.] - ETA: 5s - loss: 0.0921 - regression_loss: 0.0834 - classification_loss: 0.0087
489/500 [============================>.] - ETA: 5s - loss: 0.0921 - regression_loss: 0.0834 - classification_loss: 0.0087
490/500 [============================>.] - ETA: 4s - loss: 0.0920 - regression_loss: 0.0833 - classification_loss: 0.0087
491/500 [============================>.] - ETA: 4s - loss: 0.0918 - regression_loss: 0.0831 - classification_loss: 0.0087
492/500 [============================>.] - ETA: 3s - loss: 0.0917 - regression_loss: 0.0831 - classification_loss: 0.0087
493/500 [============================>.] - ETA: 3s - loss: 0.0918 - regression_loss: 0.0832 - classification_loss: 0.0087
494/500 [============================>.] - ETA: 2s - loss: 0.0919 - regression_loss: 0.0832 - classification_loss: 0.0087
495/500 [============================>.] - ETA: 2s - loss: 0.0918 - regression_loss: 0.0831 - classification_loss: 0.0087
496/500 [============================>.] - ETA: 1s - loss: 0.0919 - regression_loss: 0.0832 - classification_loss: 0.0087
497/500 [============================>.] - ETA: 1s - loss: 0.0919 - regression_loss: 0.0832 - classification_loss: 0.0087
498/500 [============================>.] - ETA: 0s - loss: 0.0919 - regression_loss: 0.0833 - classification_loss: 0.0087
499/500 [============================>.] - ETA: 0s - loss: 0.0918 - regression_loss: 0.0831 - classification_loss: 0.0087
500/500 [==============================] - 232s 465ms/step - loss: 0.0917 - regression_loss: 0.0831 - classification_loss: 0.0087
44 instances of class building with average precision: 0.8129
mAP: 0.8129

Epoch 00005: saving model to ./snapshots/resnet50_csv_05.h5
Epoch 6/8

  1/500 [..............................] - ETA: 3:50 - loss: 0.0194 - regression_loss: 0.0151 - classification_loss: 0.0042
  2/500 [..............................] - ETA: 3:49 - loss: 0.0813 - regression_loss: 0.0759 - classification_loss: 0.0055
  3/500 [..............................] - ETA: 3:49 - loss: 0.1103 - regression_loss: 0.0999 - classification_loss: 0.0104
  4/500 [..............................] - ETA: 3:49 - loss: 0.0975 - regression_loss: 0.0889 - classification_loss: 0.0085
  5/500 [..............................] - ETA: 3:48 - loss: 0.0854 - regression_loss: 0.0782 - classification_loss: 0.0072
  6/500 [..............................] - ETA: 3:48 - loss: 0.0898 - regression_loss: 0.0829 - classification_loss: 0.0069
  7/500 [..............................] - ETA: 3:48 - loss: 0.1068 - regression_loss: 0.0976 - classification_loss: 0.0092
  8/500 [..............................] - ETA: 3:47 - loss: 0.0965 - regression_loss: 0.0882 - classification_loss: 0.0083
  9/500 [..............................] - ETA: 3:47 - loss: 0.0906 - regression_loss: 0.0829 - classification_loss: 0.0077
 10/500 [..............................] - ETA: 3:46 - loss: 0.0910 - regression_loss: 0.0836 - classification_loss: 0.0074
 11/500 [..............................] - ETA: 3:46 - loss: 0.0890 - regression_loss: 0.0818 - classification_loss: 0.0072
 12/500 [..............................] - ETA: 3:46 - loss: 0.0949 - regression_loss: 0.0865 - classification_loss: 0.0084
 13/500 [..............................] - ETA: 3:45 - loss: 0.0935 - regression_loss: 0.0855 - classification_loss: 0.0080
 14/500 [..............................] - ETA: 3:45 - loss: 0.0943 - regression_loss: 0.0864 - classification_loss: 0.0079
 15/500 [..............................] - ETA: 3:44 - loss: 0.0966 - regression_loss: 0.0891 - classification_loss: 0.0075
 16/500 [..............................] - ETA: 3:44 - loss: 0.0958 - regression_loss: 0.0887 - classification_loss: 0.0071
 17/500 [>.............................] - ETA: 3:43 - loss: 0.0977 - regression_loss: 0.0900 - classification_loss: 0.0078
 18/500 [>.............................] - ETA: 3:43 - loss: 0.0962 - regression_loss: 0.0886 - classification_loss: 0.0076
 19/500 [>.............................] - ETA: 3:42 - loss: 0.0960 - regression_loss: 0.0885 - classification_loss: 0.0075
 20/500 [>.............................] - ETA: 3:42 - loss: 0.0925 - regression_loss: 0.0852 - classification_loss: 0.0073
 21/500 [>.............................] - ETA: 3:42 - loss: 0.0907 - regression_loss: 0.0837 - classification_loss: 0.0070
 22/500 [>.............................] - ETA: 3:41 - loss: 0.0886 - regression_loss: 0.0817 - classification_loss: 0.0069
 23/500 [>.............................] - ETA: 3:41 - loss: 0.0898 - regression_loss: 0.0824 - classification_loss: 0.0074
 24/500 [>.............................] - ETA: 3:40 - loss: 0.0890 - regression_loss: 0.0818 - classification_loss: 0.0072
 25/500 [>.............................] - ETA: 3:40 - loss: 0.0883 - regression_loss: 0.0812 - classification_loss: 0.0071
 26/500 [>.............................] - ETA: 3:40 - loss: 0.0861 - regression_loss: 0.0792 - classification_loss: 0.0070
 27/500 [>.............................] - ETA: 3:39 - loss: 0.0855 - regression_loss: 0.0786 - classification_loss: 0.0069
 28/500 [>.............................] - ETA: 3:39 - loss: 0.0845 - regression_loss: 0.0777 - classification_loss: 0.0068
 29/500 [>.............................] - ETA: 3:38 - loss: 0.0820 - regression_loss: 0.0754 - classification_loss: 0.0066
 30/500 [>.............................] - ETA: 3:38 - loss: 0.0840 - regression_loss: 0.0769 - classification_loss: 0.0071
 31/500 [>.............................] - ETA: 3:37 - loss: 0.0815 - regression_loss: 0.0745 - classification_loss: 0.0069
 32/500 [>.............................] - ETA: 3:37 - loss: 0.0834 - regression_loss: 0.0760 - classification_loss: 0.0074
 33/500 [>.............................] - ETA: 3:36 - loss: 0.0827 - regression_loss: 0.0754 - classification_loss: 0.0073
 34/500 [=>............................] - ETA: 3:36 - loss: 0.0843 - regression_loss: 0.0771 - classification_loss: 0.0072
 35/500 [=>............................] - ETA: 3:35 - loss: 0.0827 - regression_loss: 0.0756 - classification_loss: 0.0071
 36/500 [=>............................] - ETA: 3:35 - loss: 0.0827 - regression_loss: 0.0756 - classification_loss: 0.0071
 37/500 [=>............................] - ETA: 3:34 - loss: 0.0816 - regression_loss: 0.0747 - classification_loss: 0.0069
 38/500 [=>............................] - ETA: 3:34 - loss: 0.0812 - regression_loss: 0.0744 - classification_loss: 0.0069
 39/500 [=>............................] - ETA: 3:33 - loss: 0.0864 - regression_loss: 0.0791 - classification_loss: 0.0073
 40/500 [=>............................] - ETA: 3:33 - loss: 0.0868 - regression_loss: 0.0796 - classification_loss: 0.0072
 41/500 [=>............................] - ETA: 3:33 - loss: 0.0859 - regression_loss: 0.0788 - classification_loss: 0.0071
 42/500 [=>............................] - ETA: 3:32 - loss: 0.0890 - regression_loss: 0.0816 - classification_loss: 0.0074
 43/500 [=>............................] - ETA: 3:32 - loss: 0.0873 - regression_loss: 0.0801 - classification_loss: 0.0073
 44/500 [=>............................] - ETA: 3:31 - loss: 0.0869 - regression_loss: 0.0797 - classification_loss: 0.0072
 45/500 [=>............................] - ETA: 3:31 - loss: 0.0878 - regression_loss: 0.0807 - classification_loss: 0.0072
 46/500 [=>............................] - ETA: 3:31 - loss: 0.0869 - regression_loss: 0.0799 - classification_loss: 0.0071
 47/500 [=>............................] - ETA: 3:30 - loss: 0.0882 - regression_loss: 0.0813 - classification_loss: 0.0070
 48/500 [=>............................] - ETA: 3:30 - loss: 0.0869 - regression_loss: 0.0801 - classification_loss: 0.0069
 49/500 [=>............................] - ETA: 3:29 - loss: 0.0885 - regression_loss: 0.0813 - classification_loss: 0.0071
 50/500 [==>...........................] - ETA: 3:29 - loss: 0.0883 - regression_loss: 0.0812 - classification_loss: 0.0071
 51/500 [==>...........................] - ETA: 3:28 - loss: 0.0869 - regression_loss: 0.0799 - classification_loss: 0.0070
 52/500 [==>...........................] - ETA: 3:28 - loss: 0.0876 - regression_loss: 0.0804 - classification_loss: 0.0072
 53/500 [==>...........................] - ETA: 3:27 - loss: 0.0873 - regression_loss: 0.0801 - classification_loss: 0.0072
 54/500 [==>...........................] - ETA: 3:27 - loss: 0.0869 - regression_loss: 0.0798 - classification_loss: 0.0071
 55/500 [==>...........................] - ETA: 3:26 - loss: 0.0886 - regression_loss: 0.0816 - classification_loss: 0.0071
 56/500 [==>...........................] - ETA: 3:26 - loss: 0.0881 - regression_loss: 0.0811 - classification_loss: 0.0070
 57/500 [==>...........................] - ETA: 3:25 - loss: 0.0877 - regression_loss: 0.0808 - classification_loss: 0.0069
 58/500 [==>...........................] - ETA: 3:25 - loss: 0.0871 - regression_loss: 0.0803 - classification_loss: 0.0068
 59/500 [==>...........................] - ETA: 3:24 - loss: 0.0886 - regression_loss: 0.0818 - classification_loss: 0.0068
 60/500 [==>...........................] - ETA: 3:24 - loss: 0.0907 - regression_loss: 0.0836 - classification_loss: 0.0071
 61/500 [==>...........................] - ETA: 3:24 - loss: 0.0910 - regression_loss: 0.0840 - classification_loss: 0.0070
 62/500 [==>...........................] - ETA: 3:23 - loss: 0.0899 - regression_loss: 0.0829 - classification_loss: 0.0069
 63/500 [==>...........................] - ETA: 3:23 - loss: 0.0895 - regression_loss: 0.0826 - classification_loss: 0.0069
 64/500 [==>...........................] - ETA: 3:22 - loss: 0.0904 - regression_loss: 0.0833 - classification_loss: 0.0071
 65/500 [==>...........................] - ETA: 3:22 - loss: 0.0910 - regression_loss: 0.0839 - classification_loss: 0.0070
 66/500 [==>...........................] - ETA: 3:21 - loss: 0.0906 - regression_loss: 0.0836 - classification_loss: 0.0070
 67/500 [===>..........................] - ETA: 3:21 - loss: 0.0913 - regression_loss: 0.0844 - classification_loss: 0.0069
 68/500 [===>..........................] - ETA: 3:20 - loss: 0.0920 - regression_loss: 0.0849 - classification_loss: 0.0071
 69/500 [===>..........................] - ETA: 3:20 - loss: 0.0918 - regression_loss: 0.0847 - classification_loss: 0.0071
 70/500 [===>..........................] - ETA: 3:20 - loss: 0.0915 - regression_loss: 0.0845 - classification_loss: 0.0070
 71/500 [===>..........................] - ETA: 3:19 - loss: 0.0907 - regression_loss: 0.0837 - classification_loss: 0.0070
 72/500 [===>..........................] - ETA: 3:19 - loss: 0.0899 - regression_loss: 0.0830 - classification_loss: 0.0069
 73/500 [===>..........................] - ETA: 3:18 - loss: 0.0916 - regression_loss: 0.0846 - classification_loss: 0.0071
 74/500 [===>..........................] - ETA: 3:18 - loss: 0.0917 - regression_loss: 0.0846 - classification_loss: 0.0070
 75/500 [===>..........................] - ETA: 3:17 - loss: 0.0912 - regression_loss: 0.0842 - classification_loss: 0.0070
 76/500 [===>..........................] - ETA: 3:17 - loss: 0.0913 - regression_loss: 0.0844 - classification_loss: 0.0070
 77/500 [===>..........................] - ETA: 3:16 - loss: 0.0919 - regression_loss: 0.0848 - classification_loss: 0.0071
 78/500 [===>..........................] - ETA: 3:16 - loss: 0.0914 - regression_loss: 0.0843 - classification_loss: 0.0071
 79/500 [===>..........................] - ETA: 3:15 - loss: 0.0916 - regression_loss: 0.0846 - classification_loss: 0.0070
 80/500 [===>..........................] - ETA: 3:15 - loss: 0.0906 - regression_loss: 0.0837 - classification_loss: 0.0069
 81/500 [===>..........................] - ETA: 3:14 - loss: 0.0917 - regression_loss: 0.0846 - classification_loss: 0.0071
 82/500 [===>..........................] - ETA: 3:14 - loss: 0.0907 - regression_loss: 0.0837 - classification_loss: 0.0070
 83/500 [===>..........................] - ETA: 3:13 - loss: 0.0901 - regression_loss: 0.0831 - classification_loss: 0.0070
 84/500 [====>.........................] - ETA: 3:13 - loss: 0.0912 - regression_loss: 0.0843 - classification_loss: 0.0069
 85/500 [====>.........................] - ETA: 3:12 - loss: 0.0919 - regression_loss: 0.0850 - classification_loss: 0.0069
 86/500 [====>.........................] - ETA: 3:12 - loss: 0.0919 - regression_loss: 0.0850 - classification_loss: 0.0069
 87/500 [====>.........................] - ETA: 3:11 - loss: 0.0912 - regression_loss: 0.0844 - classification_loss: 0.0068
 88/500 [====>.........................] - ETA: 3:11 - loss: 0.0923 - regression_loss: 0.0853 - classification_loss: 0.0070
 89/500 [====>.........................] - ETA: 3:11 - loss: 0.0924 - regression_loss: 0.0854 - classification_loss: 0.0070
 90/500 [====>.........................] - ETA: 3:10 - loss: 0.0933 - regression_loss: 0.0864 - classification_loss: 0.0069
 91/500 [====>.........................] - ETA: 3:10 - loss: 0.0924 - regression_loss: 0.0855 - classification_loss: 0.0069
 92/500 [====>.........................] - ETA: 3:09 - loss: 0.0923 - regression_loss: 0.0855 - classification_loss: 0.0068
 93/500 [====>.........................] - ETA: 3:09 - loss: 0.0928 - regression_loss: 0.0858 - classification_loss: 0.0070
 94/500 [====>.........................] - ETA: 3:08 - loss: 0.0920 - regression_loss: 0.0851 - classification_loss: 0.0070
 95/500 [====>.........................] - ETA: 3:08 - loss: 0.0912 - regression_loss: 0.0843 - classification_loss: 0.0069
 96/500 [====>.........................] - ETA: 3:07 - loss: 0.0911 - regression_loss: 0.0843 - classification_loss: 0.0069
 97/500 [====>.........................] - ETA: 3:07 - loss: 0.0908 - regression_loss: 0.0839 - classification_loss: 0.0068
 98/500 [====>.........................] - ETA: 3:06 - loss: 0.0922 - regression_loss: 0.0852 - classification_loss: 0.0070
 99/500 [====>.........................] - ETA: 3:06 - loss: 0.0919 - regression_loss: 0.0849 - classification_loss: 0.0069
100/500 [=====>........................] - ETA: 3:05 - loss: 0.0920 - regression_loss: 0.0851 - classification_loss: 0.0069
101/500 [=====>........................] - ETA: 3:05 - loss: 0.0914 - regression_loss: 0.0845 - classification_loss: 0.0069
102/500 [=====>........................] - ETA: 3:05 - loss: 0.0911 - regression_loss: 0.0842 - classification_loss: 0.0069
103/500 [=====>........................] - ETA: 3:04 - loss: 0.0914 - regression_loss: 0.0845 - classification_loss: 0.0068
104/500 [=====>........................] - ETA: 3:04 - loss: 0.0912 - regression_loss: 0.0844 - classification_loss: 0.0068
105/500 [=====>........................] - ETA: 3:03 - loss: 0.0919 - regression_loss: 0.0850 - classification_loss: 0.0069
106/500 [=====>........................] - ETA: 3:03 - loss: 0.0915 - regression_loss: 0.0846 - classification_loss: 0.0069
107/500 [=====>........................] - ETA: 3:02 - loss: 0.0920 - regression_loss: 0.0852 - classification_loss: 0.0068
108/500 [=====>........................] - ETA: 3:02 - loss: 0.0919 - regression_loss: 0.0851 - classification_loss: 0.0068
109/500 [=====>........................] - ETA: 3:01 - loss: 0.0912 - regression_loss: 0.0844 - classification_loss: 0.0068
110/500 [=====>........................] - ETA: 3:01 - loss: 0.0917 - regression_loss: 0.0849 - classification_loss: 0.0069
111/500 [=====>........................] - ETA: 3:00 - loss: 0.0916 - regression_loss: 0.0847 - classification_loss: 0.0069
112/500 [=====>........................] - ETA: 3:00 - loss: 0.0921 - regression_loss: 0.0851 - classification_loss: 0.0070
113/500 [=====>........................] - ETA: 3:00 - loss: 0.0915 - regression_loss: 0.0846 - classification_loss: 0.0069
114/500 [=====>........................] - ETA: 2:59 - loss: 0.0914 - regression_loss: 0.0845 - classification_loss: 0.0069
115/500 [=====>........................] - ETA: 2:59 - loss: 0.0908 - regression_loss: 0.0840 - classification_loss: 0.0069
116/500 [=====>........................] - ETA: 2:58 - loss: 0.0906 - regression_loss: 0.0838 - classification_loss: 0.0069
117/500 [======>.......................] - ETA: 2:58 - loss: 0.0900 - regression_loss: 0.0832 - classification_loss: 0.0068
118/500 [======>.......................] - ETA: 2:57 - loss: 0.0905 - regression_loss: 0.0836 - classification_loss: 0.0070
119/500 [======>.......................] - ETA: 2:57 - loss: 0.0902 - regression_loss: 0.0833 - classification_loss: 0.0069
120/500 [======>.......................] - ETA: 2:56 - loss: 0.0897 - regression_loss: 0.0829 - classification_loss: 0.0069
121/500 [======>.......................] - ETA: 2:56 - loss: 0.0902 - regression_loss: 0.0831 - classification_loss: 0.0070
122/500 [======>.......................] - ETA: 2:55 - loss: 0.0901 - regression_loss: 0.0831 - classification_loss: 0.0070
123/500 [======>.......................] - ETA: 2:55 - loss: 0.0895 - regression_loss: 0.0825 - classification_loss: 0.0070
124/500 [======>.......................] - ETA: 2:55 - loss: 0.0892 - regression_loss: 0.0822 - classification_loss: 0.0069
125/500 [======>.......................] - ETA: 2:54 - loss: 0.0887 - regression_loss: 0.0817 - classification_loss: 0.0069
126/500 [======>.......................] - ETA: 2:54 - loss: 0.0891 - regression_loss: 0.0822 - classification_loss: 0.0069
127/500 [======>.......................] - ETA: 2:53 - loss: 0.0890 - regression_loss: 0.0822 - classification_loss: 0.0069
128/500 [======>.......................] - ETA: 2:53 - loss: 0.0891 - regression_loss: 0.0823 - classification_loss: 0.0068
129/500 [======>.......................] - ETA: 2:52 - loss: 0.0887 - regression_loss: 0.0819 - classification_loss: 0.0068
130/500 [======>.......................] - ETA: 2:52 - loss: 0.0893 - regression_loss: 0.0824 - classification_loss: 0.0069
131/500 [======>.......................] - ETA: 2:51 - loss: 0.0896 - regression_loss: 0.0826 - classification_loss: 0.0070
132/500 [======>.......................] - ETA: 2:51 - loss: 0.0896 - regression_loss: 0.0826 - classification_loss: 0.0070
133/500 [======>.......................] - ETA: 2:50 - loss: 0.0890 - regression_loss: 0.0820 - classification_loss: 0.0069
134/500 [=======>......................] - ETA: 2:50 - loss: 0.0894 - regression_loss: 0.0825 - classification_loss: 0.0069
135/500 [=======>......................] - ETA: 2:49 - loss: 0.0899 - regression_loss: 0.0829 - classification_loss: 0.0069
136/500 [=======>......................] - ETA: 2:49 - loss: 0.0901 - regression_loss: 0.0832 - classification_loss: 0.0069
137/500 [=======>......................] - ETA: 2:48 - loss: 0.0902 - regression_loss: 0.0833 - classification_loss: 0.0069
138/500 [=======>......................] - ETA: 2:48 - loss: 0.0898 - regression_loss: 0.0830 - classification_loss: 0.0069
139/500 [=======>......................] - ETA: 2:48 - loss: 0.0895 - regression_loss: 0.0827 - classification_loss: 0.0068
140/500 [=======>......................] - ETA: 2:47 - loss: 0.0900 - regression_loss: 0.0831 - classification_loss: 0.0069
141/500 [=======>......................] - ETA: 2:47 - loss: 0.0898 - regression_loss: 0.0830 - classification_loss: 0.0069
142/500 [=======>......................] - ETA: 2:46 - loss: 0.0902 - regression_loss: 0.0833 - classification_loss: 0.0069
143/500 [=======>......................] - ETA: 2:46 - loss: 0.0899 - regression_loss: 0.0830 - classification_loss: 0.0068
144/500 [=======>......................] - ETA: 2:45 - loss: 0.0901 - regression_loss: 0.0832 - classification_loss: 0.0069
145/500 [=======>......................] - ETA: 2:45 - loss: 0.0896 - regression_loss: 0.0827 - classification_loss: 0.0069
146/500 [=======>......................] - ETA: 2:44 - loss: 0.0896 - regression_loss: 0.0827 - classification_loss: 0.0069
147/500 [=======>......................] - ETA: 2:44 - loss: 0.0892 - regression_loss: 0.0824 - classification_loss: 0.0068
148/500 [=======>......................] - ETA: 2:43 - loss: 0.0889 - regression_loss: 0.0821 - classification_loss: 0.0068
149/500 [=======>......................] - ETA: 2:43 - loss: 0.0886 - regression_loss: 0.0818 - classification_loss: 0.0068
150/500 [========>.....................] - ETA: 2:42 - loss: 0.0892 - regression_loss: 0.0823 - classification_loss: 0.0069
151/500 [========>.....................] - ETA: 2:42 - loss: 0.0901 - regression_loss: 0.0831 - classification_loss: 0.0070
152/500 [========>.....................] - ETA: 2:42 - loss: 0.0902 - regression_loss: 0.0832 - classification_loss: 0.0070
153/500 [========>.....................] - ETA: 2:41 - loss: 0.0897 - regression_loss: 0.0828 - classification_loss: 0.0069
154/500 [========>.....................] - ETA: 2:41 - loss: 0.0893 - regression_loss: 0.0824 - classification_loss: 0.0069
155/500 [========>.....................] - ETA: 2:40 - loss: 0.0888 - regression_loss: 0.0820 - classification_loss: 0.0069
156/500 [========>.....................] - ETA: 2:40 - loss: 0.0892 - regression_loss: 0.0822 - classification_loss: 0.0069
157/500 [========>.....................] - ETA: 2:39 - loss: 0.0888 - regression_loss: 0.0819 - classification_loss: 0.0069
158/500 [========>.....................] - ETA: 2:39 - loss: 0.0888 - regression_loss: 0.0819 - classification_loss: 0.0069
159/500 [========>.....................] - ETA: 2:38 - loss: 0.0885 - regression_loss: 0.0816 - classification_loss: 0.0069
160/500 [========>.....................] - ETA: 2:38 - loss: 0.0886 - regression_loss: 0.0817 - classification_loss: 0.0068
161/500 [========>.....................] - ETA: 2:37 - loss: 0.0881 - regression_loss: 0.0813 - classification_loss: 0.0068
162/500 [========>.....................] - ETA: 2:37 - loss: 0.0879 - regression_loss: 0.0811 - classification_loss: 0.0068
163/500 [========>.....................] - ETA: 2:36 - loss: 0.0880 - regression_loss: 0.0812 - classification_loss: 0.0069
164/500 [========>.....................] - ETA: 2:36 - loss: 0.0877 - regression_loss: 0.0809 - classification_loss: 0.0068
165/500 [========>.....................] - ETA: 2:35 - loss: 0.0873 - regression_loss: 0.0805 - classification_loss: 0.0068
166/500 [========>.....................] - ETA: 2:35 - loss: 0.0875 - regression_loss: 0.0806 - classification_loss: 0.0069
167/500 [=========>....................] - ETA: 2:35 - loss: 0.0874 - regression_loss: 0.0806 - classification_loss: 0.0069
168/500 [=========>....................] - ETA: 2:34 - loss: 0.0873 - regression_loss: 0.0805 - classification_loss: 0.0068
169/500 [=========>....................] - ETA: 2:34 - loss: 0.0869 - regression_loss: 0.0801 - classification_loss: 0.0068
170/500 [=========>....................] - ETA: 2:33 - loss: 0.0866 - regression_loss: 0.0798 - classification_loss: 0.0068
171/500 [=========>....................] - ETA: 2:33 - loss: 0.0862 - regression_loss: 0.0794 - classification_loss: 0.0068
172/500 [=========>....................] - ETA: 2:32 - loss: 0.0866 - regression_loss: 0.0797 - classification_loss: 0.0069
173/500 [=========>....................] - ETA: 2:32 - loss: 0.0862 - regression_loss: 0.0793 - classification_loss: 0.0068
174/500 [=========>....................] - ETA: 2:31 - loss: 0.0857 - regression_loss: 0.0789 - classification_loss: 0.0068
175/500 [=========>....................] - ETA: 2:31 - loss: 0.0856 - regression_loss: 0.0788 - classification_loss: 0.0068
176/500 [=========>....................] - ETA: 2:30 - loss: 0.0854 - regression_loss: 0.0787 - classification_loss: 0.0068
177/500 [=========>....................] - ETA: 2:30 - loss: 0.0852 - regression_loss: 0.0784 - classification_loss: 0.0067
178/500 [=========>....................] - ETA: 2:29 - loss: 0.0848 - regression_loss: 0.0781 - classification_loss: 0.0067
179/500 [=========>....................] - ETA: 2:29 - loss: 0.0851 - regression_loss: 0.0783 - classification_loss: 0.0068
180/500 [=========>....................] - ETA: 2:28 - loss: 0.0852 - regression_loss: 0.0785 - classification_loss: 0.0068
181/500 [=========>....................] - ETA: 2:28 - loss: 0.0854 - regression_loss: 0.0785 - classification_loss: 0.0068
182/500 [=========>....................] - ETA: 2:28 - loss: 0.0850 - regression_loss: 0.0782 - classification_loss: 0.0068
183/500 [=========>....................] - ETA: 2:27 - loss: 0.0847 - regression_loss: 0.0779 - classification_loss: 0.0068
184/500 [==========>...................] - ETA: 2:27 - loss: 0.0846 - regression_loss: 0.0779 - classification_loss: 0.0067
185/500 [==========>...................] - ETA: 2:26 - loss: 0.0854 - regression_loss: 0.0786 - classification_loss: 0.0067
186/500 [==========>...................] - ETA: 2:26 - loss: 0.0857 - regression_loss: 0.0789 - classification_loss: 0.0068
187/500 [==========>...................] - ETA: 2:25 - loss: 0.0859 - regression_loss: 0.0791 - classification_loss: 0.0068
188/500 [==========>...................] - ETA: 2:25 - loss: 0.0856 - regression_loss: 0.0789 - classification_loss: 0.0068
189/500 [==========>...................] - ETA: 2:24 - loss: 0.0853 - regression_loss: 0.0785 - classification_loss: 0.0068
190/500 [==========>...................] - ETA: 2:24 - loss: 0.0853 - regression_loss: 0.0785 - classification_loss: 0.0067
191/500 [==========>...................] - ETA: 2:23 - loss: 0.0853 - regression_loss: 0.0786 - classification_loss: 0.0067
192/500 [==========>...................] - ETA: 2:23 - loss: 0.0850 - regression_loss: 0.0783 - classification_loss: 0.0067
193/500 [==========>...................] - ETA: 2:22 - loss: 0.0849 - regression_loss: 0.0782 - classification_loss: 0.0067
194/500 [==========>...................] - ETA: 2:22 - loss: 0.0852 - regression_loss: 0.0785 - classification_loss: 0.0067
195/500 [==========>...................] - ETA: 2:22 - loss: 0.0850 - regression_loss: 0.0783 - classification_loss: 0.0067
196/500 [==========>...................] - ETA: 2:21 - loss: 0.0852 - regression_loss: 0.0784 - classification_loss: 0.0068
197/500 [==========>...................] - ETA: 2:21 - loss: 0.0852 - regression_loss: 0.0784 - classification_loss: 0.0068
198/500 [==========>...................] - ETA: 2:20 - loss: 0.0854 - regression_loss: 0.0787 - classification_loss: 0.0067
199/500 [==========>...................] - ETA: 2:20 - loss: 0.0853 - regression_loss: 0.0786 - classification_loss: 0.0067
200/500 [===========>..................] - ETA: 2:19 - loss: 0.0852 - regression_loss: 0.0785 - classification_loss: 0.0067
201/500 [===========>..................] - ETA: 2:19 - loss: 0.0852 - regression_loss: 0.0785 - classification_loss: 0.0067
202/500 [===========>..................] - ETA: 2:18 - loss: 0.0851 - regression_loss: 0.0784 - classification_loss: 0.0067
203/500 [===========>..................] - ETA: 2:18 - loss: 0.0848 - regression_loss: 0.0782 - classification_loss: 0.0067
204/500 [===========>..................] - ETA: 2:17 - loss: 0.0847 - regression_loss: 0.0781 - classification_loss: 0.0066
205/500 [===========>..................] - ETA: 2:17 - loss: 0.0852 - regression_loss: 0.0784 - classification_loss: 0.0067
206/500 [===========>..................] - ETA: 2:16 - loss: 0.0848 - regression_loss: 0.0781 - classification_loss: 0.0067
207/500 [===========>..................] - ETA: 2:16 - loss: 0.0845 - regression_loss: 0.0778 - classification_loss: 0.0067
208/500 [===========>..................] - ETA: 2:15 - loss: 0.0847 - regression_loss: 0.0780 - classification_loss: 0.0067
209/500 [===========>..................] - ETA: 2:15 - loss: 0.0845 - regression_loss: 0.0778 - classification_loss: 0.0067
210/500 [===========>..................] - ETA: 2:15 - loss: 0.0846 - regression_loss: 0.0779 - classification_loss: 0.0067
211/500 [===========>..................] - ETA: 2:14 - loss: 0.0846 - regression_loss: 0.0779 - classification_loss: 0.0067
212/500 [===========>..................] - ETA: 2:14 - loss: 0.0849 - regression_loss: 0.0782 - classification_loss: 0.0068
213/500 [===========>..................] - ETA: 2:13 - loss: 0.0847 - regression_loss: 0.0780 - classification_loss: 0.0068
214/500 [===========>..................] - ETA: 2:13 - loss: 0.0845 - regression_loss: 0.0778 - classification_loss: 0.0067
215/500 [===========>..................] - ETA: 2:12 - loss: 0.0843 - regression_loss: 0.0776 - classification_loss: 0.0067
216/500 [===========>..................] - ETA: 2:12 - loss: 0.0840 - regression_loss: 0.0773 - classification_loss: 0.0067
217/500 [============>.................] - ETA: 2:11 - loss: 0.0839 - regression_loss: 0.0772 - classification_loss: 0.0067
218/500 [============>.................] - ETA: 2:11 - loss: 0.0837 - regression_loss: 0.0770 - classification_loss: 0.0067
219/500 [============>.................] - ETA: 2:10 - loss: 0.0833 - regression_loss: 0.0767 - classification_loss: 0.0066
220/500 [============>.................] - ETA: 2:10 - loss: 0.0837 - regression_loss: 0.0770 - classification_loss: 0.0067
221/500 [============>.................] - ETA: 2:09 - loss: 0.0834 - regression_loss: 0.0767 - classification_loss: 0.0067
222/500 [============>.................] - ETA: 2:09 - loss: 0.0836 - regression_loss: 0.0769 - classification_loss: 0.0068
223/500 [============>.................] - ETA: 2:08 - loss: 0.0833 - regression_loss: 0.0766 - classification_loss: 0.0067
224/500 [============>.................] - ETA: 2:08 - loss: 0.0833 - regression_loss: 0.0766 - classification_loss: 0.0067
225/500 [============>.................] - ETA: 2:07 - loss: 0.0835 - regression_loss: 0.0768 - classification_loss: 0.0067
226/500 [============>.................] - ETA: 2:07 - loss: 0.0835 - regression_loss: 0.0768 - classification_loss: 0.0067
227/500 [============>.................] - ETA: 2:07 - loss: 0.0832 - regression_loss: 0.0765 - classification_loss: 0.0067
228/500 [============>.................] - ETA: 2:06 - loss: 0.0830 - regression_loss: 0.0763 - classification_loss: 0.0067
229/500 [============>.................] - ETA: 2:06 - loss: 0.0827 - regression_loss: 0.0761 - classification_loss: 0.0066
230/500 [============>.................] - ETA: 2:05 - loss: 0.0829 - regression_loss: 0.0763 - classification_loss: 0.0067
231/500 [============>.................] - ETA: 2:05 - loss: 0.0832 - regression_loss: 0.0765 - classification_loss: 0.0067
232/500 [============>.................] - ETA: 2:04 - loss: 0.0829 - regression_loss: 0.0762 - classification_loss: 0.0067
233/500 [============>.................] - ETA: 2:04 - loss: 0.0826 - regression_loss: 0.0760 - classification_loss: 0.0066
234/500 [=============>................] - ETA: 2:03 - loss: 0.0825 - regression_loss: 0.0759 - classification_loss: 0.0066
235/500 [=============>................] - ETA: 2:03 - loss: 0.0826 - regression_loss: 0.0760 - classification_loss: 0.0067
236/500 [=============>................] - ETA: 2:02 - loss: 0.0828 - regression_loss: 0.0761 - classification_loss: 0.0067
237/500 [=============>................] - ETA: 2:02 - loss: 0.0827 - regression_loss: 0.0761 - classification_loss: 0.0067
238/500 [=============>................] - ETA: 2:01 - loss: 0.0828 - regression_loss: 0.0761 - classification_loss: 0.0066
239/500 [=============>................] - ETA: 2:01 - loss: 0.0827 - regression_loss: 0.0761 - classification_loss: 0.0066
240/500 [=============>................] - ETA: 2:00 - loss: 0.0831 - regression_loss: 0.0764 - classification_loss: 0.0067
241/500 [=============>................] - ETA: 2:00 - loss: 0.0829 - regression_loss: 0.0763 - classification_loss: 0.0066
242/500 [=============>................] - ETA: 2:00 - loss: 0.0827 - regression_loss: 0.0761 - classification_loss: 0.0066
243/500 [=============>................] - ETA: 1:59 - loss: 0.0831 - regression_loss: 0.0764 - classification_loss: 0.0067
244/500 [=============>................] - ETA: 1:59 - loss: 0.0833 - regression_loss: 0.0766 - classification_loss: 0.0067
245/500 [=============>................] - ETA: 1:58 - loss: 0.0835 - regression_loss: 0.0769 - classification_loss: 0.0067
246/500 [=============>................] - ETA: 1:58 - loss: 0.0834 - regression_loss: 0.0767 - classification_loss: 0.0066
247/500 [=============>................] - ETA: 1:57 - loss: 0.0837 - regression_loss: 0.0770 - classification_loss: 0.0066
248/500 [=============>................] - ETA: 1:57 - loss: 0.0843 - regression_loss: 0.0776 - classification_loss: 0.0067
249/500 [=============>................] - ETA: 1:56 - loss: 0.0844 - regression_loss: 0.0777 - classification_loss: 0.0067
250/500 [==============>...............] - ETA: 1:56 - loss: 0.0841 - regression_loss: 0.0774 - classification_loss: 0.0067
251/500 [==============>...............] - ETA: 1:55 - loss: 0.0843 - regression_loss: 0.0776 - classification_loss: 0.0067
252/500 [==============>...............] - ETA: 1:55 - loss: 0.0840 - regression_loss: 0.0773 - classification_loss: 0.0067
253/500 [==============>...............] - ETA: 1:54 - loss: 0.0841 - regression_loss: 0.0774 - classification_loss: 0.0067
254/500 [==============>...............] - ETA: 1:54 - loss: 0.0839 - regression_loss: 0.0772 - classification_loss: 0.0067
255/500 [==============>...............] - ETA: 1:53 - loss: 0.0837 - regression_loss: 0.0770 - classification_loss: 0.0067
256/500 [==============>...............] - ETA: 1:53 - loss: 0.0835 - regression_loss: 0.0768 - classification_loss: 0.0066
257/500 [==============>...............] - ETA: 1:53 - loss: 0.0836 - regression_loss: 0.0770 - classification_loss: 0.0066
258/500 [==============>...............] - ETA: 1:52 - loss: 0.0836 - regression_loss: 0.0770 - classification_loss: 0.0066
259/500 [==============>...............] - ETA: 1:52 - loss: 0.0844 - regression_loss: 0.0777 - classification_loss: 0.0067
260/500 [==============>...............] - ETA: 1:51 - loss: 0.0846 - regression_loss: 0.0779 - classification_loss: 0.0067
261/500 [==============>...............] - ETA: 1:51 - loss: 0.0847 - regression_loss: 0.0780 - classification_loss: 0.0066
262/500 [==============>...............] - ETA: 1:50 - loss: 0.0845 - regression_loss: 0.0778 - classification_loss: 0.0066
263/500 [==============>...............] - ETA: 1:50 - loss: 0.0844 - regression_loss: 0.0778 - classification_loss: 0.0066
264/500 [==============>...............] - ETA: 1:49 - loss: 0.0846 - regression_loss: 0.0779 - classification_loss: 0.0067
265/500 [==============>...............] - ETA: 1:49 - loss: 0.0845 - regression_loss: 0.0778 - classification_loss: 0.0067
266/500 [==============>...............] - ETA: 1:48 - loss: 0.0844 - regression_loss: 0.0778 - classification_loss: 0.0066
267/500 [===============>..............] - ETA: 1:48 - loss: 0.0843 - regression_loss: 0.0776 - classification_loss: 0.0066
268/500 [===============>..............] - ETA: 1:47 - loss: 0.0842 - regression_loss: 0.0776 - classification_loss: 0.0066
269/500 [===============>..............] - ETA: 1:47 - loss: 0.0841 - regression_loss: 0.0774 - classification_loss: 0.0066
270/500 [===============>..............] - ETA: 1:46 - loss: 0.0844 - regression_loss: 0.0777 - classification_loss: 0.0067
271/500 [===============>..............] - ETA: 1:46 - loss: 0.0842 - regression_loss: 0.0776 - classification_loss: 0.0066
272/500 [===============>..............] - ETA: 1:46 - loss: 0.0840 - regression_loss: 0.0774 - classification_loss: 0.0066
273/500 [===============>..............] - ETA: 1:45 - loss: 0.0841 - regression_loss: 0.0775 - classification_loss: 0.0066
274/500 [===============>..............] - ETA: 1:45 - loss: 0.0840 - regression_loss: 0.0774 - classification_loss: 0.0066
275/500 [===============>..............] - ETA: 1:44 - loss: 0.0842 - regression_loss: 0.0775 - classification_loss: 0.0066
276/500 [===============>..............] - ETA: 1:44 - loss: 0.0844 - regression_loss: 0.0777 - classification_loss: 0.0067
277/500 [===============>..............] - ETA: 1:43 - loss: 0.0843 - regression_loss: 0.0776 - classification_loss: 0.0067
278/500 [===============>..............] - ETA: 1:43 - loss: 0.0841 - regression_loss: 0.0774 - classification_loss: 0.0067
279/500 [===============>..............] - ETA: 1:42 - loss: 0.0839 - regression_loss: 0.0772 - classification_loss: 0.0066
280/500 [===============>..............] - ETA: 1:42 - loss: 0.0838 - regression_loss: 0.0772 - classification_loss: 0.0066
281/500 [===============>..............] - ETA: 1:41 - loss: 0.0843 - regression_loss: 0.0776 - classification_loss: 0.0067
282/500 [===============>..............] - ETA: 1:41 - loss: 0.0845 - regression_loss: 0.0778 - classification_loss: 0.0067
283/500 [===============>..............] - ETA: 1:40 - loss: 0.0843 - regression_loss: 0.0777 - classification_loss: 0.0067
284/500 [================>.............] - ETA: 1:40 - loss: 0.0842 - regression_loss: 0.0775 - classification_loss: 0.0066
285/500 [================>.............] - ETA: 1:40 - loss: 0.0840 - regression_loss: 0.0773 - classification_loss: 0.0066
286/500 [================>.............] - ETA: 1:39 - loss: 0.0837 - regression_loss: 0.0771 - classification_loss: 0.0066
287/500 [================>.............] - ETA: 1:39 - loss: 0.0835 - regression_loss: 0.0769 - classification_loss: 0.0066
288/500 [================>.............] - ETA: 1:38 - loss: 0.0837 - regression_loss: 0.0771 - classification_loss: 0.0066
289/500 [================>.............] - ETA: 1:38 - loss: 0.0839 - regression_loss: 0.0773 - classification_loss: 0.0066
290/500 [================>.............] - ETA: 1:37 - loss: 0.0839 - regression_loss: 0.0773 - classification_loss: 0.0066
291/500 [================>.............] - ETA: 1:37 - loss: 0.0841 - regression_loss: 0.0774 - classification_loss: 0.0067
292/500 [================>.............] - ETA: 1:36 - loss: 0.0840 - regression_loss: 0.0773 - classification_loss: 0.0066
293/500 [================>.............] - ETA: 1:36 - loss: 0.0838 - regression_loss: 0.0772 - classification_loss: 0.0066
294/500 [================>.............] - ETA: 1:35 - loss: 0.0838 - regression_loss: 0.0771 - classification_loss: 0.0066
295/500 [================>.............] - ETA: 1:35 - loss: 0.0838 - regression_loss: 0.0772 - classification_loss: 0.0066
296/500 [================>.............] - ETA: 1:34 - loss: 0.0836 - regression_loss: 0.0770 - classification_loss: 0.0066
297/500 [================>.............] - ETA: 1:34 - loss: 0.0835 - regression_loss: 0.0769 - classification_loss: 0.0066
298/500 [================>.............] - ETA: 1:33 - loss: 0.0833 - regression_loss: 0.0767 - classification_loss: 0.0066
299/500 [================>.............] - ETA: 1:33 - loss: 0.0834 - regression_loss: 0.0768 - classification_loss: 0.0066
300/500 [=================>............] - ETA: 1:33 - loss: 0.0831 - regression_loss: 0.0765 - classification_loss: 0.0066
301/500 [=================>............] - ETA: 1:32 - loss: 0.0832 - regression_loss: 0.0766 - classification_loss: 0.0066
302/500 [=================>............] - ETA: 1:32 - loss: 0.0830 - regression_loss: 0.0764 - classification_loss: 0.0066
303/500 [=================>............] - ETA: 1:31 - loss: 0.0828 - regression_loss: 0.0762 - classification_loss: 0.0066
304/500 [=================>............] - ETA: 1:31 - loss: 0.0828 - regression_loss: 0.0763 - classification_loss: 0.0066
305/500 [=================>............] - ETA: 1:30 - loss: 0.0827 - regression_loss: 0.0761 - classification_loss: 0.0066
306/500 [=================>............] - ETA: 1:30 - loss: 0.0827 - regression_loss: 0.0761 - classification_loss: 0.0066
307/500 [=================>............] - ETA: 1:29 - loss: 0.0825 - regression_loss: 0.0759 - classification_loss: 0.0065
308/500 [=================>............] - ETA: 1:29 - loss: 0.0825 - regression_loss: 0.0760 - classification_loss: 0.0065
309/500 [=================>............] - ETA: 1:28 - loss: 0.0829 - regression_loss: 0.0763 - classification_loss: 0.0066
310/500 [=================>............] - ETA: 1:28 - loss: 0.0828 - regression_loss: 0.0762 - classification_loss: 0.0066
311/500 [=================>............] - ETA: 1:27 - loss: 0.0829 - regression_loss: 0.0764 - classification_loss: 0.0066
312/500 [=================>............] - ETA: 1:27 - loss: 0.0831 - regression_loss: 0.0765 - classification_loss: 0.0065
313/500 [=================>............] - ETA: 1:26 - loss: 0.0829 - regression_loss: 0.0764 - classification_loss: 0.0065
314/500 [=================>............] - ETA: 1:26 - loss: 0.0830 - regression_loss: 0.0764 - classification_loss: 0.0066
315/500 [=================>............] - ETA: 1:26 - loss: 0.0829 - regression_loss: 0.0764 - classification_loss: 0.0065
316/500 [=================>............] - ETA: 1:25 - loss: 0.0830 - regression_loss: 0.0764 - classification_loss: 0.0066
317/500 [==================>...........] - ETA: 1:25 - loss: 0.0828 - regression_loss: 0.0762 - classification_loss: 0.0066
318/500 [==================>...........] - ETA: 1:24 - loss: 0.0828 - regression_loss: 0.0763 - classification_loss: 0.0066
319/500 [==================>...........] - ETA: 1:24 - loss: 0.0827 - regression_loss: 0.0762 - classification_loss: 0.0065
320/500 [==================>...........] - ETA: 1:23 - loss: 0.0826 - regression_loss: 0.0761 - classification_loss: 0.0065
321/500 [==================>...........] - ETA: 1:23 - loss: 0.0826 - regression_loss: 0.0761 - classification_loss: 0.0065
322/500 [==================>...........] - ETA: 1:22 - loss: 0.0825 - regression_loss: 0.0760 - classification_loss: 0.0065
323/500 [==================>...........] - ETA: 1:22 - loss: 0.0824 - regression_loss: 0.0759 - classification_loss: 0.0065
324/500 [==================>...........] - ETA: 1:21 - loss: 0.0825 - regression_loss: 0.0760 - classification_loss: 0.0065
325/500 [==================>...........] - ETA: 1:21 - loss: 0.0824 - regression_loss: 0.0759 - classification_loss: 0.0065
326/500 [==================>...........] - ETA: 1:20 - loss: 0.0824 - regression_loss: 0.0759 - classification_loss: 0.0065
327/500 [==================>...........] - ETA: 1:20 - loss: 0.0822 - regression_loss: 0.0757 - classification_loss: 0.0065
328/500 [==================>...........] - ETA: 1:19 - loss: 0.0821 - regression_loss: 0.0756 - classification_loss: 0.0065
329/500 [==================>...........] - ETA: 1:19 - loss: 0.0823 - regression_loss: 0.0758 - classification_loss: 0.0065
330/500 [==================>...........] - ETA: 1:19 - loss: 0.0823 - regression_loss: 0.0758 - classification_loss: 0.0065
331/500 [==================>...........] - ETA: 1:18 - loss: 0.0826 - regression_loss: 0.0760 - classification_loss: 0.0065
332/500 [==================>...........] - ETA: 1:18 - loss: 0.0824 - regression_loss: 0.0759 - classification_loss: 0.0065
333/500 [==================>...........] - ETA: 1:17 - loss: 0.0824 - regression_loss: 0.0759 - classification_loss: 0.0065
334/500 [===================>..........] - ETA: 1:17 - loss: 0.0825 - regression_loss: 0.0760 - classification_loss: 0.0065
335/500 [===================>..........] - ETA: 1:16 - loss: 0.0826 - regression_loss: 0.0761 - classification_loss: 0.0065
336/500 [===================>..........] - ETA: 1:16 - loss: 0.0828 - regression_loss: 0.0763 - classification_loss: 0.0065
337/500 [===================>..........] - ETA: 1:15 - loss: 0.0827 - regression_loss: 0.0762 - classification_loss: 0.0065
338/500 [===================>..........] - ETA: 1:15 - loss: 0.0826 - regression_loss: 0.0761 - classification_loss: 0.0065
339/500 [===================>..........] - ETA: 1:14 - loss: 0.0829 - regression_loss: 0.0764 - classification_loss: 0.0065
340/500 [===================>..........] - ETA: 1:14 - loss: 0.0831 - regression_loss: 0.0766 - classification_loss: 0.0065
341/500 [===================>..........] - ETA: 1:13 - loss: 0.0832 - regression_loss: 0.0767 - classification_loss: 0.0065
342/500 [===================>..........] - ETA: 1:13 - loss: 0.0831 - regression_loss: 0.0766 - classification_loss: 0.0065
343/500 [===================>..........] - ETA: 1:13 - loss: 0.0830 - regression_loss: 0.0765 - classification_loss: 0.0065
344/500 [===================>..........] - ETA: 1:12 - loss: 0.0832 - regression_loss: 0.0767 - classification_loss: 0.0065
345/500 [===================>..........] - ETA: 1:12 - loss: 0.0831 - regression_loss: 0.0766 - classification_loss: 0.0065
346/500 [===================>..........] - ETA: 1:11 - loss: 0.0831 - regression_loss: 0.0766 - classification_loss: 0.0065
347/500 [===================>..........] - ETA: 1:11 - loss: 0.0833 - regression_loss: 0.0768 - classification_loss: 0.0065
348/500 [===================>..........] - ETA: 1:10 - loss: 0.0831 - regression_loss: 0.0767 - classification_loss: 0.0065
349/500 [===================>..........] - ETA: 1:10 - loss: 0.0829 - regression_loss: 0.0765 - classification_loss: 0.0064
350/500 [====================>.........] - ETA: 1:09 - loss: 0.0831 - regression_loss: 0.0766 - classification_loss: 0.0065
351/500 [====================>.........] - ETA: 1:09 - loss: 0.0832 - regression_loss: 0.0767 - classification_loss: 0.0065
352/500 [====================>.........] - ETA: 1:08 - loss: 0.0830 - regression_loss: 0.0766 - classification_loss: 0.0065
353/500 [====================>.........] - ETA: 1:08 - loss: 0.0828 - regression_loss: 0.0764 - classification_loss: 0.0065
354/500 [====================>.........] - ETA: 1:07 - loss: 0.0830 - regression_loss: 0.0765 - classification_loss: 0.0065
355/500 [====================>.........] - ETA: 1:07 - loss: 0.0830 - regression_loss: 0.0765 - classification_loss: 0.0065
356/500 [====================>.........] - ETA: 1:06 - loss: 0.0831 - regression_loss: 0.0765 - classification_loss: 0.0065
357/500 [====================>.........] - ETA: 1:06 - loss: 0.0829 - regression_loss: 0.0764 - classification_loss: 0.0065
358/500 [====================>.........] - ETA: 1:06 - loss: 0.0828 - regression_loss: 0.0763 - classification_loss: 0.0065
359/500 [====================>.........] - ETA: 1:05 - loss: 0.0827 - regression_loss: 0.0762 - classification_loss: 0.0065
360/500 [====================>.........] - ETA: 1:05 - loss: 0.0827 - regression_loss: 0.0763 - classification_loss: 0.0065
361/500 [====================>.........] - ETA: 1:04 - loss: 0.0828 - regression_loss: 0.0763 - classification_loss: 0.0065
362/500 [====================>.........] - ETA: 1:04 - loss: 0.0826 - regression_loss: 0.0761 - classification_loss: 0.0065
363/500 [====================>.........] - ETA: 1:03 - loss: 0.0824 - regression_loss: 0.0759 - classification_loss: 0.0064
364/500 [====================>.........] - ETA: 1:03 - loss: 0.0822 - regression_loss: 0.0758 - classification_loss: 0.0064
365/500 [====================>.........] - ETA: 1:02 - loss: 0.0823 - regression_loss: 0.0758 - classification_loss: 0.0065
366/500 [====================>.........] - ETA: 1:02 - loss: 0.0822 - regression_loss: 0.0757 - classification_loss: 0.0064
367/500 [=====================>........] - ETA: 1:01 - loss: 0.0821 - regression_loss: 0.0756 - classification_loss: 0.0064
368/500 [=====================>........] - ETA: 1:01 - loss: 0.0822 - regression_loss: 0.0757 - classification_loss: 0.0065
369/500 [=====================>........] - ETA: 1:00 - loss: 0.0820 - regression_loss: 0.0755 - classification_loss: 0.0064
370/500 [=====================>........] - ETA: 1:00 - loss: 0.0821 - regression_loss: 0.0756 - classification_loss: 0.0064
371/500 [=====================>........] - ETA: 59s - loss: 0.0822 - regression_loss: 0.0757 - classification_loss: 0.0065 
372/500 [=====================>........] - ETA: 59s - loss: 0.0820 - regression_loss: 0.0756 - classification_loss: 0.0065
373/500 [=====================>........] - ETA: 59s - loss: 0.0819 - regression_loss: 0.0754 - classification_loss: 0.0065
374/500 [=====================>........] - ETA: 58s - loss: 0.0818 - regression_loss: 0.0754 - classification_loss: 0.0064
375/500 [=====================>........] - ETA: 58s - loss: 0.0818 - regression_loss: 0.0753 - classification_loss: 0.0064
376/500 [=====================>........] - ETA: 57s - loss: 0.0817 - regression_loss: 0.0753 - classification_loss: 0.0064
377/500 [=====================>........] - ETA: 57s - loss: 0.0816 - regression_loss: 0.0752 - classification_loss: 0.0064
378/500 [=====================>........] - ETA: 56s - loss: 0.0814 - regression_loss: 0.0750 - classification_loss: 0.0064
379/500 [=====================>........] - ETA: 56s - loss: 0.0813 - regression_loss: 0.0749 - classification_loss: 0.0064
380/500 [=====================>........] - ETA: 55s - loss: 0.0814 - regression_loss: 0.0750 - classification_loss: 0.0064
381/500 [=====================>........] - ETA: 55s - loss: 0.0813 - regression_loss: 0.0749 - classification_loss: 0.0064
382/500 [=====================>........] - ETA: 54s - loss: 0.0814 - regression_loss: 0.0749 - classification_loss: 0.0064
383/500 [=====================>........] - ETA: 54s - loss: 0.0813 - regression_loss: 0.0749 - classification_loss: 0.0064
384/500 [======================>.......] - ETA: 53s - loss: 0.0812 - regression_loss: 0.0747 - classification_loss: 0.0064
385/500 [======================>.......] - ETA: 53s - loss: 0.0810 - regression_loss: 0.0746 - classification_loss: 0.0064
386/500 [======================>.......] - ETA: 53s - loss: 0.0808 - regression_loss: 0.0744 - classification_loss: 0.0064
387/500 [======================>.......] - ETA: 52s - loss: 0.0806 - regression_loss: 0.0742 - classification_loss: 0.0064
388/500 [======================>.......] - ETA: 52s - loss: 0.0806 - regression_loss: 0.0742 - classification_loss: 0.0064
389/500 [======================>.......] - ETA: 51s - loss: 0.0806 - regression_loss: 0.0742 - classification_loss: 0.0064
390/500 [======================>.......] - ETA: 51s - loss: 0.0807 - regression_loss: 0.0743 - classification_loss: 0.0064
391/500 [======================>.......] - ETA: 50s - loss: 0.0807 - regression_loss: 0.0743 - classification_loss: 0.0064
392/500 [======================>.......] - ETA: 50s - loss: 0.0806 - regression_loss: 0.0742 - classification_loss: 0.0064
393/500 [======================>.......] - ETA: 49s - loss: 0.0804 - regression_loss: 0.0741 - classification_loss: 0.0064
394/500 [======================>.......] - ETA: 49s - loss: 0.0806 - regression_loss: 0.0742 - classification_loss: 0.0064
395/500 [======================>.......] - ETA: 48s - loss: 0.0805 - regression_loss: 0.0741 - classification_loss: 0.0064
396/500 [======================>.......] - ETA: 48s - loss: 0.0804 - regression_loss: 0.0740 - classification_loss: 0.0064
397/500 [======================>.......] - ETA: 47s - loss: 0.0804 - regression_loss: 0.0740 - classification_loss: 0.0064
398/500 [======================>.......] - ETA: 47s - loss: 0.0803 - regression_loss: 0.0739 - classification_loss: 0.0064
399/500 [======================>.......] - ETA: 46s - loss: 0.0802 - regression_loss: 0.0739 - classification_loss: 0.0064
400/500 [=======================>......] - ETA: 46s - loss: 0.0803 - regression_loss: 0.0740 - classification_loss: 0.0064
401/500 [=======================>......] - ETA: 46s - loss: 0.0802 - regression_loss: 0.0738 - classification_loss: 0.0064
402/500 [=======================>......] - ETA: 45s - loss: 0.0801 - regression_loss: 0.0738 - classification_loss: 0.0064
403/500 [=======================>......] - ETA: 45s - loss: 0.0802 - regression_loss: 0.0738 - classification_loss: 0.0064
404/500 [=======================>......] - ETA: 44s - loss: 0.0801 - regression_loss: 0.0738 - classification_loss: 0.0064
405/500 [=======================>......] - ETA: 44s - loss: 0.0799 - regression_loss: 0.0736 - classification_loss: 0.0064
406/500 [=======================>......] - ETA: 43s - loss: 0.0800 - regression_loss: 0.0736 - classification_loss: 0.0064
407/500 [=======================>......] - ETA: 43s - loss: 0.0798 - regression_loss: 0.0735 - classification_loss: 0.0063
408/500 [=======================>......] - ETA: 42s - loss: 0.0797 - regression_loss: 0.0734 - classification_loss: 0.0063
409/500 [=======================>......] - ETA: 42s - loss: 0.0801 - regression_loss: 0.0737 - classification_loss: 0.0064
410/500 [=======================>......] - ETA: 41s - loss: 0.0805 - regression_loss: 0.0741 - classification_loss: 0.0064
411/500 [=======================>......] - ETA: 41s - loss: 0.0806 - regression_loss: 0.0742 - classification_loss: 0.0064
412/500 [=======================>......] - ETA: 40s - loss: 0.0805 - regression_loss: 0.0742 - classification_loss: 0.0064
413/500 [=======================>......] - ETA: 40s - loss: 0.0805 - regression_loss: 0.0741 - classification_loss: 0.0064
414/500 [=======================>......] - ETA: 40s - loss: 0.0805 - regression_loss: 0.0742 - classification_loss: 0.0064
415/500 [=======================>......] - ETA: 39s - loss: 0.0805 - regression_loss: 0.0742 - classification_loss: 0.0063
416/500 [=======================>......] - ETA: 39s - loss: 0.0807 - regression_loss: 0.0743 - classification_loss: 0.0063
417/500 [========================>.....] - ETA: 38s - loss: 0.0806 - regression_loss: 0.0743 - classification_loss: 0.0063
418/500 [========================>.....] - ETA: 38s - loss: 0.0804 - regression_loss: 0.0741 - classification_loss: 0.0063
419/500 [========================>.....] - ETA: 37s - loss: 0.0804 - regression_loss: 0.0740 - classification_loss: 0.0063
420/500 [========================>.....] - ETA: 37s - loss: 0.0805 - regression_loss: 0.0742 - classification_loss: 0.0063
421/500 [========================>.....] - ETA: 36s - loss: 0.0804 - regression_loss: 0.0740 - classification_loss: 0.0063
422/500 [========================>.....] - ETA: 36s - loss: 0.0805 - regression_loss: 0.0741 - classification_loss: 0.0064
423/500 [========================>.....] - ETA: 35s - loss: 0.0806 - regression_loss: 0.0742 - classification_loss: 0.0063
424/500 [========================>.....] - ETA: 35s - loss: 0.0805 - regression_loss: 0.0742 - classification_loss: 0.0063
425/500 [========================>.....] - ETA: 34s - loss: 0.0806 - regression_loss: 0.0743 - classification_loss: 0.0063
426/500 [========================>.....] - ETA: 34s - loss: 0.0808 - regression_loss: 0.0744 - classification_loss: 0.0064
427/500 [========================>.....] - ETA: 33s - loss: 0.0807 - regression_loss: 0.0743 - classification_loss: 0.0063
428/500 [========================>.....] - ETA: 33s - loss: 0.0807 - regression_loss: 0.0744 - classification_loss: 0.0063
429/500 [========================>.....] - ETA: 33s - loss: 0.0806 - regression_loss: 0.0743 - classification_loss: 0.0063
430/500 [========================>.....] - ETA: 32s - loss: 0.0806 - regression_loss: 0.0743 - classification_loss: 0.0063
431/500 [========================>.....] - ETA: 32s - loss: 0.0804 - regression_loss: 0.0741 - classification_loss: 0.0063
432/500 [========================>.....] - ETA: 31s - loss: 0.0807 - regression_loss: 0.0743 - classification_loss: 0.0063
433/500 [========================>.....] - ETA: 31s - loss: 0.0806 - regression_loss: 0.0743 - classification_loss: 0.0063
434/500 [=========================>....] - ETA: 30s - loss: 0.0807 - regression_loss: 0.0744 - classification_loss: 0.0063
435/500 [=========================>....] - ETA: 30s - loss: 0.0806 - regression_loss: 0.0743 - classification_loss: 0.0063
436/500 [=========================>....] - ETA: 29s - loss: 0.0808 - regression_loss: 0.0745 - classification_loss: 0.0063
437/500 [=========================>....] - ETA: 29s - loss: 0.0808 - regression_loss: 0.0745 - classification_loss: 0.0063
438/500 [=========================>....] - ETA: 28s - loss: 0.0808 - regression_loss: 0.0745 - classification_loss: 0.0063
439/500 [=========================>....] - ETA: 28s - loss: 0.0807 - regression_loss: 0.0744 - classification_loss: 0.0063
440/500 [=========================>....] - ETA: 27s - loss: 0.0807 - regression_loss: 0.0744 - classification_loss: 0.0063
441/500 [=========================>....] - ETA: 27s - loss: 0.0807 - regression_loss: 0.0744 - classification_loss: 0.0063
442/500 [=========================>....] - ETA: 26s - loss: 0.0807 - regression_loss: 0.0744 - classification_loss: 0.0063
443/500 [=========================>....] - ETA: 26s - loss: 0.0807 - regression_loss: 0.0744 - classification_loss: 0.0063
444/500 [=========================>....] - ETA: 26s - loss: 0.0809 - regression_loss: 0.0746 - classification_loss: 0.0063
445/500 [=========================>....] - ETA: 25s - loss: 0.0811 - regression_loss: 0.0748 - classification_loss: 0.0063
446/500 [=========================>....] - ETA: 25s - loss: 0.0811 - regression_loss: 0.0749 - classification_loss: 0.0063
447/500 [=========================>....] - ETA: 24s - loss: 0.0811 - regression_loss: 0.0749 - classification_loss: 0.0063
448/500 [=========================>....] - ETA: 24s - loss: 0.0812 - regression_loss: 0.0749 - classification_loss: 0.0063
449/500 [=========================>....] - ETA: 23s - loss: 0.0812 - regression_loss: 0.0749 - classification_loss: 0.0063
450/500 [==========================>...] - ETA: 23s - loss: 0.0812 - regression_loss: 0.0749 - classification_loss: 0.0063
451/500 [==========================>...] - ETA: 22s - loss: 0.0813 - regression_loss: 0.0750 - classification_loss: 0.0063
452/500 [==========================>...] - ETA: 22s - loss: 0.0814 - regression_loss: 0.0751 - classification_loss: 0.0063
453/500 [==========================>...] - ETA: 21s - loss: 0.0813 - regression_loss: 0.0750 - classification_loss: 0.0063
454/500 [==========================>...] - ETA: 21s - loss: 0.0812 - regression_loss: 0.0749 - classification_loss: 0.0063
455/500 [==========================>...] - ETA: 20s - loss: 0.0811 - regression_loss: 0.0748 - classification_loss: 0.0063
456/500 [==========================>...] - ETA: 20s - loss: 0.0812 - regression_loss: 0.0749 - classification_loss: 0.0063
457/500 [==========================>...] - ETA: 20s - loss: 0.0810 - regression_loss: 0.0748 - classification_loss: 0.0063
458/500 [==========================>...] - ETA: 19s - loss: 0.0809 - regression_loss: 0.0747 - classification_loss: 0.0063
459/500 [==========================>...] - ETA: 19s - loss: 0.0811 - regression_loss: 0.0748 - classification_loss: 0.0063
460/500 [==========================>...] - ETA: 18s - loss: 0.0810 - regression_loss: 0.0747 - classification_loss: 0.0063
461/500 [==========================>...] - ETA: 18s - loss: 0.0810 - regression_loss: 0.0747 - classification_loss: 0.0062
462/500 [==========================>...] - ETA: 17s - loss: 0.0808 - regression_loss: 0.0746 - classification_loss: 0.0062
463/500 [==========================>...] - ETA: 17s - loss: 0.0809 - regression_loss: 0.0746 - classification_loss: 0.0063
464/500 [==========================>...] - ETA: 16s - loss: 0.0808 - regression_loss: 0.0746 - classification_loss: 0.0062
465/500 [==========================>...] - ETA: 16s - loss: 0.0807 - regression_loss: 0.0745 - classification_loss: 0.0062
466/500 [==========================>...] - ETA: 15s - loss: 0.0807 - regression_loss: 0.0745 - classification_loss: 0.0063
467/500 [===========================>..] - ETA: 15s - loss: 0.0806 - regression_loss: 0.0743 - classification_loss: 0.0062
468/500 [===========================>..] - ETA: 14s - loss: 0.0804 - regression_loss: 0.0742 - classification_loss: 0.0062
469/500 [===========================>..] - ETA: 14s - loss: 0.0804 - regression_loss: 0.0742 - classification_loss: 0.0062
470/500 [===========================>..] - ETA: 13s - loss: 0.0804 - regression_loss: 0.0741 - classification_loss: 0.0062
471/500 [===========================>..] - ETA: 13s - loss: 0.0802 - regression_loss: 0.0740 - classification_loss: 0.0062
472/500 [===========================>..] - ETA: 13s - loss: 0.0801 - regression_loss: 0.0739 - classification_loss: 0.0062
473/500 [===========================>..] - ETA: 12s - loss: 0.0800 - regression_loss: 0.0738 - classification_loss: 0.0062
474/500 [===========================>..] - ETA: 12s - loss: 0.0799 - regression_loss: 0.0738 - classification_loss: 0.0062
475/500 [===========================>..] - ETA: 11s - loss: 0.0800 - regression_loss: 0.0738 - classification_loss: 0.0062
476/500 [===========================>..] - ETA: 11s - loss: 0.0799 - regression_loss: 0.0737 - classification_loss: 0.0062
477/500 [===========================>..] - ETA: 10s - loss: 0.0798 - regression_loss: 0.0736 - classification_loss: 0.0062
478/500 [===========================>..] - ETA: 10s - loss: 0.0797 - regression_loss: 0.0735 - classification_loss: 0.0062
479/500 [===========================>..] - ETA: 9s - loss: 0.0796 - regression_loss: 0.0734 - classification_loss: 0.0062 
480/500 [===========================>..] - ETA: 9s - loss: 0.0796 - regression_loss: 0.0734 - classification_loss: 0.0062
481/500 [===========================>..] - ETA: 8s - loss: 0.0796 - regression_loss: 0.0734 - classification_loss: 0.0062
482/500 [===========================>..] - ETA: 8s - loss: 0.0795 - regression_loss: 0.0734 - classification_loss: 0.0062
483/500 [===========================>..] - ETA: 7s - loss: 0.0795 - regression_loss: 0.0734 - classification_loss: 0.0062
484/500 [============================>.] - ETA: 7s - loss: 0.0795 - regression_loss: 0.0734 - classification_loss: 0.0062
485/500 [============================>.] - ETA: 6s - loss: 0.0797 - regression_loss: 0.0735 - classification_loss: 0.0062
486/500 [============================>.] - ETA: 6s - loss: 0.0796 - regression_loss: 0.0734 - classification_loss: 0.0062
487/500 [============================>.] - ETA: 6s - loss: 0.0797 - regression_loss: 0.0735 - classification_loss: 0.0062
488/500 [============================>.] - ETA: 5s - loss: 0.0796 - regression_loss: 0.0734 - classification_loss: 0.0062
489/500 [============================>.] - ETA: 5s - loss: 0.0795 - regression_loss: 0.0733 - classification_loss: 0.0062
490/500 [============================>.] - ETA: 4s - loss: 0.0795 - regression_loss: 0.0733 - classification_loss: 0.0062
491/500 [============================>.] - ETA: 4s - loss: 0.0794 - regression_loss: 0.0732 - classification_loss: 0.0062
492/500 [============================>.] - ETA: 3s - loss: 0.0795 - regression_loss: 0.0733 - classification_loss: 0.0062
493/500 [============================>.] - ETA: 3s - loss: 0.0794 - regression_loss: 0.0733 - classification_loss: 0.0062
494/500 [============================>.] - ETA: 2s - loss: 0.0794 - regression_loss: 0.0732 - classification_loss: 0.0062
495/500 [============================>.] - ETA: 2s - loss: 0.0793 - regression_loss: 0.0731 - classification_loss: 0.0062
496/500 [============================>.] - ETA: 1s - loss: 0.0792 - regression_loss: 0.0730 - classification_loss: 0.0062
497/500 [============================>.] - ETA: 1s - loss: 0.0791 - regression_loss: 0.0729 - classification_loss: 0.0062
498/500 [============================>.] - ETA: 0s - loss: 0.0792 - regression_loss: 0.0730 - classification_loss: 0.0062
499/500 [============================>.] - ETA: 0s - loss: 0.0792 - regression_loss: 0.0731 - classification_loss: 0.0062
500/500 [==============================] - 233s 465ms/step - loss: 0.0793 - regression_loss: 0.0731 - classification_loss: 0.0062
44 instances of class building with average precision: 0.8148
mAP: 0.8148

Epoch 00006: saving model to ./snapshots/resnet50_csv_06.h5
Epoch 7/8

  1/500 [..............................] - ETA: 3:50 - loss: 0.1336 - regression_loss: 0.1159 - classification_loss: 0.0177
  2/500 [..............................] - ETA: 3:50 - loss: 0.0964 - regression_loss: 0.0868 - classification_loss: 0.0096
  3/500 [..............................] - ETA: 3:50 - loss: 0.0829 - regression_loss: 0.0762 - classification_loss: 0.0067
  4/500 [..............................] - ETA: 3:49 - loss: 0.0673 - regression_loss: 0.0616 - classification_loss: 0.0057
  5/500 [..............................] - ETA: 3:49 - loss: 0.0664 - regression_loss: 0.0610 - classification_loss: 0.0054
  6/500 [..............................] - ETA: 3:48 - loss: 0.0582 - regression_loss: 0.0535 - classification_loss: 0.0047
  7/500 [..............................] - ETA: 3:48 - loss: 0.0538 - regression_loss: 0.0494 - classification_loss: 0.0044
  8/500 [..............................] - ETA: 3:47 - loss: 0.0563 - regression_loss: 0.0519 - classification_loss: 0.0045
  9/500 [..............................] - ETA: 3:47 - loss: 0.0628 - regression_loss: 0.0572 - classification_loss: 0.0056
 10/500 [..............................] - ETA: 3:47 - loss: 0.0594 - regression_loss: 0.0541 - classification_loss: 0.0053
 11/500 [..............................] - ETA: 3:46 - loss: 0.0649 - regression_loss: 0.0585 - classification_loss: 0.0064
 12/500 [..............................] - ETA: 3:46 - loss: 0.0621 - regression_loss: 0.0560 - classification_loss: 0.0061
 13/500 [..............................] - ETA: 3:46 - loss: 0.0608 - regression_loss: 0.0550 - classification_loss: 0.0057
 14/500 [..............................] - ETA: 3:45 - loss: 0.0618 - regression_loss: 0.0561 - classification_loss: 0.0056
 15/500 [..............................] - ETA: 3:45 - loss: 0.0601 - regression_loss: 0.0548 - classification_loss: 0.0054
 16/500 [..............................] - ETA: 3:44 - loss: 0.0654 - regression_loss: 0.0593 - classification_loss: 0.0062
 17/500 [>.............................] - ETA: 3:44 - loss: 0.0637 - regression_loss: 0.0577 - classification_loss: 0.0060
 18/500 [>.............................] - ETA: 3:43 - loss: 0.0637 - regression_loss: 0.0577 - classification_loss: 0.0059
 19/500 [>.............................] - ETA: 3:43 - loss: 0.0708 - regression_loss: 0.0651 - classification_loss: 0.0057
 20/500 [>.............................] - ETA: 3:43 - loss: 0.0692 - regression_loss: 0.0636 - classification_loss: 0.0055
 21/500 [>.............................] - ETA: 3:42 - loss: 0.0670 - regression_loss: 0.0617 - classification_loss: 0.0053
 22/500 [>.............................] - ETA: 3:42 - loss: 0.0685 - regression_loss: 0.0628 - classification_loss: 0.0057
 23/500 [>.............................] - ETA: 3:41 - loss: 0.0673 - regression_loss: 0.0618 - classification_loss: 0.0056
 24/500 [>.............................] - ETA: 3:41 - loss: 0.0648 - regression_loss: 0.0594 - classification_loss: 0.0054
 25/500 [>.............................] - ETA: 3:40 - loss: 0.0661 - regression_loss: 0.0607 - classification_loss: 0.0054
 26/500 [>.............................] - ETA: 3:40 - loss: 0.0695 - regression_loss: 0.0638 - classification_loss: 0.0057
 27/500 [>.............................] - ETA: 3:39 - loss: 0.0772 - regression_loss: 0.0716 - classification_loss: 0.0056
 28/500 [>.............................] - ETA: 3:39 - loss: 0.0749 - regression_loss: 0.0695 - classification_loss: 0.0054
 29/500 [>.............................] - ETA: 3:38 - loss: 0.0731 - regression_loss: 0.0678 - classification_loss: 0.0053
 30/500 [>.............................] - ETA: 3:38 - loss: 0.0726 - regression_loss: 0.0672 - classification_loss: 0.0053
 31/500 [>.............................] - ETA: 3:38 - loss: 0.0708 - regression_loss: 0.0656 - classification_loss: 0.0052
 32/500 [>.............................] - ETA: 3:37 - loss: 0.0710 - regression_loss: 0.0659 - classification_loss: 0.0051
 33/500 [>.............................] - ETA: 3:37 - loss: 0.0746 - regression_loss: 0.0696 - classification_loss: 0.0050
 34/500 [=>............................] - ETA: 3:36 - loss: 0.0753 - regression_loss: 0.0700 - classification_loss: 0.0053
 35/500 [=>............................] - ETA: 3:36 - loss: 0.0752 - regression_loss: 0.0700 - classification_loss: 0.0052
 36/500 [=>............................] - ETA: 3:35 - loss: 0.0767 - regression_loss: 0.0711 - classification_loss: 0.0056
 37/500 [=>............................] - ETA: 3:35 - loss: 0.0759 - regression_loss: 0.0704 - classification_loss: 0.0055
 38/500 [=>............................] - ETA: 3:34 - loss: 0.0752 - regression_loss: 0.0699 - classification_loss: 0.0054
 39/500 [=>............................] - ETA: 3:34 - loss: 0.0746 - regression_loss: 0.0692 - classification_loss: 0.0054
 40/500 [=>............................] - ETA: 3:34 - loss: 0.0728 - regression_loss: 0.0676 - classification_loss: 0.0052
 41/500 [=>............................] - ETA: 3:33 - loss: 0.0721 - regression_loss: 0.0669 - classification_loss: 0.0052
 42/500 [=>............................] - ETA: 3:33 - loss: 0.0732 - regression_loss: 0.0678 - classification_loss: 0.0054
 43/500 [=>............................] - ETA: 3:32 - loss: 0.0733 - regression_loss: 0.0679 - classification_loss: 0.0054
 44/500 [=>............................] - ETA: 3:32 - loss: 0.0737 - regression_loss: 0.0684 - classification_loss: 0.0053
 45/500 [=>............................] - ETA: 3:31 - loss: 0.0731 - regression_loss: 0.0679 - classification_loss: 0.0052
 46/500 [=>............................] - ETA: 3:31 - loss: 0.0724 - regression_loss: 0.0673 - classification_loss: 0.0051
 47/500 [=>............................] - ETA: 3:30 - loss: 0.0714 - regression_loss: 0.0664 - classification_loss: 0.0051
 48/500 [=>............................] - ETA: 3:30 - loss: 0.0725 - regression_loss: 0.0672 - classification_loss: 0.0052
 49/500 [=>............................] - ETA: 3:29 - loss: 0.0714 - regression_loss: 0.0663 - classification_loss: 0.0052
 50/500 [==>...........................] - ETA: 3:29 - loss: 0.0712 - regression_loss: 0.0661 - classification_loss: 0.0052
 51/500 [==>...........................] - ETA: 3:28 - loss: 0.0700 - regression_loss: 0.0649 - classification_loss: 0.0051
 52/500 [==>...........................] - ETA: 3:28 - loss: 0.0711 - regression_loss: 0.0658 - classification_loss: 0.0053
 53/500 [==>...........................] - ETA: 3:27 - loss: 0.0704 - regression_loss: 0.0651 - classification_loss: 0.0053
 54/500 [==>...........................] - ETA: 3:27 - loss: 0.0707 - regression_loss: 0.0654 - classification_loss: 0.0053
 55/500 [==>...........................] - ETA: 3:27 - loss: 0.0703 - regression_loss: 0.0651 - classification_loss: 0.0052
 56/500 [==>...........................] - ETA: 3:26 - loss: 0.0698 - regression_loss: 0.0647 - classification_loss: 0.0051
 57/500 [==>...........................] - ETA: 3:26 - loss: 0.0694 - regression_loss: 0.0644 - classification_loss: 0.0050
 58/500 [==>...........................] - ETA: 3:25 - loss: 0.0710 - regression_loss: 0.0658 - classification_loss: 0.0052
 59/500 [==>...........................] - ETA: 3:25 - loss: 0.0712 - regression_loss: 0.0660 - classification_loss: 0.0052
 60/500 [==>...........................] - ETA: 3:24 - loss: 0.0708 - regression_loss: 0.0656 - classification_loss: 0.0051
 61/500 [==>...........................] - ETA: 3:24 - loss: 0.0700 - regression_loss: 0.0649 - classification_loss: 0.0051
 62/500 [==>...........................] - ETA: 3:23 - loss: 0.0695 - regression_loss: 0.0645 - classification_loss: 0.0050
 63/500 [==>...........................] - ETA: 3:23 - loss: 0.0704 - regression_loss: 0.0652 - classification_loss: 0.0052
 64/500 [==>...........................] - ETA: 3:22 - loss: 0.0698 - regression_loss: 0.0647 - classification_loss: 0.0051
 65/500 [==>...........................] - ETA: 3:22 - loss: 0.0704 - regression_loss: 0.0653 - classification_loss: 0.0051
 66/500 [==>...........................] - ETA: 3:22 - loss: 0.0699 - regression_loss: 0.0649 - classification_loss: 0.0051
 67/500 [===>..........................] - ETA: 3:21 - loss: 0.0702 - regression_loss: 0.0652 - classification_loss: 0.0051
 68/500 [===>..........................] - ETA: 3:21 - loss: 0.0693 - regression_loss: 0.0643 - classification_loss: 0.0050
 69/500 [===>..........................] - ETA: 3:20 - loss: 0.0689 - regression_loss: 0.0640 - classification_loss: 0.0050
 70/500 [===>..........................] - ETA: 3:20 - loss: 0.0697 - regression_loss: 0.0646 - classification_loss: 0.0051
 71/500 [===>..........................] - ETA: 3:19 - loss: 0.0706 - regression_loss: 0.0653 - classification_loss: 0.0053
 72/500 [===>..........................] - ETA: 3:19 - loss: 0.0700 - regression_loss: 0.0648 - classification_loss: 0.0052
 73/500 [===>..........................] - ETA: 3:18 - loss: 0.0705 - regression_loss: 0.0653 - classification_loss: 0.0052
 74/500 [===>..........................] - ETA: 3:18 - loss: 0.0701 - regression_loss: 0.0650 - classification_loss: 0.0051
 75/500 [===>..........................] - ETA: 3:17 - loss: 0.0709 - regression_loss: 0.0658 - classification_loss: 0.0051
 76/500 [===>..........................] - ETA: 3:17 - loss: 0.0702 - regression_loss: 0.0651 - classification_loss: 0.0051
 77/500 [===>..........................] - ETA: 3:16 - loss: 0.0703 - regression_loss: 0.0653 - classification_loss: 0.0050
 78/500 [===>..........................] - ETA: 3:16 - loss: 0.0714 - regression_loss: 0.0662 - classification_loss: 0.0052
 79/500 [===>..........................] - ETA: 3:15 - loss: 0.0707 - regression_loss: 0.0656 - classification_loss: 0.0051
 80/500 [===>..........................] - ETA: 3:15 - loss: 0.0709 - regression_loss: 0.0658 - classification_loss: 0.0051
 81/500 [===>..........................] - ETA: 3:14 - loss: 0.0720 - regression_loss: 0.0668 - classification_loss: 0.0052
 82/500 [===>..........................] - ETA: 3:14 - loss: 0.0721 - regression_loss: 0.0669 - classification_loss: 0.0052
 83/500 [===>..........................] - ETA: 3:14 - loss: 0.0729 - regression_loss: 0.0677 - classification_loss: 0.0052
 84/500 [====>.........................] - ETA: 3:13 - loss: 0.0723 - regression_loss: 0.0672 - classification_loss: 0.0051
 85/500 [====>.........................] - ETA: 3:13 - loss: 0.0730 - regression_loss: 0.0679 - classification_loss: 0.0051
 86/500 [====>.........................] - ETA: 3:12 - loss: 0.0725 - regression_loss: 0.0674 - classification_loss: 0.0051
 87/500 [====>.........................] - ETA: 3:12 - loss: 0.0733 - regression_loss: 0.0682 - classification_loss: 0.0051
 88/500 [====>.........................] - ETA: 3:11 - loss: 0.0730 - regression_loss: 0.0679 - classification_loss: 0.0051
 89/500 [====>.........................] - ETA: 3:11 - loss: 0.0745 - regression_loss: 0.0694 - classification_loss: 0.0052
 90/500 [====>.........................] - ETA: 3:10 - loss: 0.0740 - regression_loss: 0.0689 - classification_loss: 0.0051
 91/500 [====>.........................] - ETA: 3:10 - loss: 0.0743 - regression_loss: 0.0692 - classification_loss: 0.0051
 92/500 [====>.........................] - ETA: 3:09 - loss: 0.0756 - regression_loss: 0.0705 - classification_loss: 0.0051
 93/500 [====>.........................] - ETA: 3:09 - loss: 0.0763 - regression_loss: 0.0712 - classification_loss: 0.0051
 94/500 [====>.........................] - ETA: 3:08 - loss: 0.0770 - regression_loss: 0.0718 - classification_loss: 0.0052
 95/500 [====>.........................] - ETA: 3:08 - loss: 0.0769 - regression_loss: 0.0717 - classification_loss: 0.0051
 96/500 [====>.........................] - ETA: 3:07 - loss: 0.0764 - regression_loss: 0.0713 - classification_loss: 0.0051
 97/500 [====>.........................] - ETA: 3:07 - loss: 0.0760 - regression_loss: 0.0709 - classification_loss: 0.0051
 98/500 [====>.........................] - ETA: 3:06 - loss: 0.0760 - regression_loss: 0.0709 - classification_loss: 0.0051
 99/500 [====>.........................] - ETA: 3:06 - loss: 0.0756 - regression_loss: 0.0706 - classification_loss: 0.0050
100/500 [=====>........................] - ETA: 3:05 - loss: 0.0777 - regression_loss: 0.0726 - classification_loss: 0.0051
101/500 [=====>........................] - ETA: 3:05 - loss: 0.0794 - regression_loss: 0.0743 - classification_loss: 0.0051
102/500 [=====>........................] - ETA: 3:04 - loss: 0.0798 - regression_loss: 0.0747 - classification_loss: 0.0051
103/500 [=====>........................] - ETA: 3:04 - loss: 0.0812 - regression_loss: 0.0761 - classification_loss: 0.0051
104/500 [=====>........................] - ETA: 3:04 - loss: 0.0811 - regression_loss: 0.0760 - classification_loss: 0.0051
105/500 [=====>........................] - ETA: 3:03 - loss: 0.0806 - regression_loss: 0.0755 - classification_loss: 0.0051
106/500 [=====>........................] - ETA: 3:03 - loss: 0.0810 - regression_loss: 0.0758 - classification_loss: 0.0052
107/500 [=====>........................] - ETA: 3:02 - loss: 0.0809 - regression_loss: 0.0757 - classification_loss: 0.0052
108/500 [=====>........................] - ETA: 3:02 - loss: 0.0805 - regression_loss: 0.0754 - classification_loss: 0.0051
109/500 [=====>........................] - ETA: 3:01 - loss: 0.0799 - regression_loss: 0.0747 - classification_loss: 0.0051
110/500 [=====>........................] - ETA: 3:01 - loss: 0.0806 - regression_loss: 0.0755 - classification_loss: 0.0051
111/500 [=====>........................] - ETA: 3:00 - loss: 0.0808 - regression_loss: 0.0757 - classification_loss: 0.0051
112/500 [=====>........................] - ETA: 3:00 - loss: 0.0810 - regression_loss: 0.0759 - classification_loss: 0.0051
113/500 [=====>........................] - ETA: 2:59 - loss: 0.0818 - regression_loss: 0.0766 - classification_loss: 0.0052
114/500 [=====>........................] - ETA: 2:59 - loss: 0.0818 - regression_loss: 0.0766 - classification_loss: 0.0052
115/500 [=====>........................] - ETA: 2:58 - loss: 0.0820 - regression_loss: 0.0769 - classification_loss: 0.0051
116/500 [=====>........................] - ETA: 2:58 - loss: 0.0821 - regression_loss: 0.0770 - classification_loss: 0.0051
117/500 [======>.......................] - ETA: 2:57 - loss: 0.0816 - regression_loss: 0.0765 - classification_loss: 0.0051
118/500 [======>.......................] - ETA: 2:57 - loss: 0.0816 - regression_loss: 0.0765 - classification_loss: 0.0051
119/500 [======>.......................] - ETA: 2:57 - loss: 0.0818 - regression_loss: 0.0766 - classification_loss: 0.0052
120/500 [======>.......................] - ETA: 2:56 - loss: 0.0815 - regression_loss: 0.0764 - classification_loss: 0.0051
121/500 [======>.......................] - ETA: 2:56 - loss: 0.0819 - regression_loss: 0.0767 - classification_loss: 0.0051
122/500 [======>.......................] - ETA: 2:55 - loss: 0.0819 - regression_loss: 0.0768 - classification_loss: 0.0051
123/500 [======>.......................] - ETA: 2:55 - loss: 0.0813 - regression_loss: 0.0762 - classification_loss: 0.0051
124/500 [======>.......................] - ETA: 2:54 - loss: 0.0810 - regression_loss: 0.0760 - classification_loss: 0.0050
125/500 [======>.......................] - ETA: 2:54 - loss: 0.0815 - regression_loss: 0.0763 - classification_loss: 0.0051
126/500 [======>.......................] - ETA: 2:53 - loss: 0.0812 - regression_loss: 0.0761 - classification_loss: 0.0051
127/500 [======>.......................] - ETA: 2:53 - loss: 0.0807 - regression_loss: 0.0757 - classification_loss: 0.0051
128/500 [======>.......................] - ETA: 2:52 - loss: 0.0806 - regression_loss: 0.0755 - classification_loss: 0.0051
129/500 [======>.......................] - ETA: 2:52 - loss: 0.0808 - regression_loss: 0.0757 - classification_loss: 0.0052
130/500 [======>.......................] - ETA: 2:51 - loss: 0.0804 - regression_loss: 0.0753 - classification_loss: 0.0051
131/500 [======>.......................] - ETA: 2:51 - loss: 0.0805 - regression_loss: 0.0753 - classification_loss: 0.0052
132/500 [======>.......................] - ETA: 2:51 - loss: 0.0800 - regression_loss: 0.0748 - classification_loss: 0.0052
133/500 [======>.......................] - ETA: 2:50 - loss: 0.0800 - regression_loss: 0.0749 - classification_loss: 0.0051
134/500 [=======>......................] - ETA: 2:50 - loss: 0.0796 - regression_loss: 0.0744 - classification_loss: 0.0051
135/500 [=======>......................] - ETA: 2:49 - loss: 0.0794 - regression_loss: 0.0743 - classification_loss: 0.0051
136/500 [=======>......................] - ETA: 2:49 - loss: 0.0791 - regression_loss: 0.0740 - classification_loss: 0.0051
137/500 [=======>......................] - ETA: 2:48 - loss: 0.0786 - regression_loss: 0.0735 - classification_loss: 0.0051
138/500 [=======>......................] - ETA: 2:48 - loss: 0.0789 - regression_loss: 0.0737 - classification_loss: 0.0051
139/500 [=======>......................] - ETA: 2:47 - loss: 0.0788 - regression_loss: 0.0736 - classification_loss: 0.0051
140/500 [=======>......................] - ETA: 2:47 - loss: 0.0787 - regression_loss: 0.0736 - classification_loss: 0.0051
141/500 [=======>......................] - ETA: 2:46 - loss: 0.0787 - regression_loss: 0.0736 - classification_loss: 0.0051
142/500 [=======>......................] - ETA: 2:46 - loss: 0.0783 - regression_loss: 0.0732 - classification_loss: 0.0051
143/500 [=======>......................] - ETA: 2:45 - loss: 0.0782 - regression_loss: 0.0732 - classification_loss: 0.0050
144/500 [=======>......................] - ETA: 2:45 - loss: 0.0778 - regression_loss: 0.0728 - classification_loss: 0.0050
145/500 [=======>......................] - ETA: 2:45 - loss: 0.0781 - regression_loss: 0.0730 - classification_loss: 0.0051
146/500 [=======>......................] - ETA: 2:44 - loss: 0.0782 - regression_loss: 0.0731 - classification_loss: 0.0051
147/500 [=======>......................] - ETA: 2:44 - loss: 0.0783 - regression_loss: 0.0732 - classification_loss: 0.0052
148/500 [=======>......................] - ETA: 2:43 - loss: 0.0783 - regression_loss: 0.0732 - classification_loss: 0.0051
149/500 [=======>......................] - ETA: 2:43 - loss: 0.0781 - regression_loss: 0.0729 - classification_loss: 0.0051
150/500 [========>.....................] - ETA: 2:42 - loss: 0.0781 - regression_loss: 0.0730 - classification_loss: 0.0051
151/500 [========>.....................] - ETA: 2:42 - loss: 0.0780 - regression_loss: 0.0729 - classification_loss: 0.0051
152/500 [========>.....................] - ETA: 2:41 - loss: 0.0783 - regression_loss: 0.0731 - classification_loss: 0.0052
153/500 [========>.....................] - ETA: 2:41 - loss: 0.0778 - regression_loss: 0.0727 - classification_loss: 0.0051
154/500 [========>.....................] - ETA: 2:40 - loss: 0.0774 - regression_loss: 0.0723 - classification_loss: 0.0051
155/500 [========>.....................] - ETA: 2:40 - loss: 0.0770 - regression_loss: 0.0719 - classification_loss: 0.0051
156/500 [========>.....................] - ETA: 2:39 - loss: 0.0769 - regression_loss: 0.0718 - classification_loss: 0.0051
157/500 [========>.....................] - ETA: 2:39 - loss: 0.0771 - regression_loss: 0.0719 - classification_loss: 0.0051
158/500 [========>.....................] - ETA: 2:38 - loss: 0.0768 - regression_loss: 0.0717 - classification_loss: 0.0051
159/500 [========>.....................] - ETA: 2:38 - loss: 0.0768 - regression_loss: 0.0718 - classification_loss: 0.0051
160/500 [========>.....................] - ETA: 2:38 - loss: 0.0766 - regression_loss: 0.0715 - classification_loss: 0.0051
161/500 [========>.....................] - ETA: 2:37 - loss: 0.0763 - regression_loss: 0.0712 - classification_loss: 0.0050
162/500 [========>.....................] - ETA: 2:37 - loss: 0.0759 - regression_loss: 0.0708 - classification_loss: 0.0050
163/500 [========>.....................] - ETA: 2:36 - loss: 0.0759 - regression_loss: 0.0709 - classification_loss: 0.0050
164/500 [========>.....................] - ETA: 2:36 - loss: 0.0756 - regression_loss: 0.0706 - classification_loss: 0.0050
165/500 [========>.....................] - ETA: 2:35 - loss: 0.0760 - regression_loss: 0.0709 - classification_loss: 0.0051
166/500 [========>.....................] - ETA: 2:35 - loss: 0.0757 - regression_loss: 0.0707 - classification_loss: 0.0050
167/500 [=========>....................] - ETA: 2:34 - loss: 0.0756 - regression_loss: 0.0706 - classification_loss: 0.0050
168/500 [=========>....................] - ETA: 2:34 - loss: 0.0759 - regression_loss: 0.0708 - classification_loss: 0.0051
169/500 [=========>....................] - ETA: 2:33 - loss: 0.0757 - regression_loss: 0.0706 - classification_loss: 0.0051
170/500 [=========>....................] - ETA: 2:33 - loss: 0.0754 - regression_loss: 0.0704 - classification_loss: 0.0050
171/500 [=========>....................] - ETA: 2:32 - loss: 0.0756 - regression_loss: 0.0705 - classification_loss: 0.0051
172/500 [=========>....................] - ETA: 2:32 - loss: 0.0753 - regression_loss: 0.0702 - classification_loss: 0.0051
173/500 [=========>....................] - ETA: 2:32 - loss: 0.0751 - regression_loss: 0.0700 - classification_loss: 0.0051
174/500 [=========>....................] - ETA: 2:31 - loss: 0.0747 - regression_loss: 0.0697 - classification_loss: 0.0050
175/500 [=========>....................] - ETA: 2:31 - loss: 0.0747 - regression_loss: 0.0697 - classification_loss: 0.0050
176/500 [=========>....................] - ETA: 2:30 - loss: 0.0746 - regression_loss: 0.0696 - classification_loss: 0.0050
177/500 [=========>....................] - ETA: 2:30 - loss: 0.0745 - regression_loss: 0.0694 - classification_loss: 0.0050
178/500 [=========>....................] - ETA: 2:29 - loss: 0.0743 - regression_loss: 0.0693 - classification_loss: 0.0050
179/500 [=========>....................] - ETA: 2:29 - loss: 0.0746 - regression_loss: 0.0696 - classification_loss: 0.0051
180/500 [=========>....................] - ETA: 2:28 - loss: 0.0743 - regression_loss: 0.0693 - classification_loss: 0.0050
181/500 [=========>....................] - ETA: 2:28 - loss: 0.0741 - regression_loss: 0.0691 - classification_loss: 0.0050
182/500 [=========>....................] - ETA: 2:27 - loss: 0.0738 - regression_loss: 0.0688 - classification_loss: 0.0050
183/500 [=========>....................] - ETA: 2:27 - loss: 0.0736 - regression_loss: 0.0686 - classification_loss: 0.0050
184/500 [==========>...................] - ETA: 2:26 - loss: 0.0738 - regression_loss: 0.0689 - classification_loss: 0.0050
185/500 [==========>...................] - ETA: 2:26 - loss: 0.0741 - regression_loss: 0.0691 - classification_loss: 0.0050
186/500 [==========>...................] - ETA: 2:25 - loss: 0.0738 - regression_loss: 0.0688 - classification_loss: 0.0050
187/500 [==========>...................] - ETA: 2:25 - loss: 0.0736 - regression_loss: 0.0686 - classification_loss: 0.0050
188/500 [==========>...................] - ETA: 2:25 - loss: 0.0740 - regression_loss: 0.0690 - classification_loss: 0.0050
189/500 [==========>...................] - ETA: 2:24 - loss: 0.0740 - regression_loss: 0.0690 - classification_loss: 0.0050
190/500 [==========>...................] - ETA: 2:24 - loss: 0.0738 - regression_loss: 0.0688 - classification_loss: 0.0050
191/500 [==========>...................] - ETA: 2:23 - loss: 0.0734 - regression_loss: 0.0684 - classification_loss: 0.0050
192/500 [==========>...................] - ETA: 2:23 - loss: 0.0734 - regression_loss: 0.0684 - classification_loss: 0.0050
193/500 [==========>...................] - ETA: 2:22 - loss: 0.0736 - regression_loss: 0.0685 - classification_loss: 0.0050
194/500 [==========>...................] - ETA: 2:22 - loss: 0.0739 - regression_loss: 0.0688 - classification_loss: 0.0050
195/500 [==========>...................] - ETA: 2:21 - loss: 0.0737 - regression_loss: 0.0687 - classification_loss: 0.0050
196/500 [==========>...................] - ETA: 2:21 - loss: 0.0739 - regression_loss: 0.0688 - classification_loss: 0.0051
197/500 [==========>...................] - ETA: 2:20 - loss: 0.0736 - regression_loss: 0.0686 - classification_loss: 0.0050
198/500 [==========>...................] - ETA: 2:20 - loss: 0.0734 - regression_loss: 0.0684 - classification_loss: 0.0050
199/500 [==========>...................] - ETA: 2:19 - loss: 0.0732 - regression_loss: 0.0682 - classification_loss: 0.0050
200/500 [===========>..................] - ETA: 2:19 - loss: 0.0732 - regression_loss: 0.0682 - classification_loss: 0.0050
201/500 [===========>..................] - ETA: 2:18 - loss: 0.0734 - regression_loss: 0.0683 - classification_loss: 0.0051
202/500 [===========>..................] - ETA: 2:18 - loss: 0.0732 - regression_loss: 0.0681 - classification_loss: 0.0050
203/500 [===========>..................] - ETA: 2:18 - loss: 0.0729 - regression_loss: 0.0678 - classification_loss: 0.0050
204/500 [===========>..................] - ETA: 2:17 - loss: 0.0726 - regression_loss: 0.0676 - classification_loss: 0.0050
205/500 [===========>..................] - ETA: 2:17 - loss: 0.0728 - regression_loss: 0.0678 - classification_loss: 0.0050
206/500 [===========>..................] - ETA: 2:16 - loss: 0.0727 - regression_loss: 0.0678 - classification_loss: 0.0050
207/500 [===========>..................] - ETA: 2:16 - loss: 0.0730 - regression_loss: 0.0679 - classification_loss: 0.0050
208/500 [===========>..................] - ETA: 2:15 - loss: 0.0729 - regression_loss: 0.0679 - classification_loss: 0.0050
209/500 [===========>..................] - ETA: 2:15 - loss: 0.0729 - regression_loss: 0.0679 - classification_loss: 0.0050
210/500 [===========>..................] - ETA: 2:14 - loss: 0.0727 - regression_loss: 0.0677 - classification_loss: 0.0050
211/500 [===========>..................] - ETA: 2:14 - loss: 0.0724 - regression_loss: 0.0675 - classification_loss: 0.0050
212/500 [===========>..................] - ETA: 2:13 - loss: 0.0724 - regression_loss: 0.0674 - classification_loss: 0.0050
213/500 [===========>..................] - ETA: 2:13 - loss: 0.0726 - regression_loss: 0.0676 - classification_loss: 0.0050
214/500 [===========>..................] - ETA: 2:12 - loss: 0.0723 - regression_loss: 0.0673 - classification_loss: 0.0050
215/500 [===========>..................] - ETA: 2:12 - loss: 0.0723 - regression_loss: 0.0673 - classification_loss: 0.0050
216/500 [===========>..................] - ETA: 2:11 - loss: 0.0721 - regression_loss: 0.0671 - classification_loss: 0.0050
217/500 [============>.................] - ETA: 2:11 - loss: 0.0719 - regression_loss: 0.0670 - classification_loss: 0.0049
218/500 [============>.................] - ETA: 2:11 - loss: 0.0721 - regression_loss: 0.0671 - classification_loss: 0.0050
219/500 [============>.................] - ETA: 2:10 - loss: 0.0721 - regression_loss: 0.0672 - classification_loss: 0.0050
220/500 [============>.................] - ETA: 2:10 - loss: 0.0720 - regression_loss: 0.0670 - classification_loss: 0.0050
221/500 [============>.................] - ETA: 2:09 - loss: 0.0722 - regression_loss: 0.0672 - classification_loss: 0.0050
222/500 [============>.................] - ETA: 2:09 - loss: 0.0719 - regression_loss: 0.0669 - classification_loss: 0.0050
223/500 [============>.................] - ETA: 2:08 - loss: 0.0718 - regression_loss: 0.0669 - classification_loss: 0.0050
224/500 [============>.................] - ETA: 2:08 - loss: 0.0716 - regression_loss: 0.0667 - classification_loss: 0.0050
225/500 [============>.................] - ETA: 2:07 - loss: 0.0723 - regression_loss: 0.0673 - classification_loss: 0.0049
226/500 [============>.................] - ETA: 2:07 - loss: 0.0728 - regression_loss: 0.0678 - classification_loss: 0.0049
227/500 [============>.................] - ETA: 2:06 - loss: 0.0727 - regression_loss: 0.0678 - classification_loss: 0.0049
228/500 [============>.................] - ETA: 2:06 - loss: 0.0725 - regression_loss: 0.0676 - classification_loss: 0.0049
229/500 [============>.................] - ETA: 2:05 - loss: 0.0725 - regression_loss: 0.0676 - classification_loss: 0.0049
230/500 [============>.................] - ETA: 2:05 - loss: 0.0726 - regression_loss: 0.0677 - classification_loss: 0.0049
231/500 [============>.................] - ETA: 2:04 - loss: 0.0724 - regression_loss: 0.0675 - classification_loss: 0.0049
232/500 [============>.................] - ETA: 2:04 - loss: 0.0722 - regression_loss: 0.0673 - classification_loss: 0.0049
233/500 [============>.................] - ETA: 2:04 - loss: 0.0723 - regression_loss: 0.0674 - classification_loss: 0.0049
234/500 [=============>................] - ETA: 2:03 - loss: 0.0724 - regression_loss: 0.0675 - classification_loss: 0.0050
235/500 [=============>................] - ETA: 2:03 - loss: 0.0724 - regression_loss: 0.0674 - classification_loss: 0.0049
236/500 [=============>................] - ETA: 2:02 - loss: 0.0723 - regression_loss: 0.0674 - classification_loss: 0.0049
237/500 [=============>................] - ETA: 2:02 - loss: 0.0722 - regression_loss: 0.0673 - classification_loss: 0.0049
238/500 [=============>................] - ETA: 2:01 - loss: 0.0722 - regression_loss: 0.0673 - classification_loss: 0.0050
239/500 [=============>................] - ETA: 2:01 - loss: 0.0723 - regression_loss: 0.0674 - classification_loss: 0.0050
240/500 [=============>................] - ETA: 2:00 - loss: 0.0721 - regression_loss: 0.0672 - classification_loss: 0.0049
241/500 [=============>................] - ETA: 2:00 - loss: 0.0720 - regression_loss: 0.0670 - classification_loss: 0.0049
242/500 [=============>................] - ETA: 1:59 - loss: 0.0720 - regression_loss: 0.0671 - classification_loss: 0.0049
243/500 [=============>................] - ETA: 1:59 - loss: 0.0723 - regression_loss: 0.0673 - classification_loss: 0.0050
244/500 [=============>................] - ETA: 1:58 - loss: 0.0723 - regression_loss: 0.0674 - classification_loss: 0.0049
245/500 [=============>................] - ETA: 1:58 - loss: 0.0720 - regression_loss: 0.0671 - classification_loss: 0.0049
246/500 [=============>................] - ETA: 1:58 - loss: 0.0718 - regression_loss: 0.0669 - classification_loss: 0.0049
247/500 [=============>................] - ETA: 1:57 - loss: 0.0723 - regression_loss: 0.0674 - classification_loss: 0.0050
248/500 [=============>................] - ETA: 1:57 - loss: 0.0723 - regression_loss: 0.0673 - classification_loss: 0.0050
249/500 [=============>................] - ETA: 1:56 - loss: 0.0722 - regression_loss: 0.0672 - classification_loss: 0.0049
250/500 [==============>...............] - ETA: 1:56 - loss: 0.0725 - regression_loss: 0.0676 - classification_loss: 0.0049
251/500 [==============>...............] - ETA: 1:55 - loss: 0.0727 - regression_loss: 0.0678 - classification_loss: 0.0049
252/500 [==============>...............] - ETA: 1:55 - loss: 0.0729 - regression_loss: 0.0680 - classification_loss: 0.0050
253/500 [==============>...............] - ETA: 1:54 - loss: 0.0727 - regression_loss: 0.0677 - classification_loss: 0.0049
254/500 [==============>...............] - ETA: 1:54 - loss: 0.0727 - regression_loss: 0.0677 - classification_loss: 0.0049
255/500 [==============>...............] - ETA: 1:53 - loss: 0.0726 - regression_loss: 0.0677 - classification_loss: 0.0049
256/500 [==============>...............] - ETA: 1:53 - loss: 0.0727 - regression_loss: 0.0678 - classification_loss: 0.0049
257/500 [==============>...............] - ETA: 1:52 - loss: 0.0728 - regression_loss: 0.0679 - classification_loss: 0.0049
258/500 [==============>...............] - ETA: 1:52 - loss: 0.0726 - regression_loss: 0.0677 - classification_loss: 0.0049
259/500 [==============>...............] - ETA: 1:52 - loss: 0.0725 - regression_loss: 0.0676 - classification_loss: 0.0049
260/500 [==============>...............] - ETA: 1:51 - loss: 0.0726 - regression_loss: 0.0677 - classification_loss: 0.0049
261/500 [==============>...............] - ETA: 1:51 - loss: 0.0725 - regression_loss: 0.0676 - classification_loss: 0.0049
262/500 [==============>...............] - ETA: 1:50 - loss: 0.0723 - regression_loss: 0.0674 - classification_loss: 0.0049
263/500 [==============>...............] - ETA: 1:50 - loss: 0.0725 - regression_loss: 0.0675 - classification_loss: 0.0049
264/500 [==============>...............] - ETA: 1:49 - loss: 0.0722 - regression_loss: 0.0673 - classification_loss: 0.0049
265/500 [==============>...............] - ETA: 1:49 - loss: 0.0723 - regression_loss: 0.0673 - classification_loss: 0.0049
266/500 [==============>...............] - ETA: 1:48 - loss: 0.0722 - regression_loss: 0.0673 - classification_loss: 0.0049
267/500 [===============>..............] - ETA: 1:48 - loss: 0.0721 - regression_loss: 0.0672 - classification_loss: 0.0049
268/500 [===============>..............] - ETA: 1:47 - loss: 0.0719 - regression_loss: 0.0670 - classification_loss: 0.0049
269/500 [===============>..............] - ETA: 1:47 - loss: 0.0718 - regression_loss: 0.0670 - classification_loss: 0.0049
270/500 [===============>..............] - ETA: 1:46 - loss: 0.0721 - regression_loss: 0.0672 - classification_loss: 0.0049
271/500 [===============>..............] - ETA: 1:46 - loss: 0.0720 - regression_loss: 0.0671 - classification_loss: 0.0049
272/500 [===============>..............] - ETA: 1:46 - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0049
273/500 [===============>..............] - ETA: 1:45 - loss: 0.0723 - regression_loss: 0.0674 - classification_loss: 0.0049
274/500 [===============>..............] - ETA: 1:45 - loss: 0.0725 - regression_loss: 0.0676 - classification_loss: 0.0049
275/500 [===============>..............] - ETA: 1:44 - loss: 0.0725 - regression_loss: 0.0676 - classification_loss: 0.0049
276/500 [===============>..............] - ETA: 1:44 - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0049
277/500 [===============>..............] - ETA: 1:43 - loss: 0.0724 - regression_loss: 0.0675 - classification_loss: 0.0049
278/500 [===============>..............] - ETA: 1:43 - loss: 0.0724 - regression_loss: 0.0675 - classification_loss: 0.0049
279/500 [===============>..............] - ETA: 1:42 - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
280/500 [===============>..............] - ETA: 1:42 - loss: 0.0725 - regression_loss: 0.0676 - classification_loss: 0.0049
281/500 [===============>..............] - ETA: 1:41 - loss: 0.0724 - regression_loss: 0.0675 - classification_loss: 0.0049
282/500 [===============>..............] - ETA: 1:41 - loss: 0.0723 - regression_loss: 0.0674 - classification_loss: 0.0049
283/500 [===============>..............] - ETA: 1:40 - loss: 0.0721 - regression_loss: 0.0673 - classification_loss: 0.0049
284/500 [================>.............] - ETA: 1:40 - loss: 0.0721 - regression_loss: 0.0672 - classification_loss: 0.0048
285/500 [================>.............] - ETA: 1:39 - loss: 0.0722 - regression_loss: 0.0673 - classification_loss: 0.0049
286/500 [================>.............] - ETA: 1:39 - loss: 0.0722 - regression_loss: 0.0673 - classification_loss: 0.0049
287/500 [================>.............] - ETA: 1:39 - loss: 0.0720 - regression_loss: 0.0671 - classification_loss: 0.0049
288/500 [================>.............] - ETA: 1:38 - loss: 0.0718 - regression_loss: 0.0669 - classification_loss: 0.0049
289/500 [================>.............] - ETA: 1:38 - loss: 0.0719 - regression_loss: 0.0670 - classification_loss: 0.0049
290/500 [================>.............] - ETA: 1:37 - loss: 0.0717 - regression_loss: 0.0668 - classification_loss: 0.0049
291/500 [================>.............] - ETA: 1:37 - loss: 0.0716 - regression_loss: 0.0668 - classification_loss: 0.0049
292/500 [================>.............] - ETA: 1:36 - loss: 0.0717 - regression_loss: 0.0668 - classification_loss: 0.0049
293/500 [================>.............] - ETA: 1:36 - loss: 0.0717 - regression_loss: 0.0668 - classification_loss: 0.0049
294/500 [================>.............] - ETA: 1:35 - loss: 0.0718 - regression_loss: 0.0669 - classification_loss: 0.0049
295/500 [================>.............] - ETA: 1:35 - loss: 0.0716 - regression_loss: 0.0667 - classification_loss: 0.0049
296/500 [================>.............] - ETA: 1:34 - loss: 0.0717 - regression_loss: 0.0668 - classification_loss: 0.0049
297/500 [================>.............] - ETA: 1:34 - loss: 0.0715 - regression_loss: 0.0666 - classification_loss: 0.0049
298/500 [================>.............] - ETA: 1:33 - loss: 0.0718 - regression_loss: 0.0669 - classification_loss: 0.0049
299/500 [================>.............] - ETA: 1:33 - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0049
300/500 [=================>............] - ETA: 1:32 - loss: 0.0716 - regression_loss: 0.0667 - classification_loss: 0.0049
301/500 [=================>............] - ETA: 1:32 - loss: 0.0714 - regression_loss: 0.0665 - classification_loss: 0.0048
302/500 [=================>............] - ETA: 1:32 - loss: 0.0714 - regression_loss: 0.0665 - classification_loss: 0.0048
303/500 [=================>............] - ETA: 1:31 - loss: 0.0715 - regression_loss: 0.0666 - classification_loss: 0.0049
304/500 [=================>............] - ETA: 1:31 - loss: 0.0716 - regression_loss: 0.0667 - classification_loss: 0.0049
305/500 [=================>............] - ETA: 1:30 - loss: 0.0716 - regression_loss: 0.0667 - classification_loss: 0.0049
306/500 [=================>............] - ETA: 1:30 - loss: 0.0716 - regression_loss: 0.0667 - classification_loss: 0.0048
307/500 [=================>............] - ETA: 1:29 - loss: 0.0718 - regression_loss: 0.0669 - classification_loss: 0.0049
308/500 [=================>............] - ETA: 1:29 - loss: 0.0716 - regression_loss: 0.0667 - classification_loss: 0.0049
309/500 [=================>............] - ETA: 1:28 - loss: 0.0714 - regression_loss: 0.0666 - classification_loss: 0.0049
310/500 [=================>............] - ETA: 1:28 - loss: 0.0713 - regression_loss: 0.0665 - classification_loss: 0.0049
311/500 [=================>............] - ETA: 1:27 - loss: 0.0712 - regression_loss: 0.0664 - classification_loss: 0.0048
312/500 [=================>............] - ETA: 1:27 - loss: 0.0715 - regression_loss: 0.0666 - classification_loss: 0.0048
313/500 [=================>............] - ETA: 1:26 - loss: 0.0718 - regression_loss: 0.0669 - classification_loss: 0.0049
314/500 [=================>............] - ETA: 1:26 - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0049
315/500 [=================>............] - ETA: 1:25 - loss: 0.0718 - regression_loss: 0.0669 - classification_loss: 0.0048
316/500 [=================>............] - ETA: 1:25 - loss: 0.0716 - regression_loss: 0.0668 - classification_loss: 0.0048
317/500 [==================>...........] - ETA: 1:25 - loss: 0.0715 - regression_loss: 0.0666 - classification_loss: 0.0048
318/500 [==================>...........] - ETA: 1:24 - loss: 0.0717 - regression_loss: 0.0668 - classification_loss: 0.0048
319/500 [==================>...........] - ETA: 1:24 - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0048
320/500 [==================>...........] - ETA: 1:23 - loss: 0.0716 - regression_loss: 0.0668 - classification_loss: 0.0048
321/500 [==================>...........] - ETA: 1:23 - loss: 0.0715 - regression_loss: 0.0667 - classification_loss: 0.0048
322/500 [==================>...........] - ETA: 1:22 - loss: 0.0713 - regression_loss: 0.0665 - classification_loss: 0.0048
323/500 [==================>...........] - ETA: 1:22 - loss: 0.0714 - regression_loss: 0.0666 - classification_loss: 0.0048
324/500 [==================>...........] - ETA: 1:21 - loss: 0.0713 - regression_loss: 0.0665 - classification_loss: 0.0048
325/500 [==================>...........] - ETA: 1:21 - loss: 0.0714 - regression_loss: 0.0666 - classification_loss: 0.0048
326/500 [==================>...........] - ETA: 1:20 - loss: 0.0714 - regression_loss: 0.0666 - classification_loss: 0.0048
327/500 [==================>...........] - ETA: 1:20 - loss: 0.0714 - regression_loss: 0.0666 - classification_loss: 0.0048
328/500 [==================>...........] - ETA: 1:19 - loss: 0.0713 - regression_loss: 0.0665 - classification_loss: 0.0048
329/500 [==================>...........] - ETA: 1:19 - loss: 0.0712 - regression_loss: 0.0663 - classification_loss: 0.0048
330/500 [==================>...........] - ETA: 1:19 - loss: 0.0711 - regression_loss: 0.0663 - classification_loss: 0.0048
331/500 [==================>...........] - ETA: 1:18 - loss: 0.0709 - regression_loss: 0.0661 - classification_loss: 0.0048
332/500 [==================>...........] - ETA: 1:18 - loss: 0.0711 - regression_loss: 0.0663 - classification_loss: 0.0048
333/500 [==================>...........] - ETA: 1:17 - loss: 0.0715 - regression_loss: 0.0667 - classification_loss: 0.0048
334/500 [===================>..........] - ETA: 1:17 - loss: 0.0714 - regression_loss: 0.0666 - classification_loss: 0.0048
335/500 [===================>..........] - ETA: 1:16 - loss: 0.0715 - regression_loss: 0.0667 - classification_loss: 0.0048
336/500 [===================>..........] - ETA: 1:16 - loss: 0.0715 - regression_loss: 0.0667 - classification_loss: 0.0048
337/500 [===================>..........] - ETA: 1:15 - loss: 0.0715 - regression_loss: 0.0667 - classification_loss: 0.0048
338/500 [===================>..........] - ETA: 1:15 - loss: 0.0716 - regression_loss: 0.0668 - classification_loss: 0.0048
339/500 [===================>..........] - ETA: 1:14 - loss: 0.0716 - regression_loss: 0.0668 - classification_loss: 0.0048
340/500 [===================>..........] - ETA: 1:14 - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0048
341/500 [===================>..........] - ETA: 1:13 - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
342/500 [===================>..........] - ETA: 1:13 - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
343/500 [===================>..........] - ETA: 1:12 - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0048
344/500 [===================>..........] - ETA: 1:12 - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0048
345/500 [===================>..........] - ETA: 1:12 - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
346/500 [===================>..........] - ETA: 1:11 - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0048
347/500 [===================>..........] - ETA: 1:11 - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
348/500 [===================>..........] - ETA: 1:10 - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0048
349/500 [===================>..........] - ETA: 1:10 - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0048
350/500 [====================>.........] - ETA: 1:09 - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
351/500 [====================>.........] - ETA: 1:09 - loss: 0.0723 - regression_loss: 0.0674 - classification_loss: 0.0048
352/500 [====================>.........] - ETA: 1:08 - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
353/500 [====================>.........] - ETA: 1:08 - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0048
354/500 [====================>.........] - ETA: 1:07 - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
355/500 [====================>.........] - ETA: 1:07 - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
356/500 [====================>.........] - ETA: 1:06 - loss: 0.0721 - regression_loss: 0.0673 - classification_loss: 0.0048
357/500 [====================>.........] - ETA: 1:06 - loss: 0.0720 - regression_loss: 0.0672 - classification_loss: 0.0048
358/500 [====================>.........] - ETA: 1:06 - loss: 0.0721 - regression_loss: 0.0673 - classification_loss: 0.0048
359/500 [====================>.........] - ETA: 1:05 - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
360/500 [====================>.........] - ETA: 1:05 - loss: 0.0722 - regression_loss: 0.0673 - classification_loss: 0.0048
361/500 [====================>.........] - ETA: 1:04 - loss: 0.0722 - regression_loss: 0.0673 - classification_loss: 0.0048
362/500 [====================>.........] - ETA: 1:04 - loss: 0.0720 - regression_loss: 0.0672 - classification_loss: 0.0048
363/500 [====================>.........] - ETA: 1:03 - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
364/500 [====================>.........] - ETA: 1:03 - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
365/500 [====================>.........] - ETA: 1:02 - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
366/500 [====================>.........] - ETA: 1:02 - loss: 0.0720 - regression_loss: 0.0671 - classification_loss: 0.0048
367/500 [=====================>........] - ETA: 1:01 - loss: 0.0718 - regression_loss: 0.0670 - classification_loss: 0.0048
368/500 [=====================>........] - ETA: 1:01 - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0048
369/500 [=====================>........] - ETA: 1:00 - loss: 0.0717 - regression_loss: 0.0668 - classification_loss: 0.0048
370/500 [=====================>........] - ETA: 1:00 - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0048
371/500 [=====================>........] - ETA: 59s - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0048 
372/500 [=====================>........] - ETA: 59s - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0048
373/500 [=====================>........] - ETA: 59s - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0048
374/500 [=====================>........] - ETA: 58s - loss: 0.0716 - regression_loss: 0.0668 - classification_loss: 0.0048
375/500 [=====================>........] - ETA: 58s - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0048
376/500 [=====================>........] - ETA: 57s - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0048
377/500 [=====================>........] - ETA: 57s - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
378/500 [=====================>........] - ETA: 56s - loss: 0.0722 - regression_loss: 0.0673 - classification_loss: 0.0048
379/500 [=====================>........] - ETA: 56s - loss: 0.0721 - regression_loss: 0.0672 - classification_loss: 0.0048
380/500 [=====================>........] - ETA: 55s - loss: 0.0721 - regression_loss: 0.0673 - classification_loss: 0.0048
381/500 [=====================>........] - ETA: 55s - loss: 0.0722 - regression_loss: 0.0673 - classification_loss: 0.0048
382/500 [=====================>........] - ETA: 54s - loss: 0.0721 - regression_loss: 0.0672 - classification_loss: 0.0048
383/500 [=====================>........] - ETA: 54s - loss: 0.0720 - regression_loss: 0.0672 - classification_loss: 0.0048
384/500 [======================>.......] - ETA: 53s - loss: 0.0720 - regression_loss: 0.0672 - classification_loss: 0.0048
385/500 [======================>.......] - ETA: 53s - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
386/500 [======================>.......] - ETA: 52s - loss: 0.0720 - regression_loss: 0.0672 - classification_loss: 0.0048
387/500 [======================>.......] - ETA: 52s - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
388/500 [======================>.......] - ETA: 52s - loss: 0.0718 - regression_loss: 0.0670 - classification_loss: 0.0048
389/500 [======================>.......] - ETA: 51s - loss: 0.0718 - regression_loss: 0.0670 - classification_loss: 0.0048
390/500 [======================>.......] - ETA: 51s - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0048
391/500 [======================>.......] - ETA: 50s - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
392/500 [======================>.......] - ETA: 50s - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
393/500 [======================>.......] - ETA: 49s - loss: 0.0720 - regression_loss: 0.0672 - classification_loss: 0.0048
394/500 [======================>.......] - ETA: 49s - loss: 0.0720 - regression_loss: 0.0671 - classification_loss: 0.0048
395/500 [======================>.......] - ETA: 48s - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
396/500 [======================>.......] - ETA: 48s - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
397/500 [======================>.......] - ETA: 47s - loss: 0.0717 - regression_loss: 0.0670 - classification_loss: 0.0048
398/500 [======================>.......] - ETA: 47s - loss: 0.0716 - regression_loss: 0.0668 - classification_loss: 0.0048
399/500 [======================>.......] - ETA: 46s - loss: 0.0718 - regression_loss: 0.0670 - classification_loss: 0.0048
400/500 [=======================>......] - ETA: 46s - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
401/500 [=======================>......] - ETA: 46s - loss: 0.0721 - regression_loss: 0.0673 - classification_loss: 0.0048
402/500 [=======================>......] - ETA: 45s - loss: 0.0721 - regression_loss: 0.0672 - classification_loss: 0.0048
403/500 [=======================>......] - ETA: 45s - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
404/500 [=======================>......] - ETA: 44s - loss: 0.0718 - regression_loss: 0.0670 - classification_loss: 0.0048
405/500 [=======================>......] - ETA: 44s - loss: 0.0718 - regression_loss: 0.0670 - classification_loss: 0.0048
406/500 [=======================>......] - ETA: 43s - loss: 0.0718 - regression_loss: 0.0670 - classification_loss: 0.0048
407/500 [=======================>......] - ETA: 43s - loss: 0.0717 - regression_loss: 0.0669 - classification_loss: 0.0048
408/500 [=======================>......] - ETA: 42s - loss: 0.0716 - regression_loss: 0.0668 - classification_loss: 0.0048
409/500 [=======================>......] - ETA: 42s - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
410/500 [=======================>......] - ETA: 41s - loss: 0.0718 - regression_loss: 0.0670 - classification_loss: 0.0048
411/500 [=======================>......] - ETA: 41s - loss: 0.0719 - regression_loss: 0.0671 - classification_loss: 0.0048
412/500 [=======================>......] - ETA: 40s - loss: 0.0721 - regression_loss: 0.0673 - classification_loss: 0.0048
413/500 [=======================>......] - ETA: 40s - loss: 0.0720 - regression_loss: 0.0672 - classification_loss: 0.0048
414/500 [=======================>......] - ETA: 39s - loss: 0.0720 - regression_loss: 0.0673 - classification_loss: 0.0048
415/500 [=======================>......] - ETA: 39s - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
416/500 [=======================>......] - ETA: 39s - loss: 0.0725 - regression_loss: 0.0677 - classification_loss: 0.0048
417/500 [========================>.....] - ETA: 38s - loss: 0.0723 - regression_loss: 0.0676 - classification_loss: 0.0048
418/500 [========================>.....] - ETA: 38s - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0048
419/500 [========================>.....] - ETA: 37s - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
420/500 [========================>.....] - ETA: 37s - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0048
421/500 [========================>.....] - ETA: 36s - loss: 0.0724 - regression_loss: 0.0676 - classification_loss: 0.0048
422/500 [========================>.....] - ETA: 36s - loss: 0.0723 - regression_loss: 0.0676 - classification_loss: 0.0048
423/500 [========================>.....] - ETA: 35s - loss: 0.0724 - regression_loss: 0.0677 - classification_loss: 0.0048
424/500 [========================>.....] - ETA: 35s - loss: 0.0724 - regression_loss: 0.0676 - classification_loss: 0.0048
425/500 [========================>.....] - ETA: 34s - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0048
426/500 [========================>.....] - ETA: 34s - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
427/500 [========================>.....] - ETA: 33s - loss: 0.0721 - regression_loss: 0.0673 - classification_loss: 0.0047
428/500 [========================>.....] - ETA: 33s - loss: 0.0720 - regression_loss: 0.0673 - classification_loss: 0.0047
429/500 [========================>.....] - ETA: 32s - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
430/500 [========================>.....] - ETA: 32s - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0048
431/500 [========================>.....] - ETA: 32s - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0047
432/500 [========================>.....] - ETA: 31s - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0047
433/500 [========================>.....] - ETA: 31s - loss: 0.0721 - regression_loss: 0.0674 - classification_loss: 0.0047
434/500 [=========================>....] - ETA: 30s - loss: 0.0721 - regression_loss: 0.0674 - classification_loss: 0.0047
435/500 [=========================>....] - ETA: 30s - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0047
436/500 [=========================>....] - ETA: 29s - loss: 0.0721 - regression_loss: 0.0674 - classification_loss: 0.0047
437/500 [=========================>....] - ETA: 29s - loss: 0.0722 - regression_loss: 0.0674 - classification_loss: 0.0048
438/500 [=========================>....] - ETA: 28s - loss: 0.0721 - regression_loss: 0.0673 - classification_loss: 0.0047
439/500 [=========================>....] - ETA: 28s - loss: 0.0721 - regression_loss: 0.0673 - classification_loss: 0.0047
440/500 [=========================>....] - ETA: 27s - loss: 0.0719 - regression_loss: 0.0672 - classification_loss: 0.0047
441/500 [=========================>....] - ETA: 27s - loss: 0.0719 - regression_loss: 0.0672 - classification_loss: 0.0047
442/500 [=========================>....] - ETA: 26s - loss: 0.0719 - regression_loss: 0.0672 - classification_loss: 0.0047
443/500 [=========================>....] - ETA: 26s - loss: 0.0720 - regression_loss: 0.0673 - classification_loss: 0.0047
444/500 [=========================>....] - ETA: 26s - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0047
445/500 [=========================>....] - ETA: 25s - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0047
446/500 [=========================>....] - ETA: 25s - loss: 0.0723 - regression_loss: 0.0676 - classification_loss: 0.0047
447/500 [=========================>....] - ETA: 24s - loss: 0.0723 - regression_loss: 0.0675 - classification_loss: 0.0047
448/500 [=========================>....] - ETA: 24s - loss: 0.0722 - regression_loss: 0.0675 - classification_loss: 0.0047
449/500 [=========================>....] - ETA: 23s - loss: 0.0724 - regression_loss: 0.0677 - classification_loss: 0.0047
450/500 [==========================>...] - ETA: 23s - loss: 0.0728 - regression_loss: 0.0681 - classification_loss: 0.0047
451/500 [==========================>...] - ETA: 22s - loss: 0.0728 - regression_loss: 0.0681 - classification_loss: 0.0047
452/500 [==========================>...] - ETA: 22s - loss: 0.0727 - regression_loss: 0.0680 - classification_loss: 0.0047
453/500 [==========================>...] - ETA: 21s - loss: 0.0726 - regression_loss: 0.0679 - classification_loss: 0.0047
454/500 [==========================>...] - ETA: 21s - loss: 0.0727 - regression_loss: 0.0679 - classification_loss: 0.0047
455/500 [==========================>...] - ETA: 20s - loss: 0.0726 - regression_loss: 0.0679 - classification_loss: 0.0047
456/500 [==========================>...] - ETA: 20s - loss: 0.0725 - regression_loss: 0.0678 - classification_loss: 0.0047
457/500 [==========================>...] - ETA: 19s - loss: 0.0724 - regression_loss: 0.0677 - classification_loss: 0.0047
458/500 [==========================>...] - ETA: 19s - loss: 0.0724 - regression_loss: 0.0677 - classification_loss: 0.0047
459/500 [==========================>...] - ETA: 19s - loss: 0.0725 - regression_loss: 0.0678 - classification_loss: 0.0047
460/500 [==========================>...] - ETA: 18s - loss: 0.0726 - regression_loss: 0.0679 - classification_loss: 0.0047
461/500 [==========================>...] - ETA: 18s - loss: 0.0725 - regression_loss: 0.0678 - classification_loss: 0.0047
462/500 [==========================>...] - ETA: 17s - loss: 0.0724 - regression_loss: 0.0677 - classification_loss: 0.0047
463/500 [==========================>...] - ETA: 17s - loss: 0.0725 - regression_loss: 0.0678 - classification_loss: 0.0047
464/500 [==========================>...] - ETA: 16s - loss: 0.0724 - regression_loss: 0.0677 - classification_loss: 0.0047
465/500 [==========================>...] - ETA: 16s - loss: 0.0724 - regression_loss: 0.0677 - classification_loss: 0.0047
466/500 [==========================>...] - ETA: 15s - loss: 0.0723 - regression_loss: 0.0676 - classification_loss: 0.0047
467/500 [===========================>..] - ETA: 15s - loss: 0.0723 - regression_loss: 0.0676 - classification_loss: 0.0047
468/500 [===========================>..] - ETA: 14s - loss: 0.0724 - regression_loss: 0.0677 - classification_loss: 0.0047
469/500 [===========================>..] - ETA: 14s - loss: 0.0723 - regression_loss: 0.0676 - classification_loss: 0.0047
470/500 [===========================>..] - ETA: 13s - loss: 0.0723 - regression_loss: 0.0676 - classification_loss: 0.0047
471/500 [===========================>..] - ETA: 13s - loss: 0.0722 - regression_loss: 0.0676 - classification_loss: 0.0047
472/500 [===========================>..] - ETA: 13s - loss: 0.0724 - regression_loss: 0.0677 - classification_loss: 0.0047
473/500 [===========================>..] - ETA: 12s - loss: 0.0725 - regression_loss: 0.0678 - classification_loss: 0.0047
474/500 [===========================>..] - ETA: 12s - loss: 0.0724 - regression_loss: 0.0677 - classification_loss: 0.0047
475/500 [===========================>..] - ETA: 11s - loss: 0.0723 - regression_loss: 0.0676 - classification_loss: 0.0047
476/500 [===========================>..] - ETA: 11s - loss: 0.0722 - regression_loss: 0.0675 - classification_loss: 0.0047
477/500 [===========================>..] - ETA: 10s - loss: 0.0721 - regression_loss: 0.0675 - classification_loss: 0.0047
478/500 [===========================>..] - ETA: 10s - loss: 0.0720 - regression_loss: 0.0674 - classification_loss: 0.0047
479/500 [===========================>..] - ETA: 9s - loss: 0.0722 - regression_loss: 0.0676 - classification_loss: 0.0047 
480/500 [===========================>..] - ETA: 9s - loss: 0.0722 - regression_loss: 0.0676 - classification_loss: 0.0047
481/500 [===========================>..] - ETA: 8s - loss: 0.0723 - regression_loss: 0.0676 - classification_loss: 0.0047
482/500 [===========================>..] - ETA: 8s - loss: 0.0723 - regression_loss: 0.0676 - classification_loss: 0.0047
483/500 [===========================>..] - ETA: 7s - loss: 0.0722 - regression_loss: 0.0676 - classification_loss: 0.0047
484/500 [============================>.] - ETA: 7s - loss: 0.0722 - regression_loss: 0.0675 - classification_loss: 0.0047
485/500 [============================>.] - ETA: 6s - loss: 0.0722 - regression_loss: 0.0676 - classification_loss: 0.0047
486/500 [============================>.] - ETA: 6s - loss: 0.0722 - regression_loss: 0.0676 - classification_loss: 0.0047
487/500 [============================>.] - ETA: 6s - loss: 0.0723 - regression_loss: 0.0676 - classification_loss: 0.0047
488/500 [============================>.] - ETA: 5s - loss: 0.0722 - regression_loss: 0.0676 - classification_loss: 0.0047
489/500 [============================>.] - ETA: 5s - loss: 0.0721 - regression_loss: 0.0675 - classification_loss: 0.0047
490/500 [============================>.] - ETA: 4s - loss: 0.0720 - regression_loss: 0.0674 - classification_loss: 0.0047
491/500 [============================>.] - ETA: 4s - loss: 0.0719 - regression_loss: 0.0673 - classification_loss: 0.0047
492/500 [============================>.] - ETA: 3s - loss: 0.0719 - regression_loss: 0.0673 - classification_loss: 0.0047
493/500 [============================>.] - ETA: 3s - loss: 0.0718 - regression_loss: 0.0672 - classification_loss: 0.0046
494/500 [============================>.] - ETA: 2s - loss: 0.0718 - regression_loss: 0.0672 - classification_loss: 0.0047
495/500 [============================>.] - ETA: 2s - loss: 0.0718 - regression_loss: 0.0672 - classification_loss: 0.0047
496/500 [============================>.] - ETA: 1s - loss: 0.0718 - regression_loss: 0.0671 - classification_loss: 0.0047
497/500 [============================>.] - ETA: 1s - loss: 0.0717 - regression_loss: 0.0670 - classification_loss: 0.0046
498/500 [============================>.] - ETA: 0s - loss: 0.0716 - regression_loss: 0.0670 - classification_loss: 0.0046
499/500 [============================>.] - ETA: 0s - loss: 0.0716 - regression_loss: 0.0670 - classification_loss: 0.0046
500/500 [==============================] - 232s 465ms/step - loss: 0.0718 - regression_loss: 0.0671 - classification_loss: 0.0046
44 instances of class building with average precision: 0.8159
mAP: 0.8159

Epoch 00007: saving model to ./snapshots/resnet50_csv_07.h5
Epoch 8/8

  1/500 [..............................] - ETA: 3:50 - loss: 0.0037 - regression_loss: 0.0030 - classification_loss: 6.8544e-04
  2/500 [..............................] - ETA: 3:50 - loss: 0.0603 - regression_loss: 0.0543 - classification_loss: 0.0060    
  3/500 [..............................] - ETA: 3:50 - loss: 0.0635 - regression_loss: 0.0587 - classification_loss: 0.0048
  4/500 [..............................] - ETA: 3:49 - loss: 0.0526 - regression_loss: 0.0486 - classification_loss: 0.0040
  5/500 [..............................] - ETA: 3:49 - loss: 0.0517 - regression_loss: 0.0478 - classification_loss: 0.0039
  6/500 [..............................] - ETA: 3:49 - loss: 0.0480 - regression_loss: 0.0444 - classification_loss: 0.0036
  7/500 [..............................] - ETA: 3:48 - loss: 0.0504 - regression_loss: 0.0468 - classification_loss: 0.0036
  8/500 [..............................] - ETA: 3:48 - loss: 0.0551 - regression_loss: 0.0504 - classification_loss: 0.0047
  9/500 [..............................] - ETA: 3:47 - loss: 0.0504 - regression_loss: 0.0462 - classification_loss: 0.0042
 10/500 [..............................] - ETA: 3:47 - loss: 0.0537 - regression_loss: 0.0498 - classification_loss: 0.0040
 11/500 [..............................] - ETA: 3:47 - loss: 0.0546 - regression_loss: 0.0507 - classification_loss: 0.0039
 12/500 [..............................] - ETA: 3:47 - loss: 0.0505 - regression_loss: 0.0468 - classification_loss: 0.0036
 13/500 [..............................] - ETA: 3:46 - loss: 0.0528 - regression_loss: 0.0486 - classification_loss: 0.0042
 14/500 [..............................] - ETA: 3:46 - loss: 0.0507 - regression_loss: 0.0468 - classification_loss: 0.0040
 15/500 [..............................] - ETA: 3:46 - loss: 0.0491 - regression_loss: 0.0452 - classification_loss: 0.0038
 16/500 [..............................] - ETA: 3:46 - loss: 0.0510 - regression_loss: 0.0467 - classification_loss: 0.0043
 17/500 [>.............................] - ETA: 3:45 - loss: 0.0494 - regression_loss: 0.0454 - classification_loss: 0.0040
 18/500 [>.............................] - ETA: 3:44 - loss: 0.0493 - regression_loss: 0.0453 - classification_loss: 0.0040
 19/500 [>.............................] - ETA: 3:44 - loss: 0.0474 - regression_loss: 0.0435 - classification_loss: 0.0039
 20/500 [>.............................] - ETA: 3:43 - loss: 0.0458 - regression_loss: 0.0421 - classification_loss: 0.0037
 21/500 [>.............................] - ETA: 3:43 - loss: 0.0453 - regression_loss: 0.0416 - classification_loss: 0.0037
 22/500 [>.............................] - ETA: 3:43 - loss: 0.0461 - regression_loss: 0.0421 - classification_loss: 0.0040
 23/500 [>.............................] - ETA: 3:42 - loss: 0.0444 - regression_loss: 0.0405 - classification_loss: 0.0039
 24/500 [>.............................] - ETA: 3:42 - loss: 0.0440 - regression_loss: 0.0402 - classification_loss: 0.0038
 25/500 [>.............................] - ETA: 3:41 - loss: 0.0428 - regression_loss: 0.0391 - classification_loss: 0.0037
 26/500 [>.............................] - ETA: 3:41 - loss: 0.0414 - regression_loss: 0.0379 - classification_loss: 0.0036
 27/500 [>.............................] - ETA: 3:40 - loss: 0.0428 - regression_loss: 0.0392 - classification_loss: 0.0036
 28/500 [>.............................] - ETA: 3:40 - loss: 0.0417 - regression_loss: 0.0382 - classification_loss: 0.0035
 29/500 [>.............................] - ETA: 3:39 - loss: 0.0426 - regression_loss: 0.0389 - classification_loss: 0.0038
 30/500 [>.............................] - ETA: 3:39 - loss: 0.0417 - regression_loss: 0.0380 - classification_loss: 0.0037
 31/500 [>.............................] - ETA: 3:38 - loss: 0.0417 - regression_loss: 0.0381 - classification_loss: 0.0036
 32/500 [>.............................] - ETA: 3:38 - loss: 0.0410 - regression_loss: 0.0375 - classification_loss: 0.0035
 33/500 [>.............................] - ETA: 3:37 - loss: 0.0414 - regression_loss: 0.0380 - classification_loss: 0.0035
 34/500 [=>............................] - ETA: 3:37 - loss: 0.0429 - regression_loss: 0.0392 - classification_loss: 0.0037
 35/500 [=>............................] - ETA: 3:36 - loss: 0.0433 - regression_loss: 0.0396 - classification_loss: 0.0036
 36/500 [=>............................] - ETA: 3:36 - loss: 0.0425 - regression_loss: 0.0389 - classification_loss: 0.0036
 37/500 [=>............................] - ETA: 3:35 - loss: 0.0438 - regression_loss: 0.0400 - classification_loss: 0.0039
 38/500 [=>............................] - ETA: 3:35 - loss: 0.0446 - regression_loss: 0.0408 - classification_loss: 0.0038
 39/500 [=>............................] - ETA: 3:34 - loss: 0.0446 - regression_loss: 0.0408 - classification_loss: 0.0038
 40/500 [=>............................] - ETA: 3:34 - loss: 0.0438 - regression_loss: 0.0401 - classification_loss: 0.0037
 41/500 [=>............................] - ETA: 3:34 - loss: 0.0431 - regression_loss: 0.0395 - classification_loss: 0.0036
 42/500 [=>............................] - ETA: 3:33 - loss: 0.0434 - regression_loss: 0.0397 - classification_loss: 0.0036
 43/500 [=>............................] - ETA: 3:33 - loss: 0.0440 - regression_loss: 0.0402 - classification_loss: 0.0038
 44/500 [=>............................] - ETA: 3:32 - loss: 0.0435 - regression_loss: 0.0398 - classification_loss: 0.0037
 45/500 [=>............................] - ETA: 3:32 - loss: 0.0431 - regression_loss: 0.0394 - classification_loss: 0.0037
 46/500 [=>............................] - ETA: 3:31 - loss: 0.0425 - regression_loss: 0.0388 - classification_loss: 0.0036
 47/500 [=>............................] - ETA: 3:31 - loss: 0.0438 - regression_loss: 0.0400 - classification_loss: 0.0038
 48/500 [=>............................] - ETA: 3:30 - loss: 0.0442 - regression_loss: 0.0404 - classification_loss: 0.0038
 49/500 [=>............................] - ETA: 3:30 - loss: 0.0436 - regression_loss: 0.0399 - classification_loss: 0.0037
 50/500 [==>...........................] - ETA: 3:29 - loss: 0.0432 - regression_loss: 0.0395 - classification_loss: 0.0037
 51/500 [==>...........................] - ETA: 3:29 - loss: 0.0445 - regression_loss: 0.0407 - classification_loss: 0.0038
 52/500 [==>...........................] - ETA: 3:28 - loss: 0.0455 - regression_loss: 0.0417 - classification_loss: 0.0038
 53/500 [==>...........................] - ETA: 3:28 - loss: 0.0451 - regression_loss: 0.0413 - classification_loss: 0.0037
 54/500 [==>...........................] - ETA: 3:27 - loss: 0.0497 - regression_loss: 0.0460 - classification_loss: 0.0037
 55/500 [==>...........................] - ETA: 3:27 - loss: 0.0490 - regression_loss: 0.0453 - classification_loss: 0.0036
 56/500 [==>...........................] - ETA: 3:26 - loss: 0.0483 - regression_loss: 0.0448 - classification_loss: 0.0036
 57/500 [==>...........................] - ETA: 3:26 - loss: 0.0484 - regression_loss: 0.0448 - classification_loss: 0.0036
 58/500 [==>...........................] - ETA: 3:25 - loss: 0.0489 - regression_loss: 0.0454 - classification_loss: 0.0035
 59/500 [==>...........................] - ETA: 3:25 - loss: 0.0502 - regression_loss: 0.0467 - classification_loss: 0.0035
 60/500 [==>...........................] - ETA: 3:24 - loss: 0.0518 - regression_loss: 0.0482 - classification_loss: 0.0036
 61/500 [==>...........................] - ETA: 3:24 - loss: 0.0513 - regression_loss: 0.0477 - classification_loss: 0.0036
 62/500 [==>...........................] - ETA: 3:24 - loss: 0.0521 - regression_loss: 0.0485 - classification_loss: 0.0036
 63/500 [==>...........................] - ETA: 3:23 - loss: 0.0541 - regression_loss: 0.0505 - classification_loss: 0.0036
 64/500 [==>...........................] - ETA: 3:23 - loss: 0.0556 - regression_loss: 0.0519 - classification_loss: 0.0037
 65/500 [==>...........................] - ETA: 3:22 - loss: 0.0554 - regression_loss: 0.0517 - classification_loss: 0.0037
 66/500 [==>...........................] - ETA: 3:22 - loss: 0.0558 - regression_loss: 0.0522 - classification_loss: 0.0037
 67/500 [===>..........................] - ETA: 3:21 - loss: 0.0566 - regression_loss: 0.0528 - classification_loss: 0.0038
 68/500 [===>..........................] - ETA: 3:21 - loss: 0.0563 - regression_loss: 0.0525 - classification_loss: 0.0037
 69/500 [===>..........................] - ETA: 3:20 - loss: 0.0571 - regression_loss: 0.0534 - classification_loss: 0.0037
 70/500 [===>..........................] - ETA: 3:20 - loss: 0.0577 - regression_loss: 0.0541 - classification_loss: 0.0037
 71/500 [===>..........................] - ETA: 3:19 - loss: 0.0578 - regression_loss: 0.0541 - classification_loss: 0.0037
 72/500 [===>..........................] - ETA: 3:19 - loss: 0.0571 - regression_loss: 0.0535 - classification_loss: 0.0036
 73/500 [===>..........................] - ETA: 3:18 - loss: 0.0575 - regression_loss: 0.0539 - classification_loss: 0.0036
 74/500 [===>..........................] - ETA: 3:18 - loss: 0.0591 - regression_loss: 0.0553 - classification_loss: 0.0037
 75/500 [===>..........................] - ETA: 3:18 - loss: 0.0597 - regression_loss: 0.0560 - classification_loss: 0.0037
 76/500 [===>..........................] - ETA: 3:17 - loss: 0.0610 - regression_loss: 0.0573 - classification_loss: 0.0037
 77/500 [===>..........................] - ETA: 3:17 - loss: 0.0617 - regression_loss: 0.0579 - classification_loss: 0.0038
 78/500 [===>..........................] - ETA: 3:16 - loss: 0.0615 - regression_loss: 0.0577 - classification_loss: 0.0038
 79/500 [===>..........................] - ETA: 3:16 - loss: 0.0620 - regression_loss: 0.0583 - classification_loss: 0.0038
 80/500 [===>..........................] - ETA: 3:15 - loss: 0.0621 - regression_loss: 0.0584 - classification_loss: 0.0037
 81/500 [===>..........................] - ETA: 3:15 - loss: 0.0623 - regression_loss: 0.0586 - classification_loss: 0.0037
 82/500 [===>..........................] - ETA: 3:14 - loss: 0.0641 - regression_loss: 0.0603 - classification_loss: 0.0039
 83/500 [===>..........................] - ETA: 3:14 - loss: 0.0645 - regression_loss: 0.0607 - classification_loss: 0.0038
 84/500 [====>.........................] - ETA: 3:13 - loss: 0.0643 - regression_loss: 0.0606 - classification_loss: 0.0038
 85/500 [====>.........................] - ETA: 3:13 - loss: 0.0644 - regression_loss: 0.0607 - classification_loss: 0.0038
 86/500 [====>.........................] - ETA: 3:13 - loss: 0.0641 - regression_loss: 0.0604 - classification_loss: 0.0037
 87/500 [====>.........................] - ETA: 3:12 - loss: 0.0648 - regression_loss: 0.0610 - classification_loss: 0.0038
 88/500 [====>.........................] - ETA: 3:12 - loss: 0.0658 - regression_loss: 0.0619 - classification_loss: 0.0038
 89/500 [====>.........................] - ETA: 3:11 - loss: 0.0654 - regression_loss: 0.0617 - classification_loss: 0.0038
 90/500 [====>.........................] - ETA: 3:11 - loss: 0.0656 - regression_loss: 0.0618 - classification_loss: 0.0038
 91/500 [====>.........................] - ETA: 3:10 - loss: 0.0660 - regression_loss: 0.0623 - classification_loss: 0.0037
 92/500 [====>.........................] - ETA: 3:10 - loss: 0.0662 - regression_loss: 0.0625 - classification_loss: 0.0037
 93/500 [====>.........................] - ETA: 3:09 - loss: 0.0660 - regression_loss: 0.0624 - classification_loss: 0.0037
 94/500 [====>.........................] - ETA: 3:09 - loss: 0.0666 - regression_loss: 0.0628 - classification_loss: 0.0038
 95/500 [====>.........................] - ETA: 3:08 - loss: 0.0665 - regression_loss: 0.0627 - classification_loss: 0.0038
 96/500 [====>.........................] - ETA: 3:08 - loss: 0.0660 - regression_loss: 0.0623 - classification_loss: 0.0038
 97/500 [====>.........................] - ETA: 3:07 - loss: 0.0658 - regression_loss: 0.0621 - classification_loss: 0.0037
 98/500 [====>.........................] - ETA: 3:07 - loss: 0.0658 - regression_loss: 0.0621 - classification_loss: 0.0037
 99/500 [====>.........................] - ETA: 3:06 - loss: 0.0654 - regression_loss: 0.0617 - classification_loss: 0.0037
100/500 [=====>........................] - ETA: 3:06 - loss: 0.0662 - regression_loss: 0.0624 - classification_loss: 0.0038
101/500 [=====>........................] - ETA: 3:05 - loss: 0.0656 - regression_loss: 0.0618 - classification_loss: 0.0038
102/500 [=====>........................] - ETA: 3:05 - loss: 0.0660 - regression_loss: 0.0621 - classification_loss: 0.0038
103/500 [=====>........................] - ETA: 3:04 - loss: 0.0665 - regression_loss: 0.0626 - classification_loss: 0.0038
104/500 [=====>........................] - ETA: 3:04 - loss: 0.0662 - regression_loss: 0.0624 - classification_loss: 0.0038
105/500 [=====>........................] - ETA: 3:04 - loss: 0.0662 - regression_loss: 0.0624 - classification_loss: 0.0038
106/500 [=====>........................] - ETA: 3:03 - loss: 0.0671 - regression_loss: 0.0633 - classification_loss: 0.0039
107/500 [=====>........................] - ETA: 3:03 - loss: 0.0672 - regression_loss: 0.0634 - classification_loss: 0.0039
108/500 [=====>........................] - ETA: 3:02 - loss: 0.0673 - regression_loss: 0.0635 - classification_loss: 0.0038
109/500 [=====>........................] - ETA: 3:02 - loss: 0.0667 - regression_loss: 0.0629 - classification_loss: 0.0038
110/500 [=====>........................] - ETA: 3:01 - loss: 0.0665 - regression_loss: 0.0627 - classification_loss: 0.0038
111/500 [=====>........................] - ETA: 3:01 - loss: 0.0661 - regression_loss: 0.0624 - classification_loss: 0.0038
112/500 [=====>........................] - ETA: 3:00 - loss: 0.0659 - regression_loss: 0.0622 - classification_loss: 0.0037
113/500 [=====>........................] - ETA: 3:00 - loss: 0.0662 - regression_loss: 0.0625 - classification_loss: 0.0037
114/500 [=====>........................] - ETA: 2:59 - loss: 0.0657 - regression_loss: 0.0620 - classification_loss: 0.0037
115/500 [=====>........................] - ETA: 2:59 - loss: 0.0658 - regression_loss: 0.0620 - classification_loss: 0.0038
116/500 [=====>........................] - ETA: 2:58 - loss: 0.0658 - regression_loss: 0.0621 - classification_loss: 0.0038
117/500 [======>.......................] - ETA: 2:58 - loss: 0.0661 - regression_loss: 0.0623 - classification_loss: 0.0038
118/500 [======>.......................] - ETA: 2:57 - loss: 0.0660 - regression_loss: 0.0621 - classification_loss: 0.0038
119/500 [======>.......................] - ETA: 2:57 - loss: 0.0655 - regression_loss: 0.0617 - classification_loss: 0.0038
120/500 [======>.......................] - ETA: 2:56 - loss: 0.0652 - regression_loss: 0.0614 - classification_loss: 0.0038
121/500 [======>.......................] - ETA: 2:56 - loss: 0.0652 - regression_loss: 0.0615 - classification_loss: 0.0038
122/500 [======>.......................] - ETA: 2:55 - loss: 0.0649 - regression_loss: 0.0611 - classification_loss: 0.0037
123/500 [======>.......................] - ETA: 2:55 - loss: 0.0650 - regression_loss: 0.0612 - classification_loss: 0.0038
124/500 [======>.......................] - ETA: 2:55 - loss: 0.0650 - regression_loss: 0.0612 - classification_loss: 0.0038
125/500 [======>.......................] - ETA: 2:54 - loss: 0.0645 - regression_loss: 0.0608 - classification_loss: 0.0038
126/500 [======>.......................] - ETA: 2:54 - loss: 0.0643 - regression_loss: 0.0606 - classification_loss: 0.0037
127/500 [======>.......................] - ETA: 2:53 - loss: 0.0638 - regression_loss: 0.0601 - classification_loss: 0.0037
128/500 [======>.......................] - ETA: 2:53 - loss: 0.0641 - regression_loss: 0.0604 - classification_loss: 0.0037
129/500 [======>.......................] - ETA: 2:52 - loss: 0.0637 - regression_loss: 0.0600 - classification_loss: 0.0037
130/500 [======>.......................] - ETA: 2:52 - loss: 0.0640 - regression_loss: 0.0602 - classification_loss: 0.0038
131/500 [======>.......................] - ETA: 2:51 - loss: 0.0639 - regression_loss: 0.0602 - classification_loss: 0.0037
132/500 [======>.......................] - ETA: 2:51 - loss: 0.0638 - regression_loss: 0.0601 - classification_loss: 0.0037
133/500 [======>.......................] - ETA: 2:50 - loss: 0.0640 - regression_loss: 0.0602 - classification_loss: 0.0038
134/500 [=======>......................] - ETA: 2:50 - loss: 0.0639 - regression_loss: 0.0601 - classification_loss: 0.0038
135/500 [=======>......................] - ETA: 2:49 - loss: 0.0636 - regression_loss: 0.0598 - classification_loss: 0.0038
136/500 [=======>......................] - ETA: 2:49 - loss: 0.0632 - regression_loss: 0.0595 - classification_loss: 0.0038
137/500 [=======>......................] - ETA: 2:49 - loss: 0.0631 - regression_loss: 0.0594 - classification_loss: 0.0037
138/500 [=======>......................] - ETA: 2:48 - loss: 0.0629 - regression_loss: 0.0592 - classification_loss: 0.0037
139/500 [=======>......................] - ETA: 2:48 - loss: 0.0625 - regression_loss: 0.0588 - classification_loss: 0.0037
140/500 [=======>......................] - ETA: 2:47 - loss: 0.0628 - regression_loss: 0.0590 - classification_loss: 0.0038
141/500 [=======>......................] - ETA: 2:47 - loss: 0.0623 - regression_loss: 0.0586 - classification_loss: 0.0037
142/500 [=======>......................] - ETA: 2:46 - loss: 0.0621 - regression_loss: 0.0584 - classification_loss: 0.0037
143/500 [=======>......................] - ETA: 2:46 - loss: 0.0623 - regression_loss: 0.0585 - classification_loss: 0.0037
144/500 [=======>......................] - ETA: 2:45 - loss: 0.0623 - regression_loss: 0.0586 - classification_loss: 0.0037
145/500 [=======>......................] - ETA: 2:45 - loss: 0.0624 - regression_loss: 0.0586 - classification_loss: 0.0038
146/500 [=======>......................] - ETA: 2:44 - loss: 0.0620 - regression_loss: 0.0583 - classification_loss: 0.0037
147/500 [=======>......................] - ETA: 2:44 - loss: 0.0621 - regression_loss: 0.0583 - classification_loss: 0.0037
148/500 [=======>......................] - ETA: 2:43 - loss: 0.0623 - regression_loss: 0.0585 - classification_loss: 0.0038
149/500 [=======>......................] - ETA: 2:43 - loss: 0.0620 - regression_loss: 0.0582 - classification_loss: 0.0038
150/500 [========>.....................] - ETA: 2:42 - loss: 0.0620 - regression_loss: 0.0583 - classification_loss: 0.0038
151/500 [========>.....................] - ETA: 2:42 - loss: 0.0617 - regression_loss: 0.0579 - classification_loss: 0.0037
152/500 [========>.....................] - ETA: 2:42 - loss: 0.0616 - regression_loss: 0.0578 - classification_loss: 0.0037
153/500 [========>.....................] - ETA: 2:41 - loss: 0.0618 - regression_loss: 0.0581 - classification_loss: 0.0037
154/500 [========>.....................] - ETA: 2:41 - loss: 0.0618 - regression_loss: 0.0580 - classification_loss: 0.0038
155/500 [========>.....................] - ETA: 2:40 - loss: 0.0615 - regression_loss: 0.0577 - classification_loss: 0.0037
156/500 [========>.....................] - ETA: 2:40 - loss: 0.0615 - regression_loss: 0.0577 - classification_loss: 0.0038
157/500 [========>.....................] - ETA: 2:39 - loss: 0.0615 - regression_loss: 0.0578 - classification_loss: 0.0038
158/500 [========>.....................] - ETA: 2:39 - loss: 0.0614 - regression_loss: 0.0576 - classification_loss: 0.0038
159/500 [========>.....................] - ETA: 2:38 - loss: 0.0611 - regression_loss: 0.0573 - classification_loss: 0.0037
160/500 [========>.....................] - ETA: 2:38 - loss: 0.0608 - regression_loss: 0.0570 - classification_loss: 0.0037
161/500 [========>.....................] - ETA: 2:37 - loss: 0.0607 - regression_loss: 0.0570 - classification_loss: 0.0037
162/500 [========>.....................] - ETA: 2:37 - loss: 0.0605 - regression_loss: 0.0568 - classification_loss: 0.0037
163/500 [========>.....................] - ETA: 2:36 - loss: 0.0609 - regression_loss: 0.0571 - classification_loss: 0.0037
164/500 [========>.....................] - ETA: 2:36 - loss: 0.0609 - regression_loss: 0.0571 - classification_loss: 0.0037
165/500 [========>.....................] - ETA: 2:35 - loss: 0.0606 - regression_loss: 0.0569 - classification_loss: 0.0037
166/500 [========>.....................] - ETA: 2:35 - loss: 0.0603 - regression_loss: 0.0566 - classification_loss: 0.0037
167/500 [=========>....................] - ETA: 2:34 - loss: 0.0603 - regression_loss: 0.0566 - classification_loss: 0.0037
168/500 [=========>....................] - ETA: 2:34 - loss: 0.0605 - regression_loss: 0.0567 - classification_loss: 0.0037
169/500 [=========>....................] - ETA: 2:34 - loss: 0.0606 - regression_loss: 0.0568 - classification_loss: 0.0037
170/500 [=========>....................] - ETA: 2:33 - loss: 0.0603 - regression_loss: 0.0566 - classification_loss: 0.0037
171/500 [=========>....................] - ETA: 2:33 - loss: 0.0604 - regression_loss: 0.0566 - classification_loss: 0.0038
172/500 [=========>....................] - ETA: 2:32 - loss: 0.0600 - regression_loss: 0.0563 - classification_loss: 0.0037
173/500 [=========>....................] - ETA: 2:32 - loss: 0.0598 - regression_loss: 0.0560 - classification_loss: 0.0037
174/500 [=========>....................] - ETA: 2:31 - loss: 0.0596 - regression_loss: 0.0559 - classification_loss: 0.0037
175/500 [=========>....................] - ETA: 2:31 - loss: 0.0597 - regression_loss: 0.0560 - classification_loss: 0.0037
176/500 [=========>....................] - ETA: 2:30 - loss: 0.0599 - regression_loss: 0.0561 - classification_loss: 0.0037
177/500 [=========>....................] - ETA: 2:30 - loss: 0.0598 - regression_loss: 0.0560 - classification_loss: 0.0037
178/500 [=========>....................] - ETA: 2:29 - loss: 0.0599 - regression_loss: 0.0561 - classification_loss: 0.0037
179/500 [=========>....................] - ETA: 2:29 - loss: 0.0596 - regression_loss: 0.0559 - classification_loss: 0.0037
180/500 [=========>....................] - ETA: 2:28 - loss: 0.0599 - regression_loss: 0.0562 - classification_loss: 0.0037
181/500 [=========>....................] - ETA: 2:28 - loss: 0.0604 - regression_loss: 0.0567 - classification_loss: 0.0037
182/500 [=========>....................] - ETA: 2:27 - loss: 0.0612 - regression_loss: 0.0575 - classification_loss: 0.0037
183/500 [=========>....................] - ETA: 2:27 - loss: 0.0611 - regression_loss: 0.0574 - classification_loss: 0.0037
184/500 [==========>...................] - ETA: 2:27 - loss: 0.0610 - regression_loss: 0.0573 - classification_loss: 0.0037
185/500 [==========>...................] - ETA: 2:26 - loss: 0.0614 - regression_loss: 0.0577 - classification_loss: 0.0037
186/500 [==========>...................] - ETA: 2:26 - loss: 0.0614 - regression_loss: 0.0577 - classification_loss: 0.0037
187/500 [==========>...................] - ETA: 2:25 - loss: 0.0614 - regression_loss: 0.0577 - classification_loss: 0.0037
188/500 [==========>...................] - ETA: 2:25 - loss: 0.0616 - regression_loss: 0.0579 - classification_loss: 0.0037
189/500 [==========>...................] - ETA: 2:24 - loss: 0.0614 - regression_loss: 0.0577 - classification_loss: 0.0037
190/500 [==========>...................] - ETA: 2:24 - loss: 0.0615 - regression_loss: 0.0578 - classification_loss: 0.0037
191/500 [==========>...................] - ETA: 2:23 - loss: 0.0618 - regression_loss: 0.0581 - classification_loss: 0.0038
192/500 [==========>...................] - ETA: 2:23 - loss: 0.0617 - regression_loss: 0.0580 - classification_loss: 0.0037
193/500 [==========>...................] - ETA: 2:22 - loss: 0.0615 - regression_loss: 0.0578 - classification_loss: 0.0037
194/500 [==========>...................] - ETA: 2:22 - loss: 0.0614 - regression_loss: 0.0577 - classification_loss: 0.0037
195/500 [==========>...................] - ETA: 2:21 - loss: 0.0613 - regression_loss: 0.0576 - classification_loss: 0.0037
196/500 [==========>...................] - ETA: 2:21 - loss: 0.0611 - regression_loss: 0.0574 - classification_loss: 0.0037
197/500 [==========>...................] - ETA: 2:21 - loss: 0.0611 - regression_loss: 0.0574 - classification_loss: 0.0037
198/500 [==========>...................] - ETA: 2:20 - loss: 0.0612 - regression_loss: 0.0575 - classification_loss: 0.0037
199/500 [==========>...................] - ETA: 2:20 - loss: 0.0610 - regression_loss: 0.0573 - classification_loss: 0.0037
200/500 [===========>..................] - ETA: 2:19 - loss: 0.0608 - regression_loss: 0.0571 - classification_loss: 0.0037
201/500 [===========>..................] - ETA: 2:19 - loss: 0.0605 - regression_loss: 0.0569 - classification_loss: 0.0037
202/500 [===========>..................] - ETA: 2:18 - loss: 0.0610 - regression_loss: 0.0573 - classification_loss: 0.0037
203/500 [===========>..................] - ETA: 2:18 - loss: 0.0618 - regression_loss: 0.0581 - classification_loss: 0.0037
204/500 [===========>..................] - ETA: 2:17 - loss: 0.0621 - regression_loss: 0.0584 - classification_loss: 0.0037
205/500 [===========>..................] - ETA: 2:17 - loss: 0.0620 - regression_loss: 0.0583 - classification_loss: 0.0037
206/500 [===========>..................] - ETA: 2:16 - loss: 0.0622 - regression_loss: 0.0584 - classification_loss: 0.0037
207/500 [===========>..................] - ETA: 2:16 - loss: 0.0619 - regression_loss: 0.0582 - classification_loss: 0.0037
208/500 [===========>..................] - ETA: 2:15 - loss: 0.0619 - regression_loss: 0.0582 - classification_loss: 0.0037
209/500 [===========>..................] - ETA: 2:15 - loss: 0.0618 - regression_loss: 0.0581 - classification_loss: 0.0037
210/500 [===========>..................] - ETA: 2:14 - loss: 0.0621 - regression_loss: 0.0584 - classification_loss: 0.0037
211/500 [===========>..................] - ETA: 2:14 - loss: 0.0625 - regression_loss: 0.0588 - classification_loss: 0.0037
212/500 [===========>..................] - ETA: 2:14 - loss: 0.0622 - regression_loss: 0.0585 - classification_loss: 0.0037
213/500 [===========>..................] - ETA: 2:13 - loss: 0.0627 - regression_loss: 0.0590 - classification_loss: 0.0037
214/500 [===========>..................] - ETA: 2:13 - loss: 0.0626 - regression_loss: 0.0589 - classification_loss: 0.0037
215/500 [===========>..................] - ETA: 2:12 - loss: 0.0624 - regression_loss: 0.0587 - classification_loss: 0.0037
216/500 [===========>..................] - ETA: 2:12 - loss: 0.0626 - regression_loss: 0.0588 - classification_loss: 0.0037
217/500 [============>.................] - ETA: 2:11 - loss: 0.0626 - regression_loss: 0.0588 - classification_loss: 0.0037
218/500 [============>.................] - ETA: 2:11 - loss: 0.0632 - regression_loss: 0.0594 - classification_loss: 0.0037
219/500 [============>.................] - ETA: 2:10 - loss: 0.0632 - regression_loss: 0.0595 - classification_loss: 0.0037
220/500 [============>.................] - ETA: 2:10 - loss: 0.0632 - regression_loss: 0.0595 - classification_loss: 0.0037
221/500 [============>.................] - ETA: 2:09 - loss: 0.0634 - regression_loss: 0.0597 - classification_loss: 0.0037
222/500 [============>.................] - ETA: 2:09 - loss: 0.0632 - regression_loss: 0.0595 - classification_loss: 0.0037
223/500 [============>.................] - ETA: 2:08 - loss: 0.0635 - regression_loss: 0.0597 - classification_loss: 0.0037
224/500 [============>.................] - ETA: 2:08 - loss: 0.0632 - regression_loss: 0.0595 - classification_loss: 0.0037
225/500 [============>.................] - ETA: 2:07 - loss: 0.0630 - regression_loss: 0.0593 - classification_loss: 0.0037
226/500 [============>.................] - ETA: 2:07 - loss: 0.0631 - regression_loss: 0.0594 - classification_loss: 0.0037
227/500 [============>.................] - ETA: 2:07 - loss: 0.0628 - regression_loss: 0.0591 - classification_loss: 0.0037
228/500 [============>.................] - ETA: 2:06 - loss: 0.0629 - regression_loss: 0.0592 - classification_loss: 0.0037
229/500 [============>.................] - ETA: 2:06 - loss: 0.0627 - regression_loss: 0.0590 - classification_loss: 0.0037
230/500 [============>.................] - ETA: 2:05 - loss: 0.0626 - regression_loss: 0.0589 - classification_loss: 0.0037
231/500 [============>.................] - ETA: 2:05 - loss: 0.0623 - regression_loss: 0.0587 - classification_loss: 0.0037
232/500 [============>.................] - ETA: 2:04 - loss: 0.0621 - regression_loss: 0.0584 - classification_loss: 0.0037
233/500 [============>.................] - ETA: 2:04 - loss: 0.0623 - regression_loss: 0.0586 - classification_loss: 0.0037
234/500 [=============>................] - ETA: 2:03 - loss: 0.0624 - regression_loss: 0.0587 - classification_loss: 0.0037
235/500 [=============>................] - ETA: 2:03 - loss: 0.0626 - regression_loss: 0.0589 - classification_loss: 0.0037
236/500 [=============>................] - ETA: 2:02 - loss: 0.0626 - regression_loss: 0.0589 - classification_loss: 0.0037
237/500 [=============>................] - ETA: 2:02 - loss: 0.0627 - regression_loss: 0.0590 - classification_loss: 0.0037
238/500 [=============>................] - ETA: 2:01 - loss: 0.0626 - regression_loss: 0.0590 - classification_loss: 0.0037
239/500 [=============>................] - ETA: 2:01 - loss: 0.0625 - regression_loss: 0.0588 - classification_loss: 0.0037
240/500 [=============>................] - ETA: 2:01 - loss: 0.0626 - regression_loss: 0.0590 - classification_loss: 0.0037
241/500 [=============>................] - ETA: 2:00 - loss: 0.0627 - regression_loss: 0.0591 - classification_loss: 0.0037
242/500 [=============>................] - ETA: 2:00 - loss: 0.0628 - regression_loss: 0.0591 - classification_loss: 0.0037
243/500 [=============>................] - ETA: 1:59 - loss: 0.0629 - regression_loss: 0.0592 - classification_loss: 0.0037
244/500 [=============>................] - ETA: 1:59 - loss: 0.0627 - regression_loss: 0.0591 - classification_loss: 0.0037
245/500 [=============>................] - ETA: 1:58 - loss: 0.0625 - regression_loss: 0.0588 - classification_loss: 0.0037
246/500 [=============>................] - ETA: 1:58 - loss: 0.0625 - regression_loss: 0.0589 - classification_loss: 0.0037
247/500 [=============>................] - ETA: 1:57 - loss: 0.0624 - regression_loss: 0.0587 - classification_loss: 0.0037
248/500 [=============>................] - ETA: 1:57 - loss: 0.0622 - regression_loss: 0.0586 - classification_loss: 0.0036
249/500 [=============>................] - ETA: 1:56 - loss: 0.0624 - regression_loss: 0.0587 - classification_loss: 0.0037
250/500 [==============>...............] - ETA: 1:56 - loss: 0.0622 - regression_loss: 0.0585 - classification_loss: 0.0037
251/500 [==============>...............] - ETA: 1:55 - loss: 0.0622 - regression_loss: 0.0585 - classification_loss: 0.0037
252/500 [==============>...............] - ETA: 1:55 - loss: 0.0623 - regression_loss: 0.0586 - classification_loss: 0.0037
253/500 [==============>...............] - ETA: 1:54 - loss: 0.0622 - regression_loss: 0.0585 - classification_loss: 0.0037
254/500 [==============>...............] - ETA: 1:54 - loss: 0.0620 - regression_loss: 0.0583 - classification_loss: 0.0037
255/500 [==============>...............] - ETA: 1:54 - loss: 0.0619 - regression_loss: 0.0582 - classification_loss: 0.0037
256/500 [==============>...............] - ETA: 1:53 - loss: 0.0617 - regression_loss: 0.0581 - classification_loss: 0.0037
257/500 [==============>...............] - ETA: 1:53 - loss: 0.0615 - regression_loss: 0.0579 - classification_loss: 0.0036
258/500 [==============>...............] - ETA: 1:52 - loss: 0.0617 - regression_loss: 0.0580 - classification_loss: 0.0037
259/500 [==============>...............] - ETA: 1:52 - loss: 0.0617 - regression_loss: 0.0580 - classification_loss: 0.0037
260/500 [==============>...............] - ETA: 1:51 - loss: 0.0615 - regression_loss: 0.0579 - classification_loss: 0.0037
261/500 [==============>...............] - ETA: 1:51 - loss: 0.0613 - regression_loss: 0.0577 - classification_loss: 0.0037
262/500 [==============>...............] - ETA: 1:50 - loss: 0.0611 - regression_loss: 0.0575 - classification_loss: 0.0036
263/500 [==============>...............] - ETA: 1:50 - loss: 0.0610 - regression_loss: 0.0574 - classification_loss: 0.0036
264/500 [==============>...............] - ETA: 1:49 - loss: 0.0611 - regression_loss: 0.0574 - classification_loss: 0.0037
265/500 [==============>...............] - ETA: 1:49 - loss: 0.0610 - regression_loss: 0.0573 - classification_loss: 0.0037
266/500 [==============>...............] - ETA: 1:48 - loss: 0.0612 - regression_loss: 0.0575 - classification_loss: 0.0037
267/500 [===============>..............] - ETA: 1:48 - loss: 0.0610 - regression_loss: 0.0574 - classification_loss: 0.0037
268/500 [===============>..............] - ETA: 1:47 - loss: 0.0610 - regression_loss: 0.0574 - classification_loss: 0.0036
269/500 [===============>..............] - ETA: 1:47 - loss: 0.0613 - regression_loss: 0.0576 - classification_loss: 0.0037
270/500 [===============>..............] - ETA: 1:47 - loss: 0.0611 - regression_loss: 0.0574 - classification_loss: 0.0037
271/500 [===============>..............] - ETA: 1:46 - loss: 0.0612 - regression_loss: 0.0575 - classification_loss: 0.0037
272/500 [===============>..............] - ETA: 1:46 - loss: 0.0612 - regression_loss: 0.0575 - classification_loss: 0.0037
273/500 [===============>..............] - ETA: 1:45 - loss: 0.0611 - regression_loss: 0.0574 - classification_loss: 0.0037
274/500 [===============>..............] - ETA: 1:45 - loss: 0.0610 - regression_loss: 0.0573 - classification_loss: 0.0037
275/500 [===============>..............] - ETA: 1:44 - loss: 0.0609 - regression_loss: 0.0573 - classification_loss: 0.0037
276/500 [===============>..............] - ETA: 1:44 - loss: 0.0612 - regression_loss: 0.0576 - classification_loss: 0.0037
277/500 [===============>..............] - ETA: 1:43 - loss: 0.0613 - regression_loss: 0.0576 - classification_loss: 0.0037
278/500 [===============>..............] - ETA: 1:43 - loss: 0.0611 - regression_loss: 0.0574 - classification_loss: 0.0037
279/500 [===============>..............] - ETA: 1:42 - loss: 0.0609 - regression_loss: 0.0573 - classification_loss: 0.0037
280/500 [===============>..............] - ETA: 1:42 - loss: 0.0608 - regression_loss: 0.0572 - classification_loss: 0.0037
281/500 [===============>..............] - ETA: 1:41 - loss: 0.0607 - regression_loss: 0.0571 - classification_loss: 0.0037
282/500 [===============>..............] - ETA: 1:41 - loss: 0.0608 - regression_loss: 0.0571 - classification_loss: 0.0037
283/500 [===============>..............] - ETA: 1:41 - loss: 0.0606 - regression_loss: 0.0569 - classification_loss: 0.0037
284/500 [================>.............] - ETA: 1:40 - loss: 0.0606 - regression_loss: 0.0569 - classification_loss: 0.0037
285/500 [================>.............] - ETA: 1:40 - loss: 0.0607 - regression_loss: 0.0570 - classification_loss: 0.0037
286/500 [================>.............] - ETA: 1:39 - loss: 0.0607 - regression_loss: 0.0570 - classification_loss: 0.0036
287/500 [================>.............] - ETA: 1:39 - loss: 0.0606 - regression_loss: 0.0570 - classification_loss: 0.0036
288/500 [================>.............] - ETA: 1:38 - loss: 0.0606 - regression_loss: 0.0570 - classification_loss: 0.0036
289/500 [================>.............] - ETA: 1:38 - loss: 0.0606 - regression_loss: 0.0570 - classification_loss: 0.0036
290/500 [================>.............] - ETA: 1:37 - loss: 0.0607 - regression_loss: 0.0570 - classification_loss: 0.0036
291/500 [================>.............] - ETA: 1:37 - loss: 0.0605 - regression_loss: 0.0569 - classification_loss: 0.0036
292/500 [================>.............] - ETA: 1:36 - loss: 0.0608 - regression_loss: 0.0572 - classification_loss: 0.0036
293/500 [================>.............] - ETA: 1:36 - loss: 0.0610 - regression_loss: 0.0574 - classification_loss: 0.0036
294/500 [================>.............] - ETA: 1:35 - loss: 0.0609 - regression_loss: 0.0573 - classification_loss: 0.0036
295/500 [================>.............] - ETA: 1:35 - loss: 0.0611 - regression_loss: 0.0575 - classification_loss: 0.0036
296/500 [================>.............] - ETA: 1:34 - loss: 0.0613 - regression_loss: 0.0577 - classification_loss: 0.0037
297/500 [================>.............] - ETA: 1:34 - loss: 0.0614 - regression_loss: 0.0578 - classification_loss: 0.0037
298/500 [================>.............] - ETA: 1:34 - loss: 0.0613 - regression_loss: 0.0577 - classification_loss: 0.0037
299/500 [================>.............] - ETA: 1:33 - loss: 0.0611 - regression_loss: 0.0575 - classification_loss: 0.0036
300/500 [=================>............] - ETA: 1:33 - loss: 0.0610 - regression_loss: 0.0574 - classification_loss: 0.0036
301/500 [=================>............] - ETA: 1:32 - loss: 0.0611 - regression_loss: 0.0574 - classification_loss: 0.0036
302/500 [=================>............] - ETA: 1:32 - loss: 0.0609 - regression_loss: 0.0573 - classification_loss: 0.0036
303/500 [=================>............] - ETA: 1:31 - loss: 0.0608 - regression_loss: 0.0572 - classification_loss: 0.0036
304/500 [=================>............] - ETA: 1:31 - loss: 0.0613 - regression_loss: 0.0577 - classification_loss: 0.0036
305/500 [=================>............] - ETA: 1:30 - loss: 0.0615 - regression_loss: 0.0578 - classification_loss: 0.0036
306/500 [=================>............] - ETA: 1:30 - loss: 0.0613 - regression_loss: 0.0577 - classification_loss: 0.0036
307/500 [=================>............] - ETA: 1:29 - loss: 0.0614 - regression_loss: 0.0578 - classification_loss: 0.0037
308/500 [=================>............] - ETA: 1:29 - loss: 0.0614 - regression_loss: 0.0578 - classification_loss: 0.0037
309/500 [=================>............] - ETA: 1:28 - loss: 0.0614 - regression_loss: 0.0577 - classification_loss: 0.0036
310/500 [=================>............] - ETA: 1:28 - loss: 0.0614 - regression_loss: 0.0577 - classification_loss: 0.0036
311/500 [=================>............] - ETA: 1:27 - loss: 0.0612 - regression_loss: 0.0576 - classification_loss: 0.0036
312/500 [=================>............] - ETA: 1:27 - loss: 0.0612 - regression_loss: 0.0576 - classification_loss: 0.0036
313/500 [=================>............] - ETA: 1:27 - loss: 0.0615 - regression_loss: 0.0578 - classification_loss: 0.0036
314/500 [=================>............] - ETA: 1:26 - loss: 0.0614 - regression_loss: 0.0577 - classification_loss: 0.0036
315/500 [=================>............] - ETA: 1:26 - loss: 0.0615 - regression_loss: 0.0579 - classification_loss: 0.0036
316/500 [=================>............] - ETA: 1:25 - loss: 0.0616 - regression_loss: 0.0579 - classification_loss: 0.0036
317/500 [==================>...........] - ETA: 1:25 - loss: 0.0614 - regression_loss: 0.0578 - classification_loss: 0.0036
318/500 [==================>...........] - ETA: 1:24 - loss: 0.0615 - regression_loss: 0.0578 - classification_loss: 0.0036
319/500 [==================>...........] - ETA: 1:24 - loss: 0.0614 - regression_loss: 0.0577 - classification_loss: 0.0036
320/500 [==================>...........] - ETA: 1:23 - loss: 0.0614 - regression_loss: 0.0577 - classification_loss: 0.0036
321/500 [==================>...........] - ETA: 1:23 - loss: 0.0615 - regression_loss: 0.0579 - classification_loss: 0.0036
322/500 [==================>...........] - ETA: 1:22 - loss: 0.0614 - regression_loss: 0.0578 - classification_loss: 0.0036
323/500 [==================>...........] - ETA: 1:22 - loss: 0.0615 - regression_loss: 0.0579 - classification_loss: 0.0036
324/500 [==================>...........] - ETA: 1:21 - loss: 0.0617 - regression_loss: 0.0581 - classification_loss: 0.0036
325/500 [==================>...........] - ETA: 1:21 - loss: 0.0616 - regression_loss: 0.0580 - classification_loss: 0.0036
326/500 [==================>...........] - ETA: 1:20 - loss: 0.0616 - regression_loss: 0.0579 - classification_loss: 0.0036
327/500 [==================>...........] - ETA: 1:20 - loss: 0.0615 - regression_loss: 0.0579 - classification_loss: 0.0036
328/500 [==================>...........] - ETA: 1:20 - loss: 0.0616 - regression_loss: 0.0580 - classification_loss: 0.0036
329/500 [==================>...........] - ETA: 1:19 - loss: 0.0616 - regression_loss: 0.0579 - classification_loss: 0.0036
330/500 [==================>...........] - ETA: 1:19 - loss: 0.0615 - regression_loss: 0.0579 - classification_loss: 0.0036
331/500 [==================>...........] - ETA: 1:18 - loss: 0.0615 - regression_loss: 0.0579 - classification_loss: 0.0036
332/500 [==================>...........] - ETA: 1:18 - loss: 0.0616 - regression_loss: 0.0580 - classification_loss: 0.0036
333/500 [==================>...........] - ETA: 1:17 - loss: 0.0616 - regression_loss: 0.0580 - classification_loss: 0.0036
334/500 [===================>..........] - ETA: 1:17 - loss: 0.0615 - regression_loss: 0.0579 - classification_loss: 0.0036
335/500 [===================>..........] - ETA: 1:16 - loss: 0.0614 - regression_loss: 0.0578 - classification_loss: 0.0036
336/500 [===================>..........] - ETA: 1:16 - loss: 0.0615 - regression_loss: 0.0578 - classification_loss: 0.0036
337/500 [===================>..........] - ETA: 1:15 - loss: 0.0614 - regression_loss: 0.0578 - classification_loss: 0.0036
338/500 [===================>..........] - ETA: 1:15 - loss: 0.0613 - regression_loss: 0.0577 - classification_loss: 0.0036
339/500 [===================>..........] - ETA: 1:14 - loss: 0.0613 - regression_loss: 0.0577 - classification_loss: 0.0036
340/500 [===================>..........] - ETA: 1:14 - loss: 0.0614 - regression_loss: 0.0578 - classification_loss: 0.0036
341/500 [===================>..........] - ETA: 1:14 - loss: 0.0613 - regression_loss: 0.0577 - classification_loss: 0.0036
342/500 [===================>..........] - ETA: 1:13 - loss: 0.0613 - regression_loss: 0.0577 - classification_loss: 0.0036
343/500 [===================>..........] - ETA: 1:13 - loss: 0.0612 - regression_loss: 0.0576 - classification_loss: 0.0036
344/500 [===================>..........] - ETA: 1:12 - loss: 0.0612 - regression_loss: 0.0576 - classification_loss: 0.0036
345/500 [===================>..........] - ETA: 1:12 - loss: 0.0612 - regression_loss: 0.0576 - classification_loss: 0.0036
346/500 [===================>..........] - ETA: 1:11 - loss: 0.0612 - regression_loss: 0.0576 - classification_loss: 0.0036
347/500 [===================>..........] - ETA: 1:11 - loss: 0.0611 - regression_loss: 0.0575 - classification_loss: 0.0036
348/500 [===================>..........] - ETA: 1:10 - loss: 0.0610 - regression_loss: 0.0574 - classification_loss: 0.0036
349/500 [===================>..........] - ETA: 1:10 - loss: 0.0609 - regression_loss: 0.0573 - classification_loss: 0.0036
350/500 [====================>.........] - ETA: 1:09 - loss: 0.0609 - regression_loss: 0.0573 - classification_loss: 0.0036
351/500 [====================>.........] - ETA: 1:09 - loss: 0.0610 - regression_loss: 0.0574 - classification_loss: 0.0036
352/500 [====================>.........] - ETA: 1:08 - loss: 0.0610 - regression_loss: 0.0574 - classification_loss: 0.0036
353/500 [====================>.........] - ETA: 1:08 - loss: 0.0608 - regression_loss: 0.0572 - classification_loss: 0.0036
354/500 [====================>.........] - ETA: 1:07 - loss: 0.0607 - regression_loss: 0.0571 - classification_loss: 0.0036
355/500 [====================>.........] - ETA: 1:07 - loss: 0.0606 - regression_loss: 0.0570 - classification_loss: 0.0036
356/500 [====================>.........] - ETA: 1:07 - loss: 0.0605 - regression_loss: 0.0569 - classification_loss: 0.0036
357/500 [====================>.........] - ETA: 1:06 - loss: 0.0604 - regression_loss: 0.0568 - classification_loss: 0.0036
358/500 [====================>.........] - ETA: 1:06 - loss: 0.0602 - regression_loss: 0.0567 - classification_loss: 0.0036
359/500 [====================>.........] - ETA: 1:05 - loss: 0.0603 - regression_loss: 0.0567 - classification_loss: 0.0036
360/500 [====================>.........] - ETA: 1:05 - loss: 0.0603 - regression_loss: 0.0567 - classification_loss: 0.0036
361/500 [====================>.........] - ETA: 1:04 - loss: 0.0604 - regression_loss: 0.0568 - classification_loss: 0.0036
362/500 [====================>.........] - ETA: 1:04 - loss: 0.0605 - regression_loss: 0.0570 - classification_loss: 0.0036
363/500 [====================>.........] - ETA: 1:03 - loss: 0.0604 - regression_loss: 0.0568 - classification_loss: 0.0036
364/500 [====================>.........] - ETA: 1:03 - loss: 0.0603 - regression_loss: 0.0568 - classification_loss: 0.0036
365/500 [====================>.........] - ETA: 1:02 - loss: 0.0602 - regression_loss: 0.0567 - classification_loss: 0.0036
366/500 [====================>.........] - ETA: 1:02 - loss: 0.0602 - regression_loss: 0.0566 - classification_loss: 0.0036
367/500 [=====================>........] - ETA: 1:01 - loss: 0.0601 - regression_loss: 0.0565 - classification_loss: 0.0036
368/500 [=====================>........] - ETA: 1:01 - loss: 0.0601 - regression_loss: 0.0566 - classification_loss: 0.0036
369/500 [=====================>........] - ETA: 1:00 - loss: 0.0601 - regression_loss: 0.0565 - classification_loss: 0.0036
370/500 [=====================>........] - ETA: 1:00 - loss: 0.0603 - regression_loss: 0.0567 - classification_loss: 0.0036
371/500 [=====================>........] - ETA: 1:00 - loss: 0.0606 - regression_loss: 0.0570 - classification_loss: 0.0036
372/500 [=====================>........] - ETA: 59s - loss: 0.0605 - regression_loss: 0.0570 - classification_loss: 0.0036 
373/500 [=====================>........] - ETA: 59s - loss: 0.0605 - regression_loss: 0.0569 - classification_loss: 0.0036
374/500 [=====================>........] - ETA: 58s - loss: 0.0604 - regression_loss: 0.0569 - classification_loss: 0.0036
375/500 [=====================>........] - ETA: 58s - loss: 0.0604 - regression_loss: 0.0569 - classification_loss: 0.0036
376/500 [=====================>........] - ETA: 57s - loss: 0.0603 - regression_loss: 0.0567 - classification_loss: 0.0036
377/500 [=====================>........] - ETA: 57s - loss: 0.0605 - regression_loss: 0.0569 - classification_loss: 0.0036
378/500 [=====================>........] - ETA: 56s - loss: 0.0604 - regression_loss: 0.0569 - classification_loss: 0.0036
379/500 [=====================>........] - ETA: 56s - loss: 0.0604 - regression_loss: 0.0568 - classification_loss: 0.0036
380/500 [=====================>........] - ETA: 55s - loss: 0.0603 - regression_loss: 0.0567 - classification_loss: 0.0036
381/500 [=====================>........] - ETA: 55s - loss: 0.0602 - regression_loss: 0.0566 - classification_loss: 0.0036
382/500 [=====================>........] - ETA: 54s - loss: 0.0602 - regression_loss: 0.0566 - classification_loss: 0.0036
383/500 [=====================>........] - ETA: 54s - loss: 0.0602 - regression_loss: 0.0567 - classification_loss: 0.0036
384/500 [======================>.......] - ETA: 53s - loss: 0.0603 - regression_loss: 0.0568 - classification_loss: 0.0036
385/500 [======================>.......] - ETA: 53s - loss: 0.0602 - regression_loss: 0.0567 - classification_loss: 0.0036
386/500 [======================>.......] - ETA: 53s - loss: 0.0601 - regression_loss: 0.0566 - classification_loss: 0.0036
387/500 [======================>.......] - ETA: 52s - loss: 0.0601 - regression_loss: 0.0565 - classification_loss: 0.0036
388/500 [======================>.......] - ETA: 52s - loss: 0.0600 - regression_loss: 0.0564 - classification_loss: 0.0035
389/500 [======================>.......] - ETA: 51s - loss: 0.0602 - regression_loss: 0.0566 - classification_loss: 0.0036
390/500 [======================>.......] - ETA: 51s - loss: 0.0600 - regression_loss: 0.0565 - classification_loss: 0.0036
391/500 [======================>.......] - ETA: 50s - loss: 0.0599 - regression_loss: 0.0564 - classification_loss: 0.0036
392/500 [======================>.......] - ETA: 50s - loss: 0.0598 - regression_loss: 0.0563 - classification_loss: 0.0035
393/500 [======================>.......] - ETA: 49s - loss: 0.0598 - regression_loss: 0.0562 - classification_loss: 0.0035
394/500 [======================>.......] - ETA: 49s - loss: 0.0598 - regression_loss: 0.0562 - classification_loss: 0.0036
395/500 [======================>.......] - ETA: 48s - loss: 0.0597 - regression_loss: 0.0562 - classification_loss: 0.0036
396/500 [======================>.......] - ETA: 48s - loss: 0.0597 - regression_loss: 0.0562 - classification_loss: 0.0035
397/500 [======================>.......] - ETA: 47s - loss: 0.0598 - regression_loss: 0.0562 - classification_loss: 0.0036
398/500 [======================>.......] - ETA: 47s - loss: 0.0598 - regression_loss: 0.0562 - classification_loss: 0.0036
399/500 [======================>.......] - ETA: 46s - loss: 0.0597 - regression_loss: 0.0562 - classification_loss: 0.0036
400/500 [=======================>......] - ETA: 46s - loss: 0.0597 - regression_loss: 0.0562 - classification_loss: 0.0035
401/500 [=======================>......] - ETA: 46s - loss: 0.0598 - regression_loss: 0.0562 - classification_loss: 0.0036
402/500 [=======================>......] - ETA: 45s - loss: 0.0598 - regression_loss: 0.0562 - classification_loss: 0.0036
403/500 [=======================>......] - ETA: 45s - loss: 0.0597 - regression_loss: 0.0561 - classification_loss: 0.0036
404/500 [=======================>......] - ETA: 44s - loss: 0.0595 - regression_loss: 0.0560 - classification_loss: 0.0035
405/500 [=======================>......] - ETA: 44s - loss: 0.0595 - regression_loss: 0.0559 - classification_loss: 0.0035
406/500 [=======================>......] - ETA: 43s - loss: 0.0594 - regression_loss: 0.0558 - classification_loss: 0.0035
407/500 [=======================>......] - ETA: 43s - loss: 0.0592 - regression_loss: 0.0557 - classification_loss: 0.0035
408/500 [=======================>......] - ETA: 42s - loss: 0.0592 - regression_loss: 0.0557 - classification_loss: 0.0035
409/500 [=======================>......] - ETA: 42s - loss: 0.0591 - regression_loss: 0.0556 - classification_loss: 0.0035
410/500 [=======================>......] - ETA: 41s - loss: 0.0591 - regression_loss: 0.0556 - classification_loss: 0.0035
411/500 [=======================>......] - ETA: 41s - loss: 0.0590 - regression_loss: 0.0555 - classification_loss: 0.0035
412/500 [=======================>......] - ETA: 40s - loss: 0.0590 - regression_loss: 0.0555 - classification_loss: 0.0035
413/500 [=======================>......] - ETA: 40s - loss: 0.0589 - regression_loss: 0.0554 - classification_loss: 0.0035
414/500 [=======================>......] - ETA: 40s - loss: 0.0588 - regression_loss: 0.0553 - classification_loss: 0.0035
415/500 [=======================>......] - ETA: 39s - loss: 0.0587 - regression_loss: 0.0552 - classification_loss: 0.0035
416/500 [=======================>......] - ETA: 39s - loss: 0.0589 - regression_loss: 0.0554 - classification_loss: 0.0035
417/500 [========================>.....] - ETA: 38s - loss: 0.0589 - regression_loss: 0.0553 - classification_loss: 0.0035
418/500 [========================>.....] - ETA: 38s - loss: 0.0590 - regression_loss: 0.0554 - classification_loss: 0.0035
419/500 [========================>.....] - ETA: 37s - loss: 0.0591 - regression_loss: 0.0556 - classification_loss: 0.0035
420/500 [========================>.....] - ETA: 37s - loss: 0.0591 - regression_loss: 0.0556 - classification_loss: 0.0035
421/500 [========================>.....] - ETA: 36s - loss: 0.0590 - regression_loss: 0.0555 - classification_loss: 0.0035
422/500 [========================>.....] - ETA: 36s - loss: 0.0591 - regression_loss: 0.0555 - classification_loss: 0.0035
423/500 [========================>.....] - ETA: 35s - loss: 0.0590 - regression_loss: 0.0555 - classification_loss: 0.0035
424/500 [========================>.....] - ETA: 35s - loss: 0.0590 - regression_loss: 0.0555 - classification_loss: 0.0035
425/500 [========================>.....] - ETA: 34s - loss: 0.0589 - regression_loss: 0.0554 - classification_loss: 0.0035
426/500 [========================>.....] - ETA: 34s - loss: 0.0590 - regression_loss: 0.0555 - classification_loss: 0.0035
427/500 [========================>.....] - ETA: 33s - loss: 0.0591 - regression_loss: 0.0556 - classification_loss: 0.0035
428/500 [========================>.....] - ETA: 33s - loss: 0.0590 - regression_loss: 0.0555 - classification_loss: 0.0035
429/500 [========================>.....] - ETA: 33s - loss: 0.0590 - regression_loss: 0.0555 - classification_loss: 0.0035
430/500 [========================>.....] - ETA: 32s - loss: 0.0589 - regression_loss: 0.0554 - classification_loss: 0.0035
431/500 [========================>.....] - ETA: 32s - loss: 0.0588 - regression_loss: 0.0554 - classification_loss: 0.0035
432/500 [========================>.....] - ETA: 31s - loss: 0.0587 - regression_loss: 0.0553 - classification_loss: 0.0035
433/500 [========================>.....] - ETA: 31s - loss: 0.0587 - regression_loss: 0.0552 - classification_loss: 0.0035
434/500 [=========================>....] - ETA: 30s - loss: 0.0588 - regression_loss: 0.0553 - classification_loss: 0.0035
435/500 [=========================>....] - ETA: 30s - loss: 0.0587 - regression_loss: 0.0552 - classification_loss: 0.0035
436/500 [=========================>....] - ETA: 29s - loss: 0.0586 - regression_loss: 0.0551 - classification_loss: 0.0035
437/500 [=========================>....] - ETA: 29s - loss: 0.0586 - regression_loss: 0.0551 - classification_loss: 0.0035
438/500 [=========================>....] - ETA: 28s - loss: 0.0585 - regression_loss: 0.0551 - classification_loss: 0.0035
439/500 [=========================>....] - ETA: 28s - loss: 0.0586 - regression_loss: 0.0551 - classification_loss: 0.0035
440/500 [=========================>....] - ETA: 27s - loss: 0.0586 - regression_loss: 0.0551 - classification_loss: 0.0035
441/500 [=========================>....] - ETA: 27s - loss: 0.0586 - regression_loss: 0.0551 - classification_loss: 0.0035
442/500 [=========================>....] - ETA: 26s - loss: 0.0585 - regression_loss: 0.0550 - classification_loss: 0.0035
443/500 [=========================>....] - ETA: 26s - loss: 0.0585 - regression_loss: 0.0550 - classification_loss: 0.0035
444/500 [=========================>....] - ETA: 26s - loss: 0.0586 - regression_loss: 0.0551 - classification_loss: 0.0035
445/500 [=========================>....] - ETA: 25s - loss: 0.0585 - regression_loss: 0.0550 - classification_loss: 0.0035
446/500 [=========================>....] - ETA: 25s - loss: 0.0585 - regression_loss: 0.0550 - classification_loss: 0.0035
447/500 [=========================>....] - ETA: 24s - loss: 0.0583 - regression_loss: 0.0549 - classification_loss: 0.0035
448/500 [=========================>....] - ETA: 24s - loss: 0.0584 - regression_loss: 0.0549 - classification_loss: 0.0035
449/500 [=========================>....] - ETA: 23s - loss: 0.0584 - regression_loss: 0.0549 - classification_loss: 0.0035
450/500 [==========================>...] - ETA: 23s - loss: 0.0584 - regression_loss: 0.0549 - classification_loss: 0.0035
451/500 [==========================>...] - ETA: 22s - loss: 0.0584 - regression_loss: 0.0549 - classification_loss: 0.0035
452/500 [==========================>...] - ETA: 22s - loss: 0.0584 - regression_loss: 0.0549 - classification_loss: 0.0035
453/500 [==========================>...] - ETA: 21s - loss: 0.0585 - regression_loss: 0.0550 - classification_loss: 0.0035
454/500 [==========================>...] - ETA: 21s - loss: 0.0585 - regression_loss: 0.0551 - classification_loss: 0.0035
455/500 [==========================>...] - ETA: 20s - loss: 0.0585 - regression_loss: 0.0550 - classification_loss: 0.0035
456/500 [==========================>...] - ETA: 20s - loss: 0.0585 - regression_loss: 0.0550 - classification_loss: 0.0035
457/500 [==========================>...] - ETA: 19s - loss: 0.0585 - regression_loss: 0.0550 - classification_loss: 0.0035
458/500 [==========================>...] - ETA: 19s - loss: 0.0584 - regression_loss: 0.0549 - classification_loss: 0.0035
459/500 [==========================>...] - ETA: 19s - loss: 0.0584 - regression_loss: 0.0549 - classification_loss: 0.0035
460/500 [==========================>...] - ETA: 18s - loss: 0.0585 - regression_loss: 0.0550 - classification_loss: 0.0035
461/500 [==========================>...] - ETA: 18s - loss: 0.0584 - regression_loss: 0.0550 - classification_loss: 0.0035
462/500 [==========================>...] - ETA: 17s - loss: 0.0584 - regression_loss: 0.0549 - classification_loss: 0.0035
463/500 [==========================>...] - ETA: 17s - loss: 0.0585 - regression_loss: 0.0550 - classification_loss: 0.0035
464/500 [==========================>...] - ETA: 16s - loss: 0.0584 - regression_loss: 0.0550 - classification_loss: 0.0035
465/500 [==========================>...] - ETA: 16s - loss: 0.0583 - regression_loss: 0.0549 - classification_loss: 0.0035
466/500 [==========================>...] - ETA: 15s - loss: 0.0584 - regression_loss: 0.0549 - classification_loss: 0.0035
467/500 [===========================>..] - ETA: 15s - loss: 0.0583 - regression_loss: 0.0548 - classification_loss: 0.0035
468/500 [===========================>..] - ETA: 14s - loss: 0.0582 - regression_loss: 0.0548 - classification_loss: 0.0035
469/500 [===========================>..] - ETA: 14s - loss: 0.0582 - regression_loss: 0.0548 - classification_loss: 0.0035
470/500 [===========================>..] - ETA: 13s - loss: 0.0583 - regression_loss: 0.0549 - classification_loss: 0.0035
471/500 [===========================>..] - ETA: 13s - loss: 0.0582 - regression_loss: 0.0548 - classification_loss: 0.0035
472/500 [===========================>..] - ETA: 13s - loss: 0.0583 - regression_loss: 0.0548 - classification_loss: 0.0035
473/500 [===========================>..] - ETA: 12s - loss: 0.0582 - regression_loss: 0.0547 - classification_loss: 0.0035
474/500 [===========================>..] - ETA: 12s - loss: 0.0582 - regression_loss: 0.0547 - classification_loss: 0.0035
475/500 [===========================>..] - ETA: 11s - loss: 0.0581 - regression_loss: 0.0546 - classification_loss: 0.0035
476/500 [===========================>..] - ETA: 11s - loss: 0.0580 - regression_loss: 0.0545 - classification_loss: 0.0035
477/500 [===========================>..] - ETA: 10s - loss: 0.0579 - regression_loss: 0.0545 - classification_loss: 0.0035
478/500 [===========================>..] - ETA: 10s - loss: 0.0579 - regression_loss: 0.0545 - classification_loss: 0.0035
479/500 [===========================>..] - ETA: 9s - loss: 0.0579 - regression_loss: 0.0545 - classification_loss: 0.0035 
480/500 [===========================>..] - ETA: 9s - loss: 0.0578 - regression_loss: 0.0544 - classification_loss: 0.0035
481/500 [===========================>..] - ETA: 8s - loss: 0.0580 - regression_loss: 0.0545 - classification_loss: 0.0035
482/500 [===========================>..] - ETA: 8s - loss: 0.0579 - regression_loss: 0.0544 - classification_loss: 0.0034
483/500 [===========================>..] - ETA: 7s - loss: 0.0580 - regression_loss: 0.0545 - classification_loss: 0.0035
484/500 [============================>.] - ETA: 7s - loss: 0.0580 - regression_loss: 0.0545 - classification_loss: 0.0035
485/500 [============================>.] - ETA: 6s - loss: 0.0580 - regression_loss: 0.0545 - classification_loss: 0.0035
486/500 [============================>.] - ETA: 6s - loss: 0.0580 - regression_loss: 0.0545 - classification_loss: 0.0034
487/500 [============================>.] - ETA: 6s - loss: 0.0581 - regression_loss: 0.0546 - classification_loss: 0.0034
488/500 [============================>.] - ETA: 5s - loss: 0.0581 - regression_loss: 0.0547 - classification_loss: 0.0034
489/500 [============================>.] - ETA: 5s - loss: 0.0582 - regression_loss: 0.0547 - classification_loss: 0.0034
490/500 [============================>.] - ETA: 4s - loss: 0.0583 - regression_loss: 0.0549 - classification_loss: 0.0035
491/500 [============================>.] - ETA: 4s - loss: 0.0584 - regression_loss: 0.0549 - classification_loss: 0.0034
492/500 [============================>.] - ETA: 3s - loss: 0.0583 - regression_loss: 0.0549 - classification_loss: 0.0034
493/500 [============================>.] - ETA: 3s - loss: 0.0584 - regression_loss: 0.0549 - classification_loss: 0.0035
494/500 [============================>.] - ETA: 2s - loss: 0.0583 - regression_loss: 0.0549 - classification_loss: 0.0034
495/500 [============================>.] - ETA: 2s - loss: 0.0582 - regression_loss: 0.0548 - classification_loss: 0.0034
496/500 [============================>.] - ETA: 1s - loss: 0.0581 - regression_loss: 0.0547 - classification_loss: 0.0034
497/500 [============================>.] - ETA: 1s - loss: 0.0581 - regression_loss: 0.0547 - classification_loss: 0.0034
498/500 [============================>.] - ETA: 0s - loss: 0.0580 - regression_loss: 0.0546 - classification_loss: 0.0034
499/500 [============================>.] - ETA: 0s - loss: 0.0581 - regression_loss: 0.0547 - classification_loss: 0.0034
500/500 [==============================] - 233s 465ms/step - loss: 0.0580 - regression_loss: 0.0546 - classification_loss: 0.0034
44 instances of class building with average precision: 0.8159
mAP: 0.8159

Epoch 00008: saving model to ./snapshots/resnet50_csv_08.h5
