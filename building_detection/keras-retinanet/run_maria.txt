Loading model, this may take a second...
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, None, None, 3 0                                            
__________________________________________________________________________________________________
padding_conv1 (ZeroPadding2D)   (None, None, None, 3 0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1 (Conv2D)                  (None, None, None, 6 9408        padding_conv1[0][0]              
__________________________________________________________________________________________________
bn_conv1 (BatchNormalization)   (None, None, None, 6 256         conv1[0][0]                      
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, None, None, 6 0           bn_conv1[0][0]                   
__________________________________________________________________________________________________
pool1 (MaxPooling2D)            (None, None, None, 6 0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
res2a_branch2a (Conv2D)         (None, None, None, 6 4096        pool1[0][0]                      
__________________________________________________________________________________________________
bn2a_branch2a (BatchNormalizati (None, None, None, 6 256         res2a_branch2a[0][0]             
__________________________________________________________________________________________________
res2a_branch2a_relu (Activation (None, None, None, 6 0           bn2a_branch2a[0][0]              
__________________________________________________________________________________________________
padding2a_branch2b (ZeroPadding (None, None, None, 6 0           res2a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res2a_branch2b (Conv2D)         (None, None, None, 6 36864       padding2a_branch2b[0][0]         
__________________________________________________________________________________________________
bn2a_branch2b (BatchNormalizati (None, None, None, 6 256         res2a_branch2b[0][0]             
__________________________________________________________________________________________________
res2a_branch2b_relu (Activation (None, None, None, 6 0           bn2a_branch2b[0][0]              
__________________________________________________________________________________________________
res2a_branch2c (Conv2D)         (None, None, None, 2 16384       res2a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res2a_branch1 (Conv2D)          (None, None, None, 2 16384       pool1[0][0]                      
__________________________________________________________________________________________________
bn2a_branch2c (BatchNormalizati (None, None, None, 2 1024        res2a_branch2c[0][0]             
__________________________________________________________________________________________________
bn2a_branch1 (BatchNormalizatio (None, None, None, 2 1024        res2a_branch1[0][0]              
__________________________________________________________________________________________________
res2a (Add)                     (None, None, None, 2 0           bn2a_branch2c[0][0]              
                                                                 bn2a_branch1[0][0]               
__________________________________________________________________________________________________
res2a_relu (Activation)         (None, None, None, 2 0           res2a[0][0]                      
__________________________________________________________________________________________________
res2b_branch2a (Conv2D)         (None, None, None, 6 16384       res2a_relu[0][0]                 
__________________________________________________________________________________________________
bn2b_branch2a (BatchNormalizati (None, None, None, 6 256         res2b_branch2a[0][0]             
__________________________________________________________________________________________________
res2b_branch2a_relu (Activation (None, None, None, 6 0           bn2b_branch2a[0][0]              
__________________________________________________________________________________________________
padding2b_branch2b (ZeroPadding (None, None, None, 6 0           res2b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res2b_branch2b (Conv2D)         (None, None, None, 6 36864       padding2b_branch2b[0][0]         
__________________________________________________________________________________________________
bn2b_branch2b (BatchNormalizati (None, None, None, 6 256         res2b_branch2b[0][0]             
__________________________________________________________________________________________________
res2b_branch2b_relu (Activation (None, None, None, 6 0           bn2b_branch2b[0][0]              
__________________________________________________________________________________________________
res2b_branch2c (Conv2D)         (None, None, None, 2 16384       res2b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn2b_branch2c (BatchNormalizati (None, None, None, 2 1024        res2b_branch2c[0][0]             
__________________________________________________________________________________________________
res2b (Add)                     (None, None, None, 2 0           bn2b_branch2c[0][0]              
                                                                 res2a_relu[0][0]                 
__________________________________________________________________________________________________
res2b_relu (Activation)         (None, None, None, 2 0           res2b[0][0]                      
__________________________________________________________________________________________________
res2c_branch2a (Conv2D)         (None, None, None, 6 16384       res2b_relu[0][0]                 
__________________________________________________________________________________________________
bn2c_branch2a (BatchNormalizati (None, None, None, 6 256         res2c_branch2a[0][0]             
__________________________________________________________________________________________________
res2c_branch2a_relu (Activation (None, None, None, 6 0           bn2c_branch2a[0][0]              
__________________________________________________________________________________________________
padding2c_branch2b (ZeroPadding (None, None, None, 6 0           res2c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res2c_branch2b (Conv2D)         (None, None, None, 6 36864       padding2c_branch2b[0][0]         
__________________________________________________________________________________________________
bn2c_branch2b (BatchNormalizati (None, None, None, 6 256         res2c_branch2b[0][0]             
__________________________________________________________________________________________________
res2c_branch2b_relu (Activation (None, None, None, 6 0           bn2c_branch2b[0][0]              
__________________________________________________________________________________________________
res2c_branch2c (Conv2D)         (None, None, None, 2 16384       res2c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn2c_branch2c (BatchNormalizati (None, None, None, 2 1024        res2c_branch2c[0][0]             
__________________________________________________________________________________________________
res2c (Add)                     (None, None, None, 2 0           bn2c_branch2c[0][0]              
                                                                 res2b_relu[0][0]                 
__________________________________________________________________________________________________
res2c_relu (Activation)         (None, None, None, 2 0           res2c[0][0]                      
__________________________________________________________________________________________________
res3a_branch2a (Conv2D)         (None, None, None, 1 32768       res2c_relu[0][0]                 
__________________________________________________________________________________________________
bn3a_branch2a (BatchNormalizati (None, None, None, 1 512         res3a_branch2a[0][0]             
__________________________________________________________________________________________________
res3a_branch2a_relu (Activation (None, None, None, 1 0           bn3a_branch2a[0][0]              
__________________________________________________________________________________________________
padding3a_branch2b (ZeroPadding (None, None, None, 1 0           res3a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3a_branch2b (Conv2D)         (None, None, None, 1 147456      padding3a_branch2b[0][0]         
__________________________________________________________________________________________________
bn3a_branch2b (BatchNormalizati (None, None, None, 1 512         res3a_branch2b[0][0]             
__________________________________________________________________________________________________
res3a_branch2b_relu (Activation (None, None, None, 1 0           bn3a_branch2b[0][0]              
__________________________________________________________________________________________________
res3a_branch2c (Conv2D)         (None, None, None, 5 65536       res3a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res3a_branch1 (Conv2D)          (None, None, None, 5 131072      res2c_relu[0][0]                 
__________________________________________________________________________________________________
bn3a_branch2c (BatchNormalizati (None, None, None, 5 2048        res3a_branch2c[0][0]             
__________________________________________________________________________________________________
bn3a_branch1 (BatchNormalizatio (None, None, None, 5 2048        res3a_branch1[0][0]              
__________________________________________________________________________________________________
res3a (Add)                     (None, None, None, 5 0           bn3a_branch2c[0][0]              
                                                                 bn3a_branch1[0][0]               
__________________________________________________________________________________________________
res3a_relu (Activation)         (None, None, None, 5 0           res3a[0][0]                      
__________________________________________________________________________________________________
res3b_branch2a (Conv2D)         (None, None, None, 1 65536       res3a_relu[0][0]                 
__________________________________________________________________________________________________
bn3b_branch2a (BatchNormalizati (None, None, None, 1 512         res3b_branch2a[0][0]             
__________________________________________________________________________________________________
res3b_branch2a_relu (Activation (None, None, None, 1 0           bn3b_branch2a[0][0]              
__________________________________________________________________________________________________
padding3b_branch2b (ZeroPadding (None, None, None, 1 0           res3b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3b_branch2b (Conv2D)         (None, None, None, 1 147456      padding3b_branch2b[0][0]         
__________________________________________________________________________________________________
bn3b_branch2b (BatchNormalizati (None, None, None, 1 512         res3b_branch2b[0][0]             
__________________________________________________________________________________________________
res3b_branch2b_relu (Activation (None, None, None, 1 0           bn3b_branch2b[0][0]              
__________________________________________________________________________________________________
res3b_branch2c (Conv2D)         (None, None, None, 5 65536       res3b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn3b_branch2c (BatchNormalizati (None, None, None, 5 2048        res3b_branch2c[0][0]             
__________________________________________________________________________________________________
res3b (Add)                     (None, None, None, 5 0           bn3b_branch2c[0][0]              
                                                                 res3a_relu[0][0]                 
__________________________________________________________________________________________________
res3b_relu (Activation)         (None, None, None, 5 0           res3b[0][0]                      
__________________________________________________________________________________________________
res3c_branch2a (Conv2D)         (None, None, None, 1 65536       res3b_relu[0][0]                 
__________________________________________________________________________________________________
bn3c_branch2a (BatchNormalizati (None, None, None, 1 512         res3c_branch2a[0][0]             
__________________________________________________________________________________________________
res3c_branch2a_relu (Activation (None, None, None, 1 0           bn3c_branch2a[0][0]              
__________________________________________________________________________________________________
padding3c_branch2b (ZeroPadding (None, None, None, 1 0           res3c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3c_branch2b (Conv2D)         (None, None, None, 1 147456      padding3c_branch2b[0][0]         
__________________________________________________________________________________________________
bn3c_branch2b (BatchNormalizati (None, None, None, 1 512         res3c_branch2b[0][0]             
__________________________________________________________________________________________________
res3c_branch2b_relu (Activation (None, None, None, 1 0           bn3c_branch2b[0][0]              
__________________________________________________________________________________________________
res3c_branch2c (Conv2D)         (None, None, None, 5 65536       res3c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn3c_branch2c (BatchNormalizati (None, None, None, 5 2048        res3c_branch2c[0][0]             
__________________________________________________________________________________________________
res3c (Add)                     (None, None, None, 5 0           bn3c_branch2c[0][0]              
                                                                 res3b_relu[0][0]                 
__________________________________________________________________________________________________
res3c_relu (Activation)         (None, None, None, 5 0           res3c[0][0]                      
__________________________________________________________________________________________________
res3d_branch2a (Conv2D)         (None, None, None, 1 65536       res3c_relu[0][0]                 
__________________________________________________________________________________________________
bn3d_branch2a (BatchNormalizati (None, None, None, 1 512         res3d_branch2a[0][0]             
__________________________________________________________________________________________________
res3d_branch2a_relu (Activation (None, None, None, 1 0           bn3d_branch2a[0][0]              
__________________________________________________________________________________________________
padding3d_branch2b (ZeroPadding (None, None, None, 1 0           res3d_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res3d_branch2b (Conv2D)         (None, None, None, 1 147456      padding3d_branch2b[0][0]         
__________________________________________________________________________________________________
bn3d_branch2b (BatchNormalizati (None, None, None, 1 512         res3d_branch2b[0][0]             
__________________________________________________________________________________________________
res3d_branch2b_relu (Activation (None, None, None, 1 0           bn3d_branch2b[0][0]              
__________________________________________________________________________________________________
res3d_branch2c (Conv2D)         (None, None, None, 5 65536       res3d_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn3d_branch2c (BatchNormalizati (None, None, None, 5 2048        res3d_branch2c[0][0]             
__________________________________________________________________________________________________
res3d (Add)                     (None, None, None, 5 0           bn3d_branch2c[0][0]              
                                                                 res3c_relu[0][0]                 
__________________________________________________________________________________________________
res3d_relu (Activation)         (None, None, None, 5 0           res3d[0][0]                      
__________________________________________________________________________________________________
res4a_branch2a (Conv2D)         (None, None, None, 2 131072      res3d_relu[0][0]                 
__________________________________________________________________________________________________
bn4a_branch2a (BatchNormalizati (None, None, None, 2 1024        res4a_branch2a[0][0]             
__________________________________________________________________________________________________
res4a_branch2a_relu (Activation (None, None, None, 2 0           bn4a_branch2a[0][0]              
__________________________________________________________________________________________________
padding4a_branch2b (ZeroPadding (None, None, None, 2 0           res4a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4a_branch2b (Conv2D)         (None, None, None, 2 589824      padding4a_branch2b[0][0]         
__________________________________________________________________________________________________
bn4a_branch2b (BatchNormalizati (None, None, None, 2 1024        res4a_branch2b[0][0]             
__________________________________________________________________________________________________
res4a_branch2b_relu (Activation (None, None, None, 2 0           bn4a_branch2b[0][0]              
__________________________________________________________________________________________________
res4a_branch2c (Conv2D)         (None, None, None, 1 262144      res4a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res4a_branch1 (Conv2D)          (None, None, None, 1 524288      res3d_relu[0][0]                 
__________________________________________________________________________________________________
bn4a_branch2c (BatchNormalizati (None, None, None, 1 4096        res4a_branch2c[0][0]             
__________________________________________________________________________________________________
bn4a_branch1 (BatchNormalizatio (None, None, None, 1 4096        res4a_branch1[0][0]              
__________________________________________________________________________________________________
res4a (Add)                     (None, None, None, 1 0           bn4a_branch2c[0][0]              
                                                                 bn4a_branch1[0][0]               
__________________________________________________________________________________________________
res4a_relu (Activation)         (None, None, None, 1 0           res4a[0][0]                      
__________________________________________________________________________________________________
res4b_branch2a (Conv2D)         (None, None, None, 2 262144      res4a_relu[0][0]                 
__________________________________________________________________________________________________
bn4b_branch2a (BatchNormalizati (None, None, None, 2 1024        res4b_branch2a[0][0]             
__________________________________________________________________________________________________
res4b_branch2a_relu (Activation (None, None, None, 2 0           bn4b_branch2a[0][0]              
__________________________________________________________________________________________________
padding4b_branch2b (ZeroPadding (None, None, None, 2 0           res4b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4b_branch2b (Conv2D)         (None, None, None, 2 589824      padding4b_branch2b[0][0]         
__________________________________________________________________________________________________
bn4b_branch2b (BatchNormalizati (None, None, None, 2 1024        res4b_branch2b[0][0]             
__________________________________________________________________________________________________
res4b_branch2b_relu (Activation (None, None, None, 2 0           bn4b_branch2b[0][0]              
__________________________________________________________________________________________________
res4b_branch2c (Conv2D)         (None, None, None, 1 262144      res4b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4b_branch2c (BatchNormalizati (None, None, None, 1 4096        res4b_branch2c[0][0]             
__________________________________________________________________________________________________
res4b (Add)                     (None, None, None, 1 0           bn4b_branch2c[0][0]              
                                                                 res4a_relu[0][0]                 
__________________________________________________________________________________________________
res4b_relu (Activation)         (None, None, None, 1 0           res4b[0][0]                      
__________________________________________________________________________________________________
res4c_branch2a (Conv2D)         (None, None, None, 2 262144      res4b_relu[0][0]                 
__________________________________________________________________________________________________
bn4c_branch2a (BatchNormalizati (None, None, None, 2 1024        res4c_branch2a[0][0]             
__________________________________________________________________________________________________
res4c_branch2a_relu (Activation (None, None, None, 2 0           bn4c_branch2a[0][0]              
__________________________________________________________________________________________________
padding4c_branch2b (ZeroPadding (None, None, None, 2 0           res4c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4c_branch2b (Conv2D)         (None, None, None, 2 589824      padding4c_branch2b[0][0]         
__________________________________________________________________________________________________
bn4c_branch2b (BatchNormalizati (None, None, None, 2 1024        res4c_branch2b[0][0]             
__________________________________________________________________________________________________
res4c_branch2b_relu (Activation (None, None, None, 2 0           bn4c_branch2b[0][0]              
__________________________________________________________________________________________________
res4c_branch2c (Conv2D)         (None, None, None, 1 262144      res4c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4c_branch2c (BatchNormalizati (None, None, None, 1 4096        res4c_branch2c[0][0]             
__________________________________________________________________________________________________
res4c (Add)                     (None, None, None, 1 0           bn4c_branch2c[0][0]              
                                                                 res4b_relu[0][0]                 
__________________________________________________________________________________________________
res4c_relu (Activation)         (None, None, None, 1 0           res4c[0][0]                      
__________________________________________________________________________________________________
res4d_branch2a (Conv2D)         (None, None, None, 2 262144      res4c_relu[0][0]                 
__________________________________________________________________________________________________
bn4d_branch2a (BatchNormalizati (None, None, None, 2 1024        res4d_branch2a[0][0]             
__________________________________________________________________________________________________
res4d_branch2a_relu (Activation (None, None, None, 2 0           bn4d_branch2a[0][0]              
__________________________________________________________________________________________________
padding4d_branch2b (ZeroPadding (None, None, None, 2 0           res4d_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4d_branch2b (Conv2D)         (None, None, None, 2 589824      padding4d_branch2b[0][0]         
__________________________________________________________________________________________________
bn4d_branch2b (BatchNormalizati (None, None, None, 2 1024        res4d_branch2b[0][0]             
__________________________________________________________________________________________________
res4d_branch2b_relu (Activation (None, None, None, 2 0           bn4d_branch2b[0][0]              
__________________________________________________________________________________________________
res4d_branch2c (Conv2D)         (None, None, None, 1 262144      res4d_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4d_branch2c (BatchNormalizati (None, None, None, 1 4096        res4d_branch2c[0][0]             
__________________________________________________________________________________________________
res4d (Add)                     (None, None, None, 1 0           bn4d_branch2c[0][0]              
                                                                 res4c_relu[0][0]                 
__________________________________________________________________________________________________
res4d_relu (Activation)         (None, None, None, 1 0           res4d[0][0]                      
__________________________________________________________________________________________________
res4e_branch2a (Conv2D)         (None, None, None, 2 262144      res4d_relu[0][0]                 
__________________________________________________________________________________________________
bn4e_branch2a (BatchNormalizati (None, None, None, 2 1024        res4e_branch2a[0][0]             
__________________________________________________________________________________________________
res4e_branch2a_relu (Activation (None, None, None, 2 0           bn4e_branch2a[0][0]              
__________________________________________________________________________________________________
padding4e_branch2b (ZeroPadding (None, None, None, 2 0           res4e_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4e_branch2b (Conv2D)         (None, None, None, 2 589824      padding4e_branch2b[0][0]         
__________________________________________________________________________________________________
bn4e_branch2b (BatchNormalizati (None, None, None, 2 1024        res4e_branch2b[0][0]             
__________________________________________________________________________________________________
res4e_branch2b_relu (Activation (None, None, None, 2 0           bn4e_branch2b[0][0]              
__________________________________________________________________________________________________
res4e_branch2c (Conv2D)         (None, None, None, 1 262144      res4e_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4e_branch2c (BatchNormalizati (None, None, None, 1 4096        res4e_branch2c[0][0]             
__________________________________________________________________________________________________
res4e (Add)                     (None, None, None, 1 0           bn4e_branch2c[0][0]              
                                                                 res4d_relu[0][0]                 
__________________________________________________________________________________________________
res4e_relu (Activation)         (None, None, None, 1 0           res4e[0][0]                      
__________________________________________________________________________________________________
res4f_branch2a (Conv2D)         (None, None, None, 2 262144      res4e_relu[0][0]                 
__________________________________________________________________________________________________
bn4f_branch2a (BatchNormalizati (None, None, None, 2 1024        res4f_branch2a[0][0]             
__________________________________________________________________________________________________
res4f_branch2a_relu (Activation (None, None, None, 2 0           bn4f_branch2a[0][0]              
__________________________________________________________________________________________________
padding4f_branch2b (ZeroPadding (None, None, None, 2 0           res4f_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res4f_branch2b (Conv2D)         (None, None, None, 2 589824      padding4f_branch2b[0][0]         
__________________________________________________________________________________________________
bn4f_branch2b (BatchNormalizati (None, None, None, 2 1024        res4f_branch2b[0][0]             
__________________________________________________________________________________________________
res4f_branch2b_relu (Activation (None, None, None, 2 0           bn4f_branch2b[0][0]              
__________________________________________________________________________________________________
res4f_branch2c (Conv2D)         (None, None, None, 1 262144      res4f_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn4f_branch2c (BatchNormalizati (None, None, None, 1 4096        res4f_branch2c[0][0]             
__________________________________________________________________________________________________
res4f (Add)                     (None, None, None, 1 0           bn4f_branch2c[0][0]              
                                                                 res4e_relu[0][0]                 
__________________________________________________________________________________________________
res4f_relu (Activation)         (None, None, None, 1 0           res4f[0][0]                      
__________________________________________________________________________________________________
res5a_branch2a (Conv2D)         (None, None, None, 5 524288      res4f_relu[0][0]                 
__________________________________________________________________________________________________
bn5a_branch2a (BatchNormalizati (None, None, None, 5 2048        res5a_branch2a[0][0]             
__________________________________________________________________________________________________
res5a_branch2a_relu (Activation (None, None, None, 5 0           bn5a_branch2a[0][0]              
__________________________________________________________________________________________________
padding5a_branch2b (ZeroPadding (None, None, None, 5 0           res5a_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res5a_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5a_branch2b[0][0]         
__________________________________________________________________________________________________
bn5a_branch2b (BatchNormalizati (None, None, None, 5 2048        res5a_branch2b[0][0]             
__________________________________________________________________________________________________
res5a_branch2b_relu (Activation (None, None, None, 5 0           bn5a_branch2b[0][0]              
__________________________________________________________________________________________________
res5a_branch2c (Conv2D)         (None, None, None, 2 1048576     res5a_branch2b_relu[0][0]        
__________________________________________________________________________________________________
res5a_branch1 (Conv2D)          (None, None, None, 2 2097152     res4f_relu[0][0]                 
__________________________________________________________________________________________________
bn5a_branch2c (BatchNormalizati (None, None, None, 2 8192        res5a_branch2c[0][0]             
__________________________________________________________________________________________________
bn5a_branch1 (BatchNormalizatio (None, None, None, 2 8192        res5a_branch1[0][0]              
__________________________________________________________________________________________________
res5a (Add)                     (None, None, None, 2 0           bn5a_branch2c[0][0]              
                                                                 bn5a_branch1[0][0]               
__________________________________________________________________________________________________
res5a_relu (Activation)         (None, None, None, 2 0           res5a[0][0]                      
__________________________________________________________________________________________________
res5b_branch2a (Conv2D)         (None, None, None, 5 1048576     res5a_relu[0][0]                 
__________________________________________________________________________________________________
bn5b_branch2a (BatchNormalizati (None, None, None, 5 2048        res5b_branch2a[0][0]             
__________________________________________________________________________________________________
res5b_branch2a_relu (Activation (None, None, None, 5 0           bn5b_branch2a[0][0]              
__________________________________________________________________________________________________
padding5b_branch2b (ZeroPadding (None, None, None, 5 0           res5b_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res5b_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5b_branch2b[0][0]         
__________________________________________________________________________________________________
bn5b_branch2b (BatchNormalizati (None, None, None, 5 2048        res5b_branch2b[0][0]             
__________________________________________________________________________________________________
res5b_branch2b_relu (Activation (None, None, None, 5 0           bn5b_branch2b[0][0]              
__________________________________________________________________________________________________
res5b_branch2c (Conv2D)         (None, None, None, 2 1048576     res5b_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn5b_branch2c (BatchNormalizati (None, None, None, 2 8192        res5b_branch2c[0][0]             
__________________________________________________________________________________________________
res5b (Add)                     (None, None, None, 2 0           bn5b_branch2c[0][0]              
                                                                 res5a_relu[0][0]                 
__________________________________________________________________________________________________
res5b_relu (Activation)         (None, None, None, 2 0           res5b[0][0]                      
__________________________________________________________________________________________________
res5c_branch2a (Conv2D)         (None, None, None, 5 1048576     res5b_relu[0][0]                 
__________________________________________________________________________________________________
bn5c_branch2a (BatchNormalizati (None, None, None, 5 2048        res5c_branch2a[0][0]             
__________________________________________________________________________________________________
res5c_branch2a_relu (Activation (None, None, None, 5 0           bn5c_branch2a[0][0]              
__________________________________________________________________________________________________
padding5c_branch2b (ZeroPadding (None, None, None, 5 0           res5c_branch2a_relu[0][0]        
__________________________________________________________________________________________________
res5c_branch2b (Conv2D)         (None, None, None, 5 2359296     padding5c_branch2b[0][0]         
__________________________________________________________________________________________________
bn5c_branch2b (BatchNormalizati (None, None, None, 5 2048        res5c_branch2b[0][0]             
__________________________________________________________________________________________________
res5c_branch2b_relu (Activation (None, None, None, 5 0           bn5c_branch2b[0][0]              
__________________________________________________________________________________________________
res5c_branch2c (Conv2D)         (None, None, None, 2 1048576     res5c_branch2b_relu[0][0]        
__________________________________________________________________________________________________
bn5c_branch2c (BatchNormalizati (None, None, None, 2 8192        res5c_branch2c[0][0]             
__________________________________________________________________________________________________
res5c (Add)                     (None, None, None, 2 0           bn5c_branch2c[0][0]              
                                                                 res5b_relu[0][0]                 
__________________________________________________________________________________________________
res5c_relu (Activation)         (None, None, None, 2 0           res5c[0][0]                      
__________________________________________________________________________________________________
C5_reduced (Conv2D)             (None, None, None, 2 524544      res5c_relu[0][0]                 
__________________________________________________________________________________________________
P5_upsampled (UpsampleLike)     (None, None, None, 2 0           C5_reduced[0][0]                 
                                                                 res4f_relu[0][0]                 
__________________________________________________________________________________________________
C4_reduced (Conv2D)             (None, None, None, 2 262400      res4f_relu[0][0]                 
__________________________________________________________________________________________________
P4_merged (Add)                 (None, None, None, 2 0           P5_upsampled[0][0]               
                                                                 C4_reduced[0][0]                 
__________________________________________________________________________________________________
P4_upsampled (UpsampleLike)     (None, None, None, 2 0           P4_merged[0][0]                  
                                                                 res3d_relu[0][0]                 
__________________________________________________________________________________________________
C3_reduced (Conv2D)             (None, None, None, 2 131328      res3d_relu[0][0]                 
__________________________________________________________________________________________________
P6 (Conv2D)                     (None, None, None, 2 4718848     res5c_relu[0][0]                 
__________________________________________________________________________________________________
P3_merged (Add)                 (None, None, None, 2 0           P4_upsampled[0][0]               
                                                                 C3_reduced[0][0]                 
__________________________________________________________________________________________________
C6_relu (Activation)            (None, None, None, 2 0           P6[0][0]                         
__________________________________________________________________________________________________
P3 (Conv2D)                     (None, None, None, 2 590080      P3_merged[0][0]                  
__________________________________________________________________________________________________
P4 (Conv2D)                     (None, None, None, 2 590080      P4_merged[0][0]                  
__________________________________________________________________________________________________
P5 (Conv2D)                     (None, None, None, 2 590080      C5_reduced[0][0]                 
__________________________________________________________________________________________________
P7 (Conv2D)                     (None, None, None, 2 590080      C6_relu[0][0]                    
__________________________________________________________________________________________________
regression_submodel (Model)     (None, None, 4)      2443300     P3[0][0]                         
                                                                 P4[0][0]                         
                                                                 P5[0][0]                         
                                                                 P6[0][0]                         
                                                                 P7[0][0]                         
__________________________________________________________________________________________________
classification_submodel (Model) (None, None, 1)      2381065     P3[0][0]                         
                                                                 P4[0][0]                         
                                                                 P5[0][0]                         
                                                                 P6[0][0]                         
                                                                 P7[0][0]                         
__________________________________________________________________________________________________
regression (Concatenate)        (None, None, 4)      0           regression_submodel[1][0]        
                                                                 regression_submodel[2][0]        
                                                                 regression_submodel[3][0]        
                                                                 regression_submodel[4][0]        
                                                                 regression_submodel[5][0]        
__________________________________________________________________________________________________
classification (Concatenate)    (None, None, 1)      0           classification_submodel[1][0]    
                                                                 classification_submodel[2][0]    
                                                                 classification_submodel[3][0]    
                                                                 classification_submodel[4][0]    
                                                                 classification_submodel[5][0]    
==================================================================================================
Total params: 36,382,957
Trainable params: 36,276,717
Non-trainable params: 106,240
__________________________________________________________________________________________________
None
Epoch 1/40

  1/200 [..............................] - ETA: 52:17 - loss: 1.3250 - regression_loss: 1.1867 - classification_loss: 0.1383
  2/200 [..............................] - ETA: 43:44 - loss: 1.4308 - regression_loss: 1.2618 - classification_loss: 0.1690
  3/200 [..............................] - ETA: 40:38 - loss: 1.3324 - regression_loss: 1.1760 - classification_loss: 0.1564
  4/200 [..............................] - ETA: 39:07 - loss: 1.2964 - regression_loss: 1.1435 - classification_loss: 0.1529
  5/200 [..............................] - ETA: 37:50 - loss: 1.2567 - regression_loss: 1.1090 - classification_loss: 0.1477
  6/200 [..............................] - ETA: 36:48 - loss: 1.2492 - regression_loss: 1.0989 - classification_loss: 0.1503
  7/200 [>.............................] - ETA: 36:02 - loss: 1.2482 - regression_loss: 1.0971 - classification_loss: 0.1511
  8/200 [>.............................] - ETA: 35:24 - loss: 1.2459 - regression_loss: 1.0952 - classification_loss: 0.1507
  9/200 [>.............................] - ETA: 34:54 - loss: 1.2565 - regression_loss: 1.1070 - classification_loss: 0.1495
 10/200 [>.............................] - ETA: 34:28 - loss: 1.2295 - regression_loss: 1.0841 - classification_loss: 0.1453
 11/200 [>.............................] - ETA: 34:03 - loss: 1.2226 - regression_loss: 1.0782 - classification_loss: 0.1443
 12/200 [>.............................] - ETA: 33:42 - loss: 1.2169 - regression_loss: 1.0730 - classification_loss: 0.1439
 13/200 [>.............................] - ETA: 33:21 - loss: 1.2094 - regression_loss: 1.0669 - classification_loss: 0.1425
 14/200 [=>............................] - ETA: 33:03 - loss: 1.1939 - regression_loss: 1.0543 - classification_loss: 0.1396
 15/200 [=>............................] - ETA: 32:47 - loss: 1.1811 - regression_loss: 1.0438 - classification_loss: 0.1373
 16/200 [=>............................] - ETA: 32:29 - loss: 1.1755 - regression_loss: 1.0386 - classification_loss: 0.1369
 17/200 [=>............................] - ETA: 32:14 - loss: 1.1805 - regression_loss: 1.0424 - classification_loss: 0.1380
 18/200 [=>............................] - ETA: 31:58 - loss: 1.1708 - regression_loss: 1.0341 - classification_loss: 0.1367
 19/200 [=>............................] - ETA: 31:44 - loss: 1.1637 - regression_loss: 1.0278 - classification_loss: 0.1359
 20/200 [==>...........................] - ETA: 31:30 - loss: 1.1886 - regression_loss: 1.0491 - classification_loss: 0.1395
 21/200 [==>...........................] - ETA: 31:16 - loss: 1.1834 - regression_loss: 1.0447 - classification_loss: 0.1388
 22/200 [==>...........................] - ETA: 31:02 - loss: 1.1810 - regression_loss: 1.0428 - classification_loss: 0.1382
 23/200 [==>...........................] - ETA: 30:55 - loss: 1.1767 - regression_loss: 1.0388 - classification_loss: 0.1379
 24/200 [==>...........................] - ETA: 30:42 - loss: 1.1783 - regression_loss: 1.0398 - classification_loss: 0.1385
 25/200 [==>...........................] - ETA: 30:29 - loss: 1.1676 - regression_loss: 1.0311 - classification_loss: 0.1365
 26/200 [==>...........................] - ETA: 30:16 - loss: 1.1566 - regression_loss: 1.0218 - classification_loss: 0.1348
 27/200 [===>..........................] - ETA: 30:05 - loss: 1.1521 - regression_loss: 1.0180 - classification_loss: 0.1341
 28/200 [===>..........................] - ETA: 29:52 - loss: 1.1496 - regression_loss: 1.0160 - classification_loss: 0.1336
 29/200 [===>..........................] - ETA: 29:40 - loss: 1.1492 - regression_loss: 1.0150 - classification_loss: 0.1341
 30/200 [===>..........................] - ETA: 29:29 - loss: 1.1497 - regression_loss: 1.0158 - classification_loss: 0.1339
 31/200 [===>..........................] - ETA: 29:17 - loss: 1.1509 - regression_loss: 1.0168 - classification_loss: 0.1341
 32/200 [===>..........................] - ETA: 29:05 - loss: 1.1521 - regression_loss: 1.0180 - classification_loss: 0.1341
 33/200 [===>..........................] - ETA: 28:54 - loss: 1.1482 - regression_loss: 1.0146 - classification_loss: 0.1336
 34/200 [====>.........................] - ETA: 28:42 - loss: 1.1544 - regression_loss: 1.0197 - classification_loss: 0.1348
 35/200 [====>.........................] - ETA: 28:31 - loss: 1.1490 - regression_loss: 1.0149 - classification_loss: 0.1340
 36/200 [====>.........................] - ETA: 28:19 - loss: 1.1463 - regression_loss: 1.0128 - classification_loss: 0.1334
 37/200 [====>.........................] - ETA: 28:07 - loss: 1.1430 - regression_loss: 1.0103 - classification_loss: 0.1327
 38/200 [====>.........................] - ETA: 27:56 - loss: 1.1414 - regression_loss: 1.0090 - classification_loss: 0.1323
 39/200 [====>.........................] - ETA: 27:48 - loss: 1.1406 - regression_loss: 1.0086 - classification_loss: 0.1320
 40/200 [=====>........................] - ETA: 27:40 - loss: 1.1423 - regression_loss: 1.0100 - classification_loss: 0.1323
 41/200 [=====>........................] - ETA: 27:31 - loss: 1.1368 - regression_loss: 1.0055 - classification_loss: 0.1314
 42/200 [=====>........................] - ETA: 27:22 - loss: 1.1383 - regression_loss: 1.0065 - classification_loss: 0.1318
 43/200 [=====>........................] - ETA: 27:13 - loss: 1.1365 - regression_loss: 1.0049 - classification_loss: 0.1316
 44/200 [=====>........................] - ETA: 27:04 - loss: 1.1366 - regression_loss: 1.0048 - classification_loss: 0.1318
 45/200 [=====>........................] - ETA: 26:56 - loss: 1.1331 - regression_loss: 1.0019 - classification_loss: 0.1311
 46/200 [=====>........................] - ETA: 26:49 - loss: 1.1309 - regression_loss: 1.0001 - classification_loss: 0.1307
 47/200 [======>.......................] - ETA: 26:37 - loss: 1.1394 - regression_loss: 1.0069 - classification_loss: 0.1325
 48/200 [======>.......................] - ETA: 26:25 - loss: 1.1447 - regression_loss: 1.0119 - classification_loss: 0.1328
 49/200 [======>.......................] - ETA: 26:14 - loss: 1.1433 - regression_loss: 1.0107 - classification_loss: 0.1325
 50/200 [======>.......................] - ETA: 26:03 - loss: 1.1383 - regression_loss: 1.0066 - classification_loss: 0.1317
 51/200 [======>.......................] - ETA: 25:51 - loss: 1.1403 - regression_loss: 1.0084 - classification_loss: 0.1319
 52/200 [======>.......................] - ETA: 25:40 - loss: 1.1419 - regression_loss: 1.0094 - classification_loss: 0.1326
 53/200 [======>.......................] - ETA: 25:29 - loss: 1.1385 - regression_loss: 1.0066 - classification_loss: 0.1319
 54/200 [=======>......................] - ETA: 25:18 - loss: 1.1397 - regression_loss: 1.0076 - classification_loss: 0.1321
 55/200 [=======>......................] - ETA: 25:07 - loss: 1.1367 - regression_loss: 1.0052 - classification_loss: 0.1315
 56/200 [=======>......................] - ETA: 24:58 - loss: 1.1345 - regression_loss: 1.0032 - classification_loss: 0.1313
 57/200 [=======>......................] - ETA: 24:48 - loss: 1.1367 - regression_loss: 1.0052 - classification_loss: 0.1315
 58/200 [=======>......................] - ETA: 24:37 - loss: 1.1323 - regression_loss: 1.0014 - classification_loss: 0.1309
 59/200 [=======>......................] - ETA: 24:26 - loss: 1.1289 - regression_loss: 0.9986 - classification_loss: 0.1303
 60/200 [========>.....................] - ETA: 24:15 - loss: 1.1332 - regression_loss: 1.0022 - classification_loss: 0.1310
 61/200 [========>.....................] - ETA: 24:04 - loss: 1.1338 - regression_loss: 1.0026 - classification_loss: 0.1312
 62/200 [========>.....................] - ETA: 23:53 - loss: 1.1324 - regression_loss: 1.0012 - classification_loss: 0.1312
 63/200 [========>.....................] - ETA: 23:42 - loss: 1.1330 - regression_loss: 1.0018 - classification_loss: 0.1313
 64/200 [========>.....................] - ETA: 23:31 - loss: 1.1340 - regression_loss: 1.0024 - classification_loss: 0.1317
 65/200 [========>.....................] - ETA: 23:20 - loss: 1.1487 - regression_loss: 1.0120 - classification_loss: 0.1367
 66/200 [========>.....................] - ETA: 23:10 - loss: 1.1479 - regression_loss: 1.0113 - classification_loss: 0.1366
 67/200 [=========>....................] - ETA: 23:01 - loss: 1.1491 - regression_loss: 1.0124 - classification_loss: 0.1367
 68/200 [=========>....................] - ETA: 22:51 - loss: 1.1493 - regression_loss: 1.0126 - classification_loss: 0.1367
 69/200 [=========>....................] - ETA: 22:40 - loss: 1.1462 - regression_loss: 1.0099 - classification_loss: 0.1363
 70/200 [=========>....................] - ETA: 22:31 - loss: 1.1464 - regression_loss: 1.0100 - classification_loss: 0.1364
 71/200 [=========>....................] - ETA: 22:21 - loss: 1.1469 - regression_loss: 1.0106 - classification_loss: 0.1363
 72/200 [=========>....................] - ETA: 22:10 - loss: 1.1486 - regression_loss: 1.0121 - classification_loss: 0.1365
 73/200 [=========>....................] - ETA: 21:59 - loss: 1.1457 - regression_loss: 1.0092 - classification_loss: 0.1365
 74/200 [==========>...................] - ETA: 21:48 - loss: 1.1443 - regression_loss: 1.0079 - classification_loss: 0.1364
 75/200 [==========>...................] - ETA: 21:37 - loss: 1.1424 - regression_loss: 1.0062 - classification_loss: 0.1362
 76/200 [==========>...................] - ETA: 21:26 - loss: 1.1440 - regression_loss: 1.0075 - classification_loss: 0.1365
 77/200 [==========>...................] - ETA: 21:15 - loss: 1.1521 - regression_loss: 1.0144 - classification_loss: 0.1377
 78/200 [==========>...................] - ETA: 21:05 - loss: 1.1549 - regression_loss: 1.0169 - classification_loss: 0.1380
 79/200 [==========>...................] - ETA: 20:55 - loss: 1.1536 - regression_loss: 1.0159 - classification_loss: 0.1377
 80/200 [===========>..................] - ETA: 20:45 - loss: 1.1540 - regression_loss: 1.0163 - classification_loss: 0.1377
 81/200 [===========>..................] - ETA: 20:34 - loss: 1.1530 - regression_loss: 1.0153 - classification_loss: 0.1377
 82/200 [===========>..................] - ETA: 20:24 - loss: 1.1521 - regression_loss: 1.0148 - classification_loss: 0.1373
 83/200 [===========>..................] - ETA: 20:14 - loss: 1.1505 - regression_loss: 1.0132 - classification_loss: 0.1373
 84/200 [===========>..................] - ETA: 20:04 - loss: 1.1508 - regression_loss: 1.0137 - classification_loss: 0.1371
 85/200 [===========>..................] - ETA: 19:54 - loss: 1.1506 - regression_loss: 1.0135 - classification_loss: 0.1371
 86/200 [===========>..................] - ETA: 19:43 - loss: 1.1517 - regression_loss: 1.0142 - classification_loss: 0.1375
 87/200 [============>.................] - ETA: 19:32 - loss: 1.1513 - regression_loss: 1.0139 - classification_loss: 0.1374
 88/200 [============>.................] - ETA: 19:22 - loss: 1.1491 - regression_loss: 1.0121 - classification_loss: 0.1369
 89/200 [============>.................] - ETA: 19:11 - loss: 1.1507 - regression_loss: 1.0135 - classification_loss: 0.1372
 90/200 [============>.................] - ETA: 19:00 - loss: 1.1496 - regression_loss: 1.0128 - classification_loss: 0.1368
 91/200 [============>.................] - ETA: 18:49 - loss: 1.1482 - regression_loss: 1.0116 - classification_loss: 0.1366
 92/200 [============>.................] - ETA: 18:39 - loss: 1.1504 - regression_loss: 1.0136 - classification_loss: 0.1368
 93/200 [============>.................] - ETA: 18:29 - loss: 1.1481 - regression_loss: 1.0116 - classification_loss: 0.1365
 94/200 [=============>................] - ETA: 18:19 - loss: 1.1488 - regression_loss: 1.0124 - classification_loss: 0.1364
 95/200 [=============>................] - ETA: 18:09 - loss: 1.1474 - regression_loss: 1.0111 - classification_loss: 0.1363
 96/200 [=============>................] - ETA: 17:59 - loss: 1.1466 - regression_loss: 1.0103 - classification_loss: 0.1364
 97/200 [=============>................] - ETA: 17:49 - loss: 1.1449 - regression_loss: 1.0088 - classification_loss: 0.1362
 98/200 [=============>................] - ETA: 17:38 - loss: 1.1451 - regression_loss: 1.0089 - classification_loss: 0.1361
 99/200 [=============>................] - ETA: 17:28 - loss: 1.1434 - regression_loss: 1.0077 - classification_loss: 0.1357
100/200 [==============>...............] - ETA: 17:17 - loss: 1.1407 - regression_loss: 1.0055 - classification_loss: 0.1353
101/200 [==============>...............] - ETA: 17:08 - loss: 1.1394 - regression_loss: 1.0043 - classification_loss: 0.1350
102/200 [==============>...............] - ETA: 16:58 - loss: 1.1386 - regression_loss: 1.0037 - classification_loss: 0.1349
103/200 [==============>...............] - ETA: 16:47 - loss: 1.1365 - regression_loss: 1.0020 - classification_loss: 0.1345
104/200 [==============>...............] - ETA: 16:38 - loss: 1.1377 - regression_loss: 1.0028 - classification_loss: 0.1349
105/200 [==============>...............] - ETA: 16:27 - loss: 1.1420 - regression_loss: 1.0058 - classification_loss: 0.1362
106/200 [==============>...............] - ETA: 16:17 - loss: 1.1441 - regression_loss: 1.0074 - classification_loss: 0.1367
107/200 [===============>..............] - ETA: 16:07 - loss: 1.1440 - regression_loss: 1.0074 - classification_loss: 0.1366
108/200 [===============>..............] - ETA: 15:57 - loss: 1.1434 - regression_loss: 1.0068 - classification_loss: 0.1366
109/200 [===============>..............] - ETA: 15:47 - loss: 1.1496 - regression_loss: 1.0119 - classification_loss: 0.1377
110/200 [===============>..............] - ETA: 15:36 - loss: 1.1520 - regression_loss: 1.0141 - classification_loss: 0.1379
111/200 [===============>..............] - ETA: 15:25 - loss: 1.1511 - regression_loss: 1.0134 - classification_loss: 0.1377
112/200 [===============>..............] - ETA: 15:15 - loss: 1.1494 - regression_loss: 1.0121 - classification_loss: 0.1373
113/200 [===============>..............] - ETA: 15:04 - loss: 1.1497 - regression_loss: 1.0122 - classification_loss: 0.1375
114/200 [================>.............] - ETA: 14:54 - loss: 1.1529 - regression_loss: 1.0148 - classification_loss: 0.1381
115/200 [================>.............] - ETA: 14:43 - loss: 1.1531 - regression_loss: 1.0150 - classification_loss: 0.1381
116/200 [================>.............] - ETA: 14:32 - loss: 1.1521 - regression_loss: 1.0140 - classification_loss: 0.1381
117/200 [================>.............] - ETA: 14:22 - loss: 1.1536 - regression_loss: 1.0152 - classification_loss: 0.1385
118/200 [================>.............] - ETA: 14:11 - loss: 1.1540 - regression_loss: 1.0155 - classification_loss: 0.1385
119/200 [================>.............] - ETA: 14:01 - loss: 1.1566 - regression_loss: 1.0173 - classification_loss: 0.1393
120/200 [=================>............] - ETA: 13:50 - loss: 1.1585 - regression_loss: 1.0188 - classification_loss: 0.1397
121/200 [=================>............] - ETA: 13:40 - loss: 1.1577 - regression_loss: 1.0182 - classification_loss: 0.1395
122/200 [=================>............] - ETA: 13:29 - loss: 1.1605 - regression_loss: 1.0202 - classification_loss: 0.1403
123/200 [=================>............] - ETA: 13:18 - loss: 1.1601 - regression_loss: 1.0199 - classification_loss: 0.1402
124/200 [=================>............] - ETA: 13:08 - loss: 1.1614 - regression_loss: 1.0211 - classification_loss: 0.1404
125/200 [=================>............] - ETA: 12:57 - loss: 1.1611 - regression_loss: 1.0208 - classification_loss: 0.1403
126/200 [=================>............] - ETA: 12:47 - loss: 1.1614 - regression_loss: 1.0211 - classification_loss: 0.1403
127/200 [==================>...........] - ETA: 12:36 - loss: 1.1634 - regression_loss: 1.0223 - classification_loss: 0.1411
128/200 [==================>...........] - ETA: 12:26 - loss: 1.1655 - regression_loss: 1.0238 - classification_loss: 0.1417
129/200 [==================>...........] - ETA: 12:15 - loss: 1.1644 - regression_loss: 1.0229 - classification_loss: 0.1415
130/200 [==================>...........] - ETA: 12:05 - loss: 1.1625 - regression_loss: 1.0214 - classification_loss: 0.1411
131/200 [==================>...........] - ETA: 11:54 - loss: 1.1616 - regression_loss: 1.0208 - classification_loss: 0.1409
132/200 [==================>...........] - ETA: 11:44 - loss: 1.1610 - regression_loss: 1.0202 - classification_loss: 0.1408
133/200 [==================>...........] - ETA: 11:34 - loss: 1.1587 - regression_loss: 1.0183 - classification_loss: 0.1404
134/200 [===================>..........] - ETA: 11:23 - loss: 1.1599 - regression_loss: 1.0193 - classification_loss: 0.1406
135/200 [===================>..........] - ETA: 11:13 - loss: 1.1596 - regression_loss: 1.0191 - classification_loss: 0.1405
136/200 [===================>..........] - ETA: 11:03 - loss: 1.1581 - regression_loss: 1.0178 - classification_loss: 0.1403
137/200 [===================>..........] - ETA: 10:52 - loss: 1.1571 - regression_loss: 1.0170 - classification_loss: 0.1401
138/200 [===================>..........] - ETA: 10:42 - loss: 1.1608 - regression_loss: 1.0197 - classification_loss: 0.1411
139/200 [===================>..........] - ETA: 10:32 - loss: 1.1586 - regression_loss: 1.0179 - classification_loss: 0.1407
140/200 [====================>.........] - ETA: 10:21 - loss: 1.1582 - regression_loss: 1.0175 - classification_loss: 0.1407
141/200 [====================>.........] - ETA: 10:11 - loss: 1.1580 - regression_loss: 1.0175 - classification_loss: 0.1405
142/200 [====================>.........] - ETA: 10:00 - loss: 1.1586 - regression_loss: 1.0180 - classification_loss: 0.1406
143/200 [====================>.........] - ETA: 9:50 - loss: 1.1583 - regression_loss: 1.0178 - classification_loss: 0.1405 
144/200 [====================>.........] - ETA: 9:39 - loss: 1.1576 - regression_loss: 1.0173 - classification_loss: 0.1404
145/200 [====================>.........] - ETA: 9:29 - loss: 1.1572 - regression_loss: 1.0170 - classification_loss: 0.1402
146/200 [====================>.........] - ETA: 9:18 - loss: 1.1578 - regression_loss: 1.0175 - classification_loss: 0.1402
147/200 [=====================>........] - ETA: 9:08 - loss: 1.1600 - regression_loss: 1.0193 - classification_loss: 0.1407
148/200 [=====================>........] - ETA: 8:57 - loss: 1.1586 - regression_loss: 1.0181 - classification_loss: 0.1405
149/200 [=====================>........] - ETA: 8:47 - loss: 1.1583 - regression_loss: 1.0178 - classification_loss: 0.1405
150/200 [=====================>........] - ETA: 8:37 - loss: 1.1611 - regression_loss: 1.0203 - classification_loss: 0.1408
151/200 [=====================>........] - ETA: 8:26 - loss: 1.1619 - regression_loss: 1.0210 - classification_loss: 0.1408
152/200 [=====================>........] - ETA: 8:16 - loss: 1.1620 - regression_loss: 1.0211 - classification_loss: 0.1409
153/200 [=====================>........] - ETA: 8:05 - loss: 1.1613 - regression_loss: 1.0205 - classification_loss: 0.1408
154/200 [======================>.......] - ETA: 7:55 - loss: 1.1612 - regression_loss: 1.0203 - classification_loss: 0.1409
155/200 [======================>.......] - ETA: 7:45 - loss: 1.1630 - regression_loss: 1.0218 - classification_loss: 0.1412
156/200 [======================>.......] - ETA: 7:34 - loss: 1.1609 - regression_loss: 1.0200 - classification_loss: 0.1409
157/200 [======================>.......] - ETA: 7:24 - loss: 1.1607 - regression_loss: 1.0198 - classification_loss: 0.1409
158/200 [======================>.......] - ETA: 7:13 - loss: 1.1621 - regression_loss: 1.0207 - classification_loss: 0.1414
159/200 [======================>.......] - ETA: 7:03 - loss: 1.1598 - regression_loss: 1.0187 - classification_loss: 0.1411
160/200 [=======================>......] - ETA: 6:53 - loss: 1.1588 - regression_loss: 1.0179 - classification_loss: 0.1409
161/200 [=======================>......] - ETA: 6:42 - loss: 1.1590 - regression_loss: 1.0182 - classification_loss: 0.1408
162/200 [=======================>......] - ETA: 6:32 - loss: 1.1584 - regression_loss: 1.0178 - classification_loss: 0.1406
163/200 [=======================>......] - ETA: 6:21 - loss: 1.1591 - regression_loss: 1.0186 - classification_loss: 0.1405
164/200 [=======================>......] - ETA: 6:11 - loss: 1.1586 - regression_loss: 1.0181 - classification_loss: 0.1404
165/200 [=======================>......] - ETA: 6:01 - loss: 1.1573 - regression_loss: 1.0171 - classification_loss: 0.1402
166/200 [=======================>......] - ETA: 5:50 - loss: 1.1591 - regression_loss: 1.0188 - classification_loss: 0.1404
167/200 [========================>.....] - ETA: 5:40 - loss: 1.1585 - regression_loss: 1.0183 - classification_loss: 0.1403
168/200 [========================>.....] - ETA: 5:30 - loss: 1.1596 - regression_loss: 1.0191 - classification_loss: 0.1404
169/200 [========================>.....] - ETA: 5:19 - loss: 1.1612 - regression_loss: 1.0205 - classification_loss: 0.1407
170/200 [========================>.....] - ETA: 5:09 - loss: 1.1640 - regression_loss: 1.0220 - classification_loss: 0.1420
171/200 [========================>.....] - ETA: 4:59 - loss: 1.1644 - regression_loss: 1.0224 - classification_loss: 0.1420
172/200 [========================>.....] - ETA: 4:48 - loss: 1.1632 - regression_loss: 1.0214 - classification_loss: 0.1418
173/200 [========================>.....] - ETA: 4:38 - loss: 1.1628 - regression_loss: 1.0212 - classification_loss: 0.1417
174/200 [=========================>....] - ETA: 4:28 - loss: 1.1607 - regression_loss: 1.0194 - classification_loss: 0.1414
175/200 [=========================>....] - ETA: 4:17 - loss: 1.1601 - regression_loss: 1.0189 - classification_loss: 0.1412
176/200 [=========================>....] - ETA: 4:07 - loss: 1.1601 - regression_loss: 1.0188 - classification_loss: 0.1413
177/200 [=========================>....] - ETA: 3:57 - loss: 1.1583 - regression_loss: 1.0172 - classification_loss: 0.1411
178/200 [=========================>....] - ETA: 3:46 - loss: 1.1581 - regression_loss: 1.0170 - classification_loss: 0.1410
179/200 [=========================>....] - ETA: 3:36 - loss: 1.1576 - regression_loss: 1.0166 - classification_loss: 0.1410
180/200 [==========================>...] - ETA: 3:26 - loss: 1.1575 - regression_loss: 1.0166 - classification_loss: 0.1409
181/200 [==========================>...] - ETA: 3:15 - loss: 1.1564 - regression_loss: 1.0158 - classification_loss: 0.1407
182/200 [==========================>...] - ETA: 3:05 - loss: 1.1603 - regression_loss: 1.0189 - classification_loss: 0.1414
183/200 [==========================>...] - ETA: 2:55 - loss: 1.1608 - regression_loss: 1.0193 - classification_loss: 0.1415
184/200 [==========================>...] - ETA: 2:44 - loss: 1.1601 - regression_loss: 1.0187 - classification_loss: 0.1413
185/200 [==========================>...] - ETA: 2:34 - loss: 1.1597 - regression_loss: 1.0183 - classification_loss: 0.1413
186/200 [==========================>...] - ETA: 2:24 - loss: 1.1596 - regression_loss: 1.0183 - classification_loss: 0.1413
187/200 [===========================>..] - ETA: 2:13 - loss: 1.1599 - regression_loss: 1.0185 - classification_loss: 0.1414
188/200 [===========================>..] - ETA: 2:03 - loss: 1.1593 - regression_loss: 1.0181 - classification_loss: 0.1412
189/200 [===========================>..] - ETA: 1:53 - loss: 1.1601 - regression_loss: 1.0188 - classification_loss: 0.1413
190/200 [===========================>..] - ETA: 1:43 - loss: 1.1599 - regression_loss: 1.0187 - classification_loss: 0.1412
191/200 [===========================>..] - ETA: 1:32 - loss: 1.1605 - regression_loss: 1.0192 - classification_loss: 0.1413
192/200 [===========================>..] - ETA: 1:22 - loss: 1.1609 - regression_loss: 1.0196 - classification_loss: 0.1413
193/200 [===========================>..] - ETA: 1:12 - loss: 1.1600 - regression_loss: 1.0189 - classification_loss: 0.1411
194/200 [============================>.] - ETA: 1:01 - loss: 1.1609 - regression_loss: 1.0195 - classification_loss: 0.1414
195/200 [============================>.] - ETA: 51s - loss: 1.1609 - regression_loss: 1.0196 - classification_loss: 0.1413 
196/200 [============================>.] - ETA: 41s - loss: 1.1601 - regression_loss: 1.0189 - classification_loss: 0.1412
197/200 [============================>.] - ETA: 30s - loss: 1.1619 - regression_loss: 1.0203 - classification_loss: 0.1416
198/200 [============================>.] - ETA: 20s - loss: 1.1621 - regression_loss: 1.0205 - classification_loss: 0.1416
199/200 [============================>.] - ETA: 10s - loss: 1.1623 - regression_loss: 1.0207 - classification_loss: 0.1416
200/200 [==============================] - 2059s 10s/step - loss: 1.1650 - regression_loss: 1.0223 - classification_loss: 0.1426
324 instances of class building with average precision: 0.6078
mAP: 0.6078

Epoch 00001: saving model to ./snapshots/resnet50_csv_01.h5
Epoch 2/40
  1/200 [..............................] - ETA: 33:31 - loss: 0.9357 - regression_loss: 0.8382 - classification_loss: 0.0974  2/200 [..............................] - ETA: 33:15 - loss: 0.9816 - regression_loss: 0.8739 - classification_loss: 0.1077  3/200 [..............................] - ETA: 33:06 - loss: 1.0183 - regression_loss: 0.9032 - classification_loss: 0.1151  4/200 [..............................] - ETA: 32:53 - loss: 1.0045 - regression_loss: 0.8939 - classification_loss: 0.1106  5/200 [..............................] - ETA: 32:46 - loss: 1.0136 - regression_loss: 0.9029 - classification_loss: 0.1107  6/200 [..............................] - ETA: 32:38 - loss: 0.9949 - regression_loss: 0.8880 - classification_loss: 0.1069  7/200 [>.............................] - ETA: 32:27 - loss: 1.0227 - regression_loss: 0.9114 - classification_loss: 0.1113  8/200 [>.............................] - ETA: 32:20 - loss: 1.0363 - regression_loss: 0.9227 - classification_loss: 0.1136  9/200 [>.............................] - ETA: 32:09 - loss: 1.0192 - regression_loss: 0.9075 - classification_loss: 0.1116 10/200 [>.............................] - ETA: 31:59 - loss: 1.0482 - regression_loss: 0.9319 - classification_loss: 0.1163 11/200 [>.............................] - ETA: 31:51 - loss: 1.0637 - regression_loss: 0.9421 - classification_loss: 0.1216 12/200 [>.............................] - ETA: 31:40 - loss: 1.0866 - regression_loss: 0.9621 - classification_loss: 0.1246 13/200 [>.............................] - ETA: 31:30 - loss: 1.0843 - regression_loss: 0.9600 - classification_loss: 0.1242 14/200 [=>............................] - ETA: 31:20 - loss: 1.1143 - regression_loss: 0.9855 - classification_loss: 0.1289 15/200 [=>............................] - ETA: 31:09 - loss: 1.1004 - regression_loss: 0.9743 - classification_loss: 0.1262 16/200 [=>............................] - ETA: 30:59 - loss: 1.0834 - regression_loss: 0.9598 - classification_loss: 0.1236 17/200 [=>............................] - ETA: 30:49 - loss: 1.0805 - regression_loss: 0.9569 - classification_loss: 0.1237 18/200 [=>............................] - ETA: 30:38 - loss: 1.0872 - regression_loss: 0.9618 - classification_loss: 0.1254 19/200 [=>............................] - ETA: 30:31 - loss: 1.0799 - regression_loss: 0.9568 - classification_loss: 0.1231 20/200 [==>...........................] - ETA: 30:25 - loss: 1.0868 - regression_loss: 0.9624 - classification_loss: 0.1244 21/200 [==>...........................] - ETA: 30:16 - loss: 1.0923 - regression_loss: 0.9670 - classification_loss: 0.1253 22/200 [==>...........................] - ETA: 30:05 - loss: 1.0911 - regression_loss: 0.9654 - classification_loss: 0.1257 23/200 [==>...........................] - ETA: 29:55 - loss: 1.0780 - regression_loss: 0.9540 - classification_loss: 0.1240 24/200 [==>...........................] - ETA: 29:44 - loss: 1.0784 - regression_loss: 0.9544 - classification_loss: 0.1240 25/200 [==>...........................] - ETA: 29:33 - loss: 1.0848 - regression_loss: 0.9598 - classification_loss: 0.1250 26/200 [==>...........................] - ETA: 29:23 - loss: 1.0863 - regression_loss: 0.9616 - classification_loss: 0.1246 27/200 [===>..........................] - ETA: 29:12 - loss: 1.0909 - regression_loss: 0.9657 - classification_loss: 0.1251 28/200 [===>..........................] - ETA: 29:02 - loss: 1.0905 - regression_loss: 0.9656 - classification_loss: 0.1249 29/200 [===>..........................] - ETA: 28:52 - loss: 1.0881 - regression_loss: 0.9642 - classification_loss: 0.1239 30/200 [===>..........................] - ETA: 28:41 - loss: 1.0893 - regression_loss: 0.9658 - classification_loss: 0.1235 31/200 [===>..........................] - ETA: 28:31 - loss: 1.0945 - regression_loss: 0.9702 - classification_loss: 0.1243 32/200 [===>..........................] - ETA: 28:20 - loss: 1.0943 - regression_loss: 0.9682 - classification_loss: 0.1261 33/200 [===>..........................] - ETA: 28:10 - loss: 1.0955 - regression_loss: 0.9691 - classification_loss: 0.1264 34/200 [====>.........................] - ETA: 28:00 - loss: 1.1033 - regression_loss: 0.9747 - classification_loss: 0.1286 35/200 [====>.........................] - ETA: 27:49 - loss: 1.1024 - regression_loss: 0.9730 - classification_loss: 0.1294 36/200 [====>.........................] - ETA: 27:39 - loss: 1.1103 - regression_loss: 0.9793 - classification_loss: 0.1310 37/200 [====>.........................] - ETA: 27:30 - loss: 1.1140 - regression_loss: 0.9826 - classification_loss: 0.1314 38/200 [====>.........................] - ETA: 27:19 - loss: 1.1204 - regression_loss: 0.9882 - classification_loss: 0.1322 39/200 [====>.........................] - ETA: 27:09 - loss: 1.1167 - regression_loss: 0.9850 - classification_loss: 0.1317 40/200 [=====>........................] - ETA: 27:01 - loss: 1.1339 - regression_loss: 0.9984 - classification_loss: 0.1355 41/200 [=====>........................] - ETA: 26:50 - loss: 1.1395 - regression_loss: 1.0023 - classification_loss: 0.1372 42/200 [=====>........................] - ETA: 26:42 - loss: 1.1348 - regression_loss: 0.9982 - classification_loss: 0.1366 43/200 [=====>........................] - ETA: 26:34 - loss: 1.1298 - regression_loss: 0.9936 - classification_loss: 0.1362 44/200 [=====>........................] - ETA: 26:24 - loss: 1.1358 - regression_loss: 0.9986 - classification_loss: 0.1372 45/200 [=====>........................] - ETA: 26:13 - loss: 1.1271 - regression_loss: 0.9914 - classification_loss: 0.1357 46/200 [=====>........................] - ETA: 26:03 - loss: 1.1243 - regression_loss: 0.9892 - classification_loss: 0.1351 47/200 [======>.......................] - ETA: 25:53 - loss: 1.1227 - regression_loss: 0.9880 - classification_loss: 0.1346 48/200 [======>.......................] - ETA: 25:42 - loss: 1.1205 - regression_loss: 0.9863 - classification_loss: 0.1342 49/200 [======>.......................] - ETA: 25:32 - loss: 1.1169 - regression_loss: 0.9835 - classification_loss: 0.1334 50/200 [======>.......................] - ETA: 25:22 - loss: 1.1221 - regression_loss: 0.9873 - classification_loss: 0.1348 51/200 [======>.......................] - ETA: 25:11 - loss: 1.1195 - regression_loss: 0.9854 - classification_loss: 0.1341 52/200 [======>.......................] - ETA: 25:01 - loss: 1.1175 - regression_loss: 0.9837 - classification_loss: 0.1339 53/200 [======>.......................] - ETA: 24:51 - loss: 1.1175 - regression_loss: 0.9835 - classification_loss: 0.1339 54/200 [=======>......................] - ETA: 24:41 - loss: 1.1166 - regression_loss: 0.9828 - classification_loss: 0.1338 55/200 [=======>......................] - ETA: 24:31 - loss: 1.1169 - regression_loss: 0.9831 - classification_loss: 0.1339 56/200 [=======>......................] - ETA: 24:21 - loss: 1.1143 - regression_loss: 0.9809 - classification_loss: 0.1334 57/200 [=======>......................] - ETA: 24:10 - loss: 1.1129 - regression_loss: 0.9793 - classification_loss: 0.1335 58/200 [=======>......................] - ETA: 24:00 - loss: 1.1130 - regression_loss: 0.9793 - classification_loss: 0.1337 59/200 [=======>......................] - ETA: 23:50 - loss: 1.1121 - regression_loss: 0.9786 - classification_loss: 0.1335 60/200 [========>.....................] - ETA: 23:40 - loss: 1.1108 - regression_loss: 0.9778 - classification_loss: 0.1330 61/200 [========>.....................] - ETA: 23:30 - loss: 1.1132 - regression_loss: 0.9799 - classification_loss: 0.1333 62/200 [========>.....................] - ETA: 23:19 - loss: 1.1098 - regression_loss: 0.9771 - classification_loss: 0.1327 63/200 [========>.....................] - ETA: 23:09 - loss: 1.1081 - regression_loss: 0.9759 - classification_loss: 0.1322 64/200 [========>.....................] - ETA: 22:59 - loss: 1.1082 - regression_loss: 0.9762 - classification_loss: 0.1321 65/200 [========>.....................] - ETA: 22:49 - loss: 1.1067 - regression_loss: 0.9749 - classification_loss: 0.1318 66/200 [========>.....................] - ETA: 22:38 - loss: 1.1055 - regression_loss: 0.9739 - classification_loss: 0.1315 67/200 [=========>....................] - ETA: 22:28 - loss: 1.1055 - regression_loss: 0.9739 - classification_loss: 0.1316 68/200 [=========>....................] - ETA: 22:18 - loss: 1.1067 - regression_loss: 0.9751 - classification_loss: 0.1317 69/200 [=========>....................] - ETA: 22:08 - loss: 1.1047 - regression_loss: 0.9734 - classification_loss: 0.1312 70/200 [=========>....................] - ETA: 21:59 - loss: 1.1048 - regression_loss: 0.9737 - classification_loss: 0.1311 71/200 [=========>....................] - ETA: 21:49 - loss: 1.1051 - regression_loss: 0.9739 - classification_loss: 0.1312 72/200 [=========>....................] - ETA: 21:39 - loss: 1.1048 - regression_loss: 0.9737 - classification_loss: 0.1312 73/200 [=========>....................] - ETA: 21:28 - loss: 1.1044 - regression_loss: 0.9735 - classification_loss: 0.1309 74/200 [==========>...................] - ETA: 21:18 - loss: 1.1053 - regression_loss: 0.9741 - classification_loss: 0.1312 75/200 [==========>...................] - ETA: 21:08 - loss: 1.1030 - regression_loss: 0.9714 - classification_loss: 0.1316 76/200 [==========>...................] - ETA: 20:58 - loss: 1.1070 - regression_loss: 0.9747 - classification_loss: 0.1322 77/200 [==========>...................] - ETA: 20:48 - loss: 1.1080 - regression_loss: 0.9755 - classification_loss: 0.1325 78/200 [==========>...................] - ETA: 20:37 - loss: 1.1063 - regression_loss: 0.9742 - classification_loss: 0.1321 79/200 [==========>...................] - ETA: 20:27 - loss: 1.1107 - regression_loss: 0.9775 - classification_loss: 0.1332 80/200 [===========>..................] - ETA: 20:17 - loss: 1.1142 - regression_loss: 0.9801 - classification_loss: 0.1341 81/200 [===========>..................] - ETA: 20:07 - loss: 1.1119 - regression_loss: 0.9783 - classification_loss: 0.1337 82/200 [===========>..................] - ETA: 19:57 - loss: 1.1159 - regression_loss: 0.9812 - classification_loss: 0.1347 83/200 [===========>..................] - ETA: 19:47 - loss: 1.1169 - regression_loss: 0.9822 - classification_loss: 0.1347 84/200 [===========>..................] - ETA: 19:37 - loss: 1.1146 - regression_loss: 0.9803 - classification_loss: 0.1343 85/200 [===========>..................] - ETA: 19:26 - loss: 1.1165 - regression_loss: 0.9821 - classification_loss: 0.1343 86/200 [===========>..................] - ETA: 19:16 - loss: 1.1186 - regression_loss: 0.9841 - classification_loss: 0.1346 87/200 [============>.................] - ETA: 19:06 - loss: 1.1179 - regression_loss: 0.9833 - classification_loss: 0.1345 88/200 [============>.................] - ETA: 18:56 - loss: 1.1242 - regression_loss: 0.9882 - classification_loss: 0.1361 89/200 [============>.................] - ETA: 18:46 - loss: 1.1272 - regression_loss: 0.9903 - classification_loss: 0.1369 90/200 [============>.................] - ETA: 18:36 - loss: 1.1293 - regression_loss: 0.9923 - classification_loss: 0.1370 91/200 [============>.................] - ETA: 18:26 - loss: 1.1311 - regression_loss: 0.9938 - classification_loss: 0.1373 92/200 [============>.................] - ETA: 18:16 - loss: 1.1345 - regression_loss: 0.9967 - classification_loss: 0.1378 93/200 [============>.................] - ETA: 18:06 - loss: 1.1313 - regression_loss: 0.9859 - classification_loss: 0.1454 94/200 [=============>................] - ETA: 17:55 - loss: 1.1305 - regression_loss: 0.9854 - classification_loss: 0.1451 95/200 [=============>................] - ETA: 17:45 - loss: 1.1432 - regression_loss: 0.9958 - classification_loss: 0.1475 96/200 [=============>................] - ETA: 17:35 - loss: 1.1533 - regression_loss: 1.0031 - classification_loss: 0.1502 97/200 [=============>................] - ETA: 17:25 - loss: 1.1526 - regression_loss: 1.0025 - classification_loss: 0.1501 98/200 [=============>................] - ETA: 17:15 - loss: 1.1524 - regression_loss: 1.0024 - classification_loss: 0.1500 99/200 [=============>................] - ETA: 17:05 - loss: 1.1514 - regression_loss: 1.0017 - classification_loss: 0.1497100/200 [==============>...............] - ETA: 16:55 - loss: 1.1511 - regression_loss: 1.0016 - classification_loss: 0.1495101/200 [==============>...............] - ETA: 16:45 - loss: 1.1504 - regression_loss: 1.0012 - classification_loss: 0.1492102/200 [==============>...............] - ETA: 16:35 - loss: 1.1492 - regression_loss: 1.0003 - classification_loss: 0.1489103/200 [==============>...............] - ETA: 16:25 - loss: 1.1475 - regression_loss: 0.9990 - classification_loss: 0.1485104/200 [==============>...............] - ETA: 16:15 - loss: 1.1489 - regression_loss: 1.0001 - classification_loss: 0.1488105/200 [==============>...............] - ETA: 16:05 - loss: 1.1473 - regression_loss: 0.9988 - classification_loss: 0.1484106/200 [==============>...............] - ETA: 15:55 - loss: 1.1458 - regression_loss: 0.9976 - classification_loss: 0.1481